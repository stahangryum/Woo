{
  
    
        "post0": {
            "title": "네이버 영화 랭킹 크롤링",
            "content": "&#45348;&#51060;&#48260; &#50689;&#54868; &#47021;&#53433; &#53356;&#47204;&#47553; . 네이버 영화 순위를 크롤링한다. | . Code . if (!require(rvest)) install.packages(&#39;rvest&#39;) library(rvest) if (!require(tidyverse)) install.packages(&#39;tidyverse&#39;) library(tidyverse) # 날짜와 페이지를 입력하면 조건에 따른 영화 코드를 반환하는 함수를 정의함 get_movie_code &lt;- function(date, page){ # ex) date = 20220502, page = 1 base_url &lt;- &#39;https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=pnt&amp;date=&#39; target_url &lt;- paste0(base_url, date, &#39;&amp;page=&#39;, page) tables &lt;- target_url %&gt;% read_html(encoding = &#39;UTF-8&#39;) %&gt;% html_nodes(&#39;table&#39;) hrefs &lt;- tables[[1]] %&gt;% html_nodes(&#39;a&#39;) %&gt;% html_attr(&#39;href&#39;) hrefs_odd &lt;- hrefs[c(TRUE, FALSE)] # 같은 코드이나 서로 다른링크가 짝으로 존재함을 확인했다. 홀수번째 원소만 인덱싱한다. codes &lt;- substr(hrefs_odd, unlist(gregexpr(&#39;=&#39;, hrefs_odd)) + 1, nchar(hrefs_odd)) # 다섯자리 코드와 여섯자리 코드가 혼재하므로 등호를 기준으로 인덱싱한다. return(codes) } # 영화의 코드를 입력하면 영화의 정보를 반환하는 함수를 정의함 get_movie_info &lt;- function(code){ base_url &lt;- &#39;https://movie.naver.com/movie/bi/mi/point.nhn?code=&#39; target_url &lt;- paste0(base_url, code) html &lt;- read_html(target_url) title_unclean &lt;- html %&gt;% html_nodes(&quot;title&quot;) %&gt;% html_text() title &lt;- substr(title_unclean, 1, unlist(gregexpr(&#39; : 네이버 영화&#39;, title_unclean))-1) exist &lt;- html %&gt;% html_nodes(&#39;dl[class=info_spec]&#39;) %&gt;% html_nodes(&#39;dt&#39;) %&gt;% html_text() steps &lt;- html %&gt;% html_nodes(&#39;dl[class=info_spec]&#39;) %&gt;% html_nodes(&#39;dd&#39;) # 개요, 감독, 출연, 등급 중 결측값이 존재하는 경우를 대비함 step1 = NA step2 = NA step3 = NA step4 = NA for (i in 1:length(exist)){ if (exist[i] == &#39;개요()&#39;){ step1_unclean &lt;- steps[i] %&gt;% html_nodes(&#39;p&#39;) %&gt;% html_nodes(&#39;span&#39;) %&gt;% html_text() step1 &lt;- gsub(&#39; t| n| r&#39;, &#39;&#39;, step1_unclean) }else if (exist[i] == &#39;감독&#39;){ step2 &lt;- steps[i] %&gt;% html_nodes(&#39;p&#39;) %&gt;% html_text() }else if (exist[i] == &#39;출연&#39;){ step3 &lt;- steps[i] %&gt;% html_text() }else if (exist[i] == &#39;등급&#39;){ step4_unclean &lt;- steps[i] %&gt;% html_nodes(&#39;p&#39;) %&gt;% html_text() step4 &lt;- gsub(&#39; t| n| r&#39;, &#39;&#39;, step4_unclean) } } if (length(step1) == 3){ # 개봉일자가 존재하지 않는 경우 결측값으로 처리함 ex)먼 훗날 우리 step1 = c(step1, NA) } tdt &lt;- html %&gt;% html_nodes(&#39;div[class=viewing_graph]&#39;) # 성별, 나이별 관람추이가 존재하지 않는 경우 관람객 통계가 존재하지 않으므로 결측값으로 처리함 if (length(tdt) == 0){ audience_age_10 &lt;- NA audience_age_20 &lt;- NA audience_age_30 &lt;- NA audience_age_40 &lt;- NA audience_age_50 &lt;- NA audience_score &lt;- NA audience_count &lt;- NA audience_male &lt;- NA audience_female &lt;- NA audience_10 &lt;- NA audience_20 &lt;- NA audience_30 &lt;- NA audience_40 &lt;- NA audience_50 &lt;- NA } else { audi_age &lt;- html %&gt;% html_nodes(&#39;strong[class=graph_percent]&#39;) %&gt;% html_text() audience_age_10 &lt;- audi_age[1] audience_age_20 &lt;- audi_age[2] audience_age_30 &lt;- audi_age[3] audience_age_40 &lt;- audi_age[4] audience_age_50 &lt;- audi_age[5] audience_score &lt;- html %&gt;% html_nodes(&#39;div[class=grade_audience]&#39;) %&gt;% html_nodes(&#39;div[class=star_score]&#39;) %&gt;% html_nodes(&#39;em&#39;) %&gt;% html_text() %&gt;% paste(collapse=&#39;&#39;) audience_count &lt;- html %&gt;% html_nodes(&#39;div[class=grade_audience]&#39;) %&gt;% html_nodes(&#39;span[class=user_count]&#39;) %&gt;% html_nodes(&#39;em&#39;) %&gt;% html_text() %&gt;% paste(collapse=&#39;&#39;) audience_male &lt;- (html %&gt;% html_nodes(&#39;div[class=graph_area]&#39;) %&gt;% html_nodes(&#39;div[class=grp_male]&#39;) %&gt;% html_nodes(&#39;strong[class=graph_point]&#39;) %&gt;% html_text())[2] audience_female &lt;- (html %&gt;% html_nodes(&#39;div[class=graph_area]&#39;) %&gt;% html_nodes(&#39;div[class=grp_female]&#39;) %&gt;% html_nodes(&#39;strong[class=graph_point]&#39;) %&gt;% html_text())[2] audience_age &lt;- html %&gt;% html_nodes(&#39;div[class=grp_age]&#39;) %&gt;% html_nodes(&#39;strong[class=graph_point]&#39;) %&gt;% html_text() audience_10 &lt;- audience_age[6] audience_20 &lt;- audience_age[7] audience_30 &lt;- audience_age[8] audience_40 &lt;- audience_age[9] audience_50 &lt;- audience_age[10] } netizen_score &lt;- html %&gt;% html_nodes(&#39;div[class=grade_netizen]&#39;) %&gt;% html_nodes(&#39;div[class=star_score]&#39;) %&gt;% html_nodes(&#39;em&#39;) %&gt;% html_text() %&gt;% paste(collapse=&#39;&#39;) netizen_count &lt;- html %&gt;% html_nodes(&#39;div[class=grade_netizen]&#39;) %&gt;% html_nodes(&#39;span[class=user_count]&#39;) %&gt;% html_nodes(&#39;em&#39;) %&gt;% html_text() %&gt;% paste(collapse=&#39;&#39;) ntz_male &lt;- (html %&gt;% html_nodes(&#39;div[class=graph_area]&#39;) %&gt;% html_nodes(&#39;div[class=grp_male]&#39;) %&gt;% html_nodes(&#39;strong[class=graph_point]&#39;) %&gt;% html_text())[1] ntz_female &lt;- (html %&gt;% html_nodes(&#39;div[class=graph_area]&#39;) %&gt;% html_nodes(&#39;div[class=grp_female]&#39;) %&gt;% html_nodes(&#39;strong[class=graph_point]&#39;) %&gt;% html_text())[1] ntz_age &lt;- html %&gt;% html_nodes(&#39;div[class=grp_age]&#39;) %&gt;% html_nodes(&#39;strong[class=graph_point]&#39;) %&gt;% html_text() ntz_10 &lt;- ntz_age[1] ntz_20 &lt;- ntz_age[2] ntz_30 &lt;- ntz_age[3] ntz_40 &lt;- ntz_age[4] ntz_50 &lt;- ntz_age[5] return(c(title, code, step1, step2, step3, step4, audience_age_10, audience_age_20, audience_age_30, audience_age_40, audience_age_50, netizen_score, netizen_count, ntz_male, ntz_female, ntz_10, ntz_20, ntz_30, ntz_40, ntz_50, audience_score, audience_count, audience_male, audience_female, audience_10, audience_20, audience_30, audience_40, audience_50)) } info &lt;- vector(&#39;list&#39;, 100) top_100_codes &lt;- c(get_movie_code(20220502, 1), get_movie_code(20220502, 2)) for (i in 1:length(top_100_codes)){ # 한 줄씩 차곡차곡 쌓는다. info[[i]] &lt;- get_movie_info(top_100_codes[i]) } final_info &lt;- do.call(&#39;rbind&#39;, info) # 컬럼명을 지정함 colnames(final_info) &lt;- c(&quot;title&quot;,&quot;code&quot;,&quot;genre&quot;,&quot;country&quot;,&quot;runtime&quot;,&quot;release&quot;, &quot;director&quot;,&quot;actor&quot;,&quot;view_class&quot;,&quot;audience_age_10&quot;,&quot;audience_age_20&quot;, &quot;audience_age_30&quot;,&quot;audience_age_40&quot;,&quot;audience_age_50&quot;, &quot;netizen_score&quot;,&quot;netizen_count&quot;,&quot;ntz_male&quot;,&quot;ntz_female&quot;,&quot;ntz_10&quot;, &quot;ntz_20&quot;,&quot;ntz_30&quot;,&quot;ntz_40&quot;,&quot;ntz_50&quot;,&quot;audience_score&quot;, &quot;audience_count&quot;,&quot;audience_male&quot;,&quot;audience_female&quot;,&quot;audience_10&quot;, &quot;audience_20&quot;,&quot;audience_30&quot;,&quot;audience_40&quot;,&quot;audience_50&quot;) write.csv(final_info, &#39;movie.csv&#39;, row.names=T) # 최종 csv파일 생성함 . 필요한 패키지를 로딩중입니다: rvest Warning message: &#34;패키지 &#39;rvest&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; 필요한 패키지를 로딩중입니다: tidyverse Warning message: &#34;패키지 &#39;tidyverse&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Attaching packages - tidyverse 1.3.1 -- v ggplot2 3.3.5 v purrr 0.3.4 v tibble 3.1.6 v dplyr 1.0.8 v tidyr 1.2.0 v stringr 1.4.0 v readr 2.1.2 v forcats 0.5.1 Warning message: &#34;패키지 &#39;ggplot2&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tibble&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tidyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;readr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;purrr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;dplyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;stringr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;forcats&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Conflicts - tidyverse_conflicts() -- x dplyr::filter() masks stats::filter() x readr::guess_encoding() masks rvest::guess_encoding() x dplyr::lag() masks stats::lag() . final_info . A matrix: 100 × 32 of type chr titlecodegenrecountryruntimereleasedirectoractorview_classaudience_age_10⋯ntz_50audience_scoreaudience_countaudience_maleaudience_femaleaudience_10audience_20audience_30audience_40audience_50 . 클라우스 | 191613 | 애니메이션, 코미디, 가족 | 스페인, 영국 | 96분 | 2019.11.15 개봉 | 서지오 파블로스, 카를로스 마르티네즈 로페즈 | 제이슨 슈왈츠먼, J.K. 시몬스, 라시다 존스더보기 | [국내] 전체 관람가 | NA | ⋯ | 9.17 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 그린 북 | 171539 | 드라마 | 미국 | 130분 | 2019.01.09 개봉 | 피터 패럴리 | 비고 모텐슨(토니 발레롱가), 마허샬라 알리(돈 셜리 박사)더보기 | [국내] 12세 관람가 [해외] PG-13도움말 | 0% | ⋯ | 9.46 | 9.55 | 2,070 | 9.52 | 9.57 | 9.60 | 9.50 | 9.58 | 9.53 | 9.58 | . 가버나움 | 174830 | 드라마 | 레바논, 프랑스 | 126분 | 2019.01.24 개봉 | 나딘 라바키 | 자인 알 라피아(자인), 요르다노스 시프로우(라힐)더보기 | [국내] 15세 관람가 [해외] R도움말 | 2% | ⋯ | 9.55 | 9.54 | 1,393 | 9.39 | 9.61 | 9.64 | 9.56 | 9.51 | 9.58 | 9.49 | . 밥정 | 186114 | 다큐멘터리, 드라마 | 한국 | 82분 | 2020.10.07 개봉 | 박혜령 | 임지호(본인)더보기 | [국내] 전체 관람가 | 5% | ⋯ | 9.53 | 9.70 | 20 | 9.75 | 9.69 | 10.0 | 9.43 | 9.80 | 10.0 | 9.75 | . 장민호 드라마 최종회 | 213746 | 공연실황 | 한국 | 106분 | 2022.01.24 개봉 | NA | 장민호더보기 | [국내] 전체 관람가 | 0% | ⋯ | 9.89 | 9.89 | 9 | 9.00 | 10.0 | 0.00 | 0.00 | 10.0 | 9.75 | 10.0 | . 디지몬 어드벤처 라스트 에볼루션 : 인연 | 192613 | 애니메이션, 모험 | 일본 | 114분 | 2021.02.17 개봉 | 타구치 토모히사 | 하나에 나츠키(야가미 타이치), 호소야 요시마사(이시다 야마토), 사카모토 치카(아구몬)더보기 | [국내] 12세 관람가 | NA | ⋯ | 8.80 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 베일리 어게인 | 144906 | 모험, 코미디, 드라마 | 미국 | 100분 | 2018.11.22 개봉 | 라세 할스트롬 | 조시 게드(베일리/ 엘리/ 티노/ 버디 목소리), 데니스 퀘이드(이든), K.J. 아파(십대 이든)더보기 | [국내] 전체 관람가 [해외] PG도움말 | 3% | ⋯ | 9.35 | 9.42 | 463 | 9.36 | 9.44 | 9.71 | 9.52 | 9.36 | 9.14 | 9.58 | . 원더 | 151196 | 드라마 | 미국 | 113분 | 2021.02.11 재개봉, 2017.12.27 개봉 | 스티븐 크보스키 | 제이콥 트렘블레이(어기 풀먼), 줄리아 로버츠(이자벨 풀먼), 오웬 윌슨(네이트 풀먼)더보기 | [국내] 전체 관람가 [해외] PG도움말 | 2% | ⋯ | 9.33 | 9.43 | 319 | 9.37 | 9.46 | 10.0 | 9.45 | 9.47 | 9.32 | 9.56 | . 아일라 | 169240 | 드라마, 전쟁 | 한국, 터키 | 123분 | 2018.06.21 개봉 | 잔 울카이 | 김설(아일라), 이스마일 하지오글루(슐레이만)더보기 | [국내] 15세 관람가 | 0% | ⋯ | 9.44 | 9.13 | 70 | 8.81 | 9.32 | 0.00 | 9.45 | 8.74 | 9.33 | 8.17 | . 극장판 바이올렛 에버가든 | 196843 | 애니메이션, 드라마, 판타지 | 일본 | 140분 | 2020.11.12 개봉 | 이시다테 타이치 | 이시카와 유이(바이올렛 에버가든 목소리), 나미카와 다이스케(길베르트 부겐빌리아 목소리)더보기 | [국내] 전체 관람가 | 17% | ⋯ | 9.46 | 9.68 | 436 | 9.69 | 9.67 | 9.95 | 9.66 | 9.62 | 9.42 | 9.86 | . 먼 훗날 우리 | 175092 | 드라마, 멜로/로맨스 | 중국 | 120분 | NA | 유약영 | 정백연, 주동우, 톈좡좡더보기 | NA | NA | ⋯ | 9.20 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 당갈 | 157243 | 드라마, 액션 | 인도 | 161분 | 2018.04.25 개봉 | 니테쉬 티와리 | 아미르 칸(마하비르 싱 포갓), 파티마 사나 셰이크(기타), 산야 말호트라(바비타)더보기 | [국내] 12세 관람가 | 6% | ⋯ | 9.36 | 9.62 | 306 | 9.26 | 9.73 | 9.65 | 9.79 | 9.50 | 8.85 | 9.38 | . 포드 V 페라리 | 181710 | 액션, 드라마 | 미국 | 152분 | 2019.12.04 개봉 | 제임스 맨골드 | 맷 데이먼(캐롤 셸비), 크리스찬 베일(켄 마일스)더보기 | [국내] 12세 관람가 | 2% | ⋯ | 9.42 | 9.31 | 1,112 | 9.34 | 9.25 | 9.57 | 9.40 | 9.24 | 9.41 | 8.90 | . 주전장 | 179518 | 다큐멘터리 | 미국 | 121분 | 2019.07.25 개봉 | 미키 데자키 | NA | [국내] 전체 관람가 | 3% | ⋯ | 8.85 | 9.67 | 317 | 9.64 | 9.68 | 9.90 | 9.64 | 9.65 | 9.82 | 9.47 | . 그대, 고맙소 : 김호중 생애 첫 팬미팅 무비 | 196828 | 공연실황 | 한국 | 80분 | 2020.09.29 개봉 | 오윤동 | 김호중더보기 | [국내] 전체 관람가 | NA | ⋯ | 9.91 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 쇼생크 탈출 | 17421 | 드라마 | 미국 | 142분 | 2016.02.24 재개봉, 1995.01.28 개봉 | 프랭크 다라본트 | 팀 로빈스(앤디 듀프레인), 모건 프리먼(엘리스 보이드 레드 레딩)더보기 | [국내] 15세 관람가 [해외] R도움말 | 0% | ⋯ | 8.68 | 9.88 | 17 | 10.0 | 9.75 | 0.00 | 9.86 | 10.0 | 10.0 | 0.00 | . 터미네이터 2:오리지널 | 10200 | SF, 액션, 스릴러 | 미국, 프랑스 | 137분 | 2019.10.24 재개봉, 2013.11.14 재개봉, 1991.07.06 개봉 | 제임스 카메론 | 아놀드 슈왈제네거(터미네이터)더보기 | [국내] 15세 관람가 [해외] R도움말 | 0% | ⋯ | 9.00 | 9.51 | 39 | 9.42 | 9.88 | 0.00 | 9.92 | 9.92 | 8.75 | 9.33 | . 덕구 | 154667 | 드라마 | 한국 | 91분 | 2018.04.05 개봉 | 방수인 | 이순재(덕구할배), 정지훈(덕구)더보기 | [국내] 전체 관람가 | 3% | ⋯ | 9.18 | 9.30 | 265 | 9.12 | 9.40 | 10.0 | 9.23 | 9.46 | 9.14 | 9.08 | . 클래식 | 35939 | 멜로/로맨스, 드라마 | 한국 | 132분 | 2003.01.30 개봉 | 곽재용 | 손예진(지혜/주희), 조승우(준하), 조인성(상민)더보기 | [국내] 12세 관람가 | 7% | ⋯ | 9.40 | 9.79 | 14 | 9.86 | 9.71 | 10.0 | 9.62 | 10.0 | 10.0 | 0.00 | . 나 홀로 집에 | 10016 | 모험, 범죄, 가족, 코미디 | 미국 | 105분 | 1991.07.06 개봉 | 크리스 콜럼버스 | 맥컬리 컬킨(케빈 맥콜리스터), 조 페시(좀도둑 해리 림), 다니엘 스턴(좀도둑 마브 머챈츠)더보기 | [국내] 전체 관람가 [해외] PG도움말 | NA | ⋯ | 8.47 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 라이언 일병 구하기 | 18988 | 전쟁, 액션, 드라마 | 미국 | 170분 | 1998.09.12 개봉 | 스티븐 스필버그 | 톰 행크스(존 밀러 대위), 에드워드 번즈(Pvt. 리처드 레이번), 톰 시즈모어(Sgt. 마이클 호바스)더보기 | [국내] 15세 관람가 [해외] R도움말 | NA | ⋯ | 9.15 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 월-E | 69105 | 애니메이션, SF, 가족, 코미디, 멜로/로맨스, 모험 | 미국 | 104분 | 2008.08.06 개봉 | 앤드류 스탠튼 | 벤 버트(월-E / M-O 목소리), 엘리사 나이트(이브 목소리), 제프 갈린(선장 목소리)더보기 | [국내] 전체 관람가 [해외] G도움말 | NA | ⋯ | 9.25 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 빽 투 더 퓨쳐 | 10002 | SF, 코미디 | 미국 | 120분 | 2015.10.21 재개봉, 1987.07.17 개봉 | 로버트 저메키스 | 마이클 J. 폭스(마티 맥플라이), 크리스토퍼 로이드(에메트 브라운 박사), 리 톰슨(로레인 베인스 맥플라이)더보기 | [국내] 12세 관람가 [해외] PG도움말 | 2% | ⋯ | 8.82 | 9.39 | 49 | 9.64 | 9.19 | 10.0 | 9.23 | 9.78 | 9.62 | 8.00 | . 보헤미안 랩소디 | 156464 | 드라마 | 미국, 영국 | 134분 | 2018.10.31 개봉 | 브라이언 싱어 | 라미 말렉(프레디 머큐리), 루시 보인턴(메리 오스틴), 귈림 리(브라이언 메이)더보기 | [국내] 12세 관람가 | 3% | ⋯ | 9.36 | 9.45 | 13,104 | 9.39 | 9.50 | 9.45 | 9.47 | 9.47 | 9.46 | 9.35 | . 사운드 오브 뮤직 | 10102 | 멜로/로맨스, 뮤지컬, 드라마 | 미국 | 172분 | 2017.02.02 재개봉, 2012.01.23 재개봉, 1995.09.30 재개봉, 1978.02.04 재개봉, 1969.10.29 개봉 | 로버트 와이즈 | 줄리 앤드류스(마리아), 크리스토퍼 플러머(캡틴 조지 본 트랩), 엘레노 파커(남작 부인)더보기 | [국내] 전체 관람가 [해외] NR도움말 | 10% | ⋯ | 8.99 | 9.60 | 10 | 10.0 | 9.50 | 10.0 | 9.50 | 0.00 | 10.0 | 0.00 | . 포레스트 검프 | 17159 | 드라마, 코미디 | 미국 | 142분 | 2016.09.07 재개봉, 1994.10.15 개봉 | 로버트 저메키스 | 톰 행크스(포레스트 검프)더보기 | [국내] 12세 관람가 [해외] PG-13도움말 | 5% | ⋯ | 8.80 | 9.52 | 120 | 9.56 | 9.48 | 9.67 | 9.42 | 9.66 | 9.57 | 10.0 | . 글래디에이터 | 29217 | 액션, 드라마 | 미국, 영국 | 154분 | 2000.06.03 개봉 | 리들리 스콧 | 러셀 크로우(막시무스), 호아킨 피닉스(코모두스), 코니 닐슨(루실라)더보기 | [국내] 15세 관람가 [해외] R도움말 | NA | ⋯ | 9.12 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 타이타닉 | 18847 | 멜로/로맨스, 드라마 | 미국 | 194분 | 2018.02.01 재개봉, 2012.04.05 재개봉, 1998.02.20 개봉 | 제임스 카메론 | 레오나르도 디카프리오(잭 도슨), 케이트 윈슬렛(로즈 드윗 부카더)더보기 | [국내] 15세 관람가 [해외] PG-13도움말 | 14% | ⋯ | 9.08 | 9.88 | 269 | 9.92 | 9.86 | 9.82 | 9.92 | 9.91 | 9.65 | 9.92 | . 위대한 쇼맨 | 106360 | 드라마, 뮤지컬 | 미국 | 104분 | 2020.05.21 재개봉, 2017.12.20 개봉 | 마이클 그레이시 | 휴 잭맨(P.T. 바넘), 잭 에프론(필립 칼라일), 미셸 윌리엄스(채러티 바넘)더보기 | [국내] 12세 관람가 [해외] PG도움말 | 6% | ⋯ | 9.46 | 9.31 | 3,877 | 9.42 | 9.24 | 9.34 | 9.37 | 9.29 | 9.11 | 9.18 | . 인생은 아름다워 | 22126 | 드라마, 코미디 | 이탈리아 | 116분 | 2016.04.13 재개봉, 1999.03.06 개봉 | 로베르토 베니니 | 로베르토 베니니(귀도), 니콜레타 브라스키(도라)더보기 | [국내] 전체 관람가 [해외] PG-13도움말 | 0% | ⋯ | 8.35 | 9.54 | 28 | 9.38 | 9.67 | 0.00 | 9.73 | 9.67 | 9.00 | 9.00 | . ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋱ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | . 에이리언 2 | 10038 | SF, 공포, 스릴러, 액션 | 미국 | 137분 | 1986.12.24 개봉 | 제임스 카메론 | 시고니 위버(엘렌 리플리), 마이클 빈(Cpl. 드웨인 힉스), 폴 레이저(카터 버크)더보기 | [국내] 15세 관람가 [해외] R도움말 | NA | ⋯ | 9.33 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 로망 | 182348 | 멜로/로맨스 | 한국 | 112분 | 2019.04.03 개봉 | 이창근 | 이순재(조남봉), 정영숙(이매자), 조한철(조진수)더보기 | [국내] 전체 관람가 | 4% | ⋯ | 8.77 | 8.98 | 83 | 8.83 | 9.08 | 9.33 | 9.31 | 8.89 | 8.80 | 8.20 | . 미세스 다웃파이어 | 16210 | 코미디, 가족, 드라마 | 미국 | 125분 | 1994.01.22 개봉 | 크리스 콜럼버스 | 로빈 윌리엄스(다니엘/미세스 다웃파이어), 샐리 필드(미란다)더보기 | [국내] 12세 관람가 [해외] PG-13도움말 | NA | ⋯ | 9.19 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 더 록 | 17135 | 액션 | 미국 | 131분 | 1996.07.13 개봉 | 마이클 베이 | 숀 코네리(존 패트릭 메이슨), 니콜라스 케이지(닥터 스탠리 굿스피드), 에드 해리스(프란시스 X. 험멜 장군)더보기 | [국내] 15세 관람가 [해외] R도움말 | NA | ⋯ | 9.22 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 울지마 톤즈 | 76667 | 다큐멘터리 | 한국 | 91분 | 2010.09.09 개봉 | 구수환 | 이금희(나레이션), 이태석(본인)더보기 | [국내] 전체 관람가 | 0% | ⋯ | 9.30 | 10.00 | 1 | 0.00 | 10.0 | 0.00 | 0.00 | 0.00 | 10.0 | 0.00 | . 다크 나이트 | 62586 | 액션, 범죄, 드라마, 미스터리 | 미국 | 152분 | 2020.07.01 재개봉, 2017.07.12 재개봉, 2009.02.19 재개봉, 2008.08.06 개봉 | 크리스토퍼 놀란 | 크리스찬 베일(브루스 웨인/배트맨), 히스 레저(조커), 아론 에크하트(하비 덴트/투 페이스)더보기 | [국내] 15세 관람가 [해외] PG-13도움말 | 17% | ⋯ | 9.12 | 9.65 | 46 | 9.78 | 9.36 | 9.88 | 9.68 | 9.62 | 9.00 | 9.00 | . 아마데우스 | 10114 | 드라마 | 미국 | 180분 | 2015.10.29 재개봉, 1985.11.23 개봉 | 밀로스 포만 | 톰 헐스(볼프강 아마데우스 모짜르트), F. 머레이 아브라함(안토니오 살리에리), 엘리자베스 베리지(콘스탄츠 모짜르트)더보기 | [국내] 12세 관람가 [해외] PG도움말 | 3% | ⋯ | 8.95 | 9.70 | 151 | 9.75 | 9.68 | 10.0 | 9.64 | 9.75 | 9.77 | 9.67 | . 알라딘 | 13008 | 애니메이션, 뮤지컬, 코미디, 가족, 모험, 드라마, 멜로/로맨스 | 미국 | 90분 | 1993.07.03 개봉 | 존 머스커, 론 클레멘츠 | 스콧 와인거(알라딘/알리바브와 왕자 목소리), 로빈 윌리엄스(램프의 요정 지니 목소리), 린다 라킨(쟈스민 공주 목소리)더보기 | [국내] 전체 관람가 [해외] G도움말 | NA | ⋯ | 8.97 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 자산어보 | 189075 | 드라마 | 한국 | 126분 | 2021.03.31 개봉 | 이준익 | 설경구(정약전), 변요한(창대)더보기 | [국내] 12세 관람가 | 1% | ⋯ | 9.55 | 9.03 | 323 | 8.83 | 9.24 | 10.0 | 9.12 | 8.80 | 8.99 | 9.27 | . 빌리 엘리어트 | 31013 | 드라마, 가족, 코미디 | 영국, 프랑스 | 110분 | 2017.01.18 재개봉, 2001.02.17 개봉 | 스티븐 달드리 | 제이미 벨(빌리 엘리어트), 줄리 월터스(윌킨슨 부인), 게리 루이스(아버지 재키 엘리어트)더보기 | [국내] 12세 관람가 [해외] R도움말 | 4% | ⋯ | 8.66 | 9.75 | 79 | 9.76 | 9.74 | 10.0 | 9.69 | 9.85 | 9.70 | 9.33 | . 두 교황 | 189111 | 드라마 | 미국, 영국, 이탈리아, 아르헨티나 | 126분 | 2019.12.11 개봉 | 페르난도 메이렐레스 | 안소니 홉킨스(교황 베네딕토 16세), 조나단 프라이스(교황 프란치스코)더보기 | [국내] 12세 관람가 | 0% | ⋯ | 9.58 | 9.32 | 131 | 9.26 | 9.36 | 0.00 | 8.95 | 9.31 | 9.46 | 9.47 | . 그대를 사랑합니다 | 73476 | 드라마 | 한국 | 118분 | 2011.02.17 개봉 | 추창민 | 이순재(김만석), 윤소정(송이뿐), 송재호(장군봉)더보기 | [국내] 15세 관람가 | NA | ⋯ | 8.79 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 아이 엠 샘 | 34227 | 드라마 | 미국 | 132분 | 2002.10.18 개봉 | 제시 넬슨 | 숀 펜(샘 도슨), 미셸 파이퍼(리타 해리슨)더보기 | [국내] 12세 관람가 [해외] PG-13도움말 | NA | ⋯ | 9.24 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 언터처블: 1%의 우정 | 87566 | 코미디, 드라마 | 프랑스 | 112분 | 2012.03.22 개봉 | 올리비에르 나카체, 에릭 토레다노 | 프랑수아 클루제(필립), 오마 사이(드리스)더보기 | [국내] 12세 관람가 | NA | ⋯ | 9.46 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 피아니스트 | 35187 | 드라마, 전쟁 | 프랑스, 독일, 폴란드, 영국, 네덜란드 | 148분 | 2015.06.18 재개봉, 2003.01.03 개봉 | 로만 폴란스키 | 애드리언 브로디(블라디슬로프 스필만), 토마스 크레취만(빌름 호젠펠트)더보기 | [국내] 12세 관람가 [해외] R도움말 | 8% | ⋯ | 9.23 | 9.51 | 53 | 9.61 | 9.43 | 9.25 | 9.58 | 9.33 | 9.67 | 10.0 | . 오세암 | 34181 | 애니메이션, 드라마 | 한국 | 75분 | 2003.05.01 개봉 | 성백엽 | 김서영(길손이 목소리), 박선영(감이 목소리)더보기 | [국내] 전체 관람가 | NA | ⋯ | 8.51 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 언더독 | 144318 | 애니메이션 | 한국 | 102분 | 2019.01.16 개봉 | 오성윤, 이춘백 | 디오(뭉치 목소리), 박소담(밤이 목소리), 박철민(짱아 목소리)더보기 | [국내] 전체 관람가 | 3% | ⋯ | 9.18 | 9.47 | 362 | 9.53 | 9.44 | 9.60 | 9.65 | 9.32 | 9.46 | 9.74 | . 천공의 성 라퓨타 | 18782 | 애니메이션, 판타지, 모험 | 일본 | 124분 | 2004.04.30 개봉 | 미야자키 하야오 | 타나카 마유미(파즈 목소리), 요코자와 케이코(쉬타 목소리), 하츠이 코토에(돌라 목소리)더보기 | [국내] 전체 관람가 | NA | ⋯ | 8.43 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 프리 윌리 | 16466 | 가족, 모험, 드라마 | 미국 | 112분 | 1994.08.06 개봉 | 사이먼 윈서 | 케이코(윌리), 제이슨 제임스 리처(제시), 로리 페티(래 린들리)더보기 | [국내] 전체 관람가 [해외] PG도움말 | NA | ⋯ | 8.95 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 아이언 자이언트 | 25915 | 애니메이션, SF, 액션, 가족 | 미국 | 90분 | 2019.10.09 재개봉, 2000.05 개봉 | 브래드 버드 | 제니퍼 애니스톤(애니 휴즈 목소리), 빈 디젤(아이언 자이언트 목소리), 엘리 마리엔탈(호가드 휴즈 목소리)더보기 | [국내] 전체 관람가 [해외] PG도움말 | 0% | ⋯ | 9.06 | 9.47 | 15 | 9.33 | 9.67 | 0.00 | 9.50 | 9.00 | 9.75 | 0.00 | . 업 | 52120 | 애니메이션, 가족, 모험, 코미디, 액션 | 미국 | 101분 | 2009.07.29 개봉 | 피트 닥터, 밥 피터슨 | 에드워드 애스너(칼 프레드릭슨), 조던 나가이(러셀 목소리), 크리스토퍼 플러머(찰스 먼츠 목소리)더보기 | [국내] 전체 관람가 [해외] PG도움말 | NA | ⋯ | 9.05 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 라푼젤 | 75470 | 애니메이션, 코미디, 가족, 판타지, 뮤지컬, 멜로/로맨스 | 미국 | 100분 | 2011.02.10 개봉 | 네이슨 그레노, 바이론 하워드 | 맨디 무어(라푼젤 목소리), 제커리 레비(플린 라이더 목소리)더보기 | [국내] 전체 관람가 [해외] PG도움말 | NA | ⋯ | 9.10 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 시네마 천국 | 10001 | 드라마, 멜로/로맨스 | 프랑스, 이탈리아 | 124분 | 2020.04.22 재개봉, 2013.09.26 재개봉, 1993.11.13 재개봉, 1990.07.07 개봉 | 쥬세페 토르나토레 | 마르코 레오나르디(청년 살바토레), 필립 느와레(알프레도), 자끄 페렝(중년 살바토레)더보기 | [국내] 전체 관람가 [해외] PG도움말 | 9% | ⋯ | 9.17 | 9.63 | 32 | 9.73 | 9.57 | 9.67 | 9.40 | 9.88 | 10.0 | 9.75 | . 프리퀀시 | 29657 | 범죄, 드라마, SF, 스릴러 | 미국 | 117분 | 2000.11.25 개봉 | 그레고리 호블릿 | 데니스 퀘이드(프랭크 설리반), 제임스 카비젤(존 설리반)더보기 | [국내] 12세 관람가 [해외] PG-13도움말 | NA | ⋯ | 8.97 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 해리 포터와 죽음의 성물 - 2부 | 47528 | 모험, 판타지, 미스터리 | 영국, 미국 | 131분 | 2011.07.13 개봉 | 데이빗 예이츠 | 다니엘 래드클리프(해리 포터), 엠마 왓슨(헤르미온느), 루퍼트 그린트(론 위즐리)더보기 | [국내] 전체 관람가 [해외] PG-13도움말 | NA | ⋯ | 9.10 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 달링 | 152655 | 드라마, 멜로/로맨스 | 영국 | 118분 | 2018.04.12 개봉 | 앤디 서키스 | 앤드류 가필드(로빈), 클레어 포이(다이애나)더보기 | [국내] 12세 관람가 [해외] PG-13도움말 | 0% | ⋯ | 9.47 | 9.08 | 59 | 9.46 | 8.83 | 0.00 | 9.36 | 9.00 | 8.33 | 9.00 | . 드래곤 길들이기 | 70457 | 애니메이션, 모험, 코미디, 가족, 판타지 | 미국 | 98분 | 2019.01.17 재개봉, 2010.05.20 개봉 | 딘 데블로이스, 크리스 샌더스 | 제이 바루첼(히컵 목소리), 제라드 버틀러(스토이크 목소리), 아메리카 페레라(아스트리드 목소리)더보기 | [국내] 전체 관람가 [해외] PG도움말 | 0% | ⋯ | 8.98 | 8.00 | 1 | 0.00 | 8.00 | 0.00 | 0.00 | 8.00 | 0.00 | 0.00 | . 러브 유어셀프 인 서울 | 180220 | 공연실황 | 한국 | 113분 | 2019.01.26 개봉 | NA | RM(본인), 진(본인), 슈가(본인)더보기 | [국내] 전체 관람가 | NA | ⋯ | 8.85 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 소원 | 103535 | 드라마 | 한국 | 122분 | 2013.10.02 개봉 | 이준익 | 설경구(동훈), 엄지원(미희), 이레(소원)더보기 | [국내] 12세 관람가 | NA | ⋯ | 9.13 | NA | NA | NA | NA | NA | NA | NA | NA | NA | . 브레이크 더 사일런스: 더 무비 | 195975 | 다큐멘터리 | 한국 | 89분 | 2020.09.24 개봉 | 박준수 | RM(본인), 진(본인), 슈가(본인)더보기 | [국내] 전체 관람가 | NA | ⋯ | 8.78 | NA | NA | NA | NA | NA | NA | NA | NA | NA | .",
            "url": "https://stahangryum.github.io/Woo/crawling/r/2022/05/30/naver_movie.html",
            "relUrl": "/crawling/r/2022/05/30/naver_movie.html",
            "date": " • May 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "명나라, 청나라 황제 수명 데이터 분석",
            "content": "Reference . - 명나라 황제 데이터 . https://en.wikipedia.org/wiki/List_of_emperors_of_the_Ming_dynasty . - 청나라 황제 데이터 . https://en.wikipedia.org/wiki/List_of_emperors_of_the_Qing_dynasty . Crawling . if (!require(rvest)) install.packages(&#39;rvest&#39;) library(rvest) if (!require(tidyverse)) install.packages(&#39;tidyverse&#39;) library(tidyverse) get_kings_info = function(order, nation){ # ex) order = 1, nation = &#39;Ming&#39; or &#39;King&#39; ming_url = &#39;https://en.wikipedia.org/wiki/List_of_emperors_of_the_Ming_dynasty&#39; qing_url = &#39;https://en.wikipedia.org/wiki/List_of_emperors_of_the_Qing_dynasty&#39; target_url = ifelse(nation == &#39;Ming&#39;, ming_url, qing_url) dynasty = ifelse(nation == &#39;Ming&#39;, &#39;Ming&#39;, &#39;Qing&#39;) unclean_table = (target_url %&gt;% read_html %&gt;% html_nodes(&#39;table[class=wikitable]&#39;))[1] %&gt;% html_nodes(&#39;tbody&#39;) %&gt;% html_nodes(&#39;tr&#39;) %&gt;% html_text() # 정규표현식을 이용해 양식을 맞춘다 requiredRows_index = str_detect(unclean_table, &#39;[A-Za-z]{5,} ([0-9]{1,2} s[A-Z]{1}&#39;) requiredRows = unclean_table[requiredRows_index] clean_table = gsub(&#39; n&#39;, &#39;&#39;, requiredRows[order]) %&gt;% strsplit(&#39;&#39;) %&gt;% unlist() name_start_index = 1 name_end_index = grep(&#39; (&#39;, clean_table)[1]-1 # 괄호보다 한 칸 이전에 있으므로 -1 name = clean_table[name_start_index:name_end_index] %&gt;% paste(collapse = &#39;&#39;) only_numbers = requiredRows[order] %&gt;% # 숫자 존재하는 벡터 strsplit(split = &#39;[^0-9]&#39;) %&gt;% unlist() year_index = grep(&#39;.{4}&#39;, only_numbers)[1:2] # 월, 일은 2글자를 초과하지 못하므로 자연스럽게 네글자만 연도이다. year = only_numbers[year_index] return(c(dynasty, name, year)) } ming_last_order = 16 qing_last_order = 12 ming_kings_info &lt;- vector(&#39;list&#39;, ming_last_order) qing_kings_info &lt;- vector(&#39;list&#39;, qing_last_order) for (i in 1:ming_last_order) ming_kings_info[[i]] = get_kings_info(i, &#39;Ming&#39;) for (i in 1:qing_last_order) qing_kings_info[[i]] = get_kings_info(i, &#39;Qing&#39;) kings_info = do.call(&#39;rbind&#39;, c(ming_kings_info, qing_kings_info)) colnames(kings_info) &lt;- c(&#39;dynasty&#39;, &#39;name&#39;, &#39;birth&#39;, &#39;death&#39;) write.table(kings_info, &#39;China_king.txt&#39;, row.names = FALSE) . 필요한 패키지를 로딩중입니다: rvest Warning message: &#34;패키지 &#39;rvest&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; 필요한 패키지를 로딩중입니다: tidyverse Warning message: &#34;패키지 &#39;tidyverse&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Attaching packages - tidyverse 1.3.1 -- v ggplot2 3.3.5 v purrr 0.3.4 v tibble 3.1.6 v dplyr 1.0.8 v tidyr 1.2.0 v stringr 1.4.0 v readr 2.1.2 v forcats 0.5.1 Warning message: &#34;패키지 &#39;ggplot2&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tibble&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tidyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;readr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;purrr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;dplyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;stringr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;forcats&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Conflicts - tidyverse_conflicts() -- x dplyr::filter() masks stats::filter() x readr::guess_encoding() masks rvest::guess_encoding() x dplyr::lag() masks stats::lag() . Analysis . kings_info &lt;- data.frame(kings_info) kings_info[, c(&#39;birth&#39;, &#39;death&#39;)] = kings_info[, c(&#39;birth&#39;, &#39;death&#39;)] %&gt;% unlist() %&gt;% as.numeric() kings_info = kings_info %&gt;% mutate(age = death - birth) par(mfrow = c(1,2)) plot(kings_info$birth, kings_info$age, xlab = &#39;birth&#39;, ylab = &#39;age&#39;) abline(lm(kings_info$age ~ kings_info$birth)) boxplot(kings_info$age ~ factor(kings_info$dynasty), xlab = &#39;dynasty&#39;, ylab = &#39;age&#39;) .",
            "url": "https://stahangryum.github.io/Woo/crawling/r/2022/05/30/ming-qing.html",
            "relUrl": "/crawling/r/2022/05/30/ming-qing.html",
            "date": " • May 30, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "조선 국왕 수명 데이터 분석",
            "content": "Reference . - 조선 국왕 데이터 . https://ko.wikipedia.org/wiki/%EC%A1%B0%EC%84%A0_%EA%B5%AD%EC%99%95 . Crawling . - 위키피디아에서 조선의 국와 정보를 크롤링합니다. . if (!require(rvest)) install.packages(&#39;rvest&#39;) library(rvest) if (!require(tidyverse)) install.packages(&#39;tidyverse&#39;) library(tidyverse) get_required_info = function(rows, order){ clean_table = rows[order] %&gt;% # 한글자씩 쪼갠다. strsplit(split = &#39;&#39;) %&gt;% unlist() %&gt;% str_replace(&#39;[^가-힣0-9]&#39;, &#39;N&#39;) %&gt;% # (한글, 숫자)가 아닌 문자는 불필요하므로 N으로 치환한다. paste(collapse = &#39;&#39;) %&gt;% # 모든 문자를 합친 다음 N을 기준으로 다시 나눈다. strsplit(&#39;N&#39;) %&gt;% unlist() order_index = grep(&#39;^제.{1,}대$&#39;, clean_table) order = clean_table[order_index] name_index = grep(&#39;^.{1,2}[조|종|군]$&#39;, clean_table)[1] name = clean_table[name_index] years_index = grep(&#39;^.{1,}년$&#39;, clean_table) years &lt;- # 순서대로 출생, 사망, 즉위, 퇴위 clean_table[years_index] %&gt;% substr(1, 4) grave_index = grep(&#39;^.{1,3}[릉|묘]$&#39;, clean_table) grave = clean_table[grave_index] return(c(order, name, years, grave)) } target_url &lt;- &#39;https://ko.wikipedia.org/wiki/%EC%A1%B0%EC%84%A0_%EA%B5%AD%EC%99%95&#39; unclean_table &lt;- read_html(target_url, encoding = &#39;UTF-8&#39;) %&gt;% html_nodes(&#39;table[class=wikitable]&#39;) %&gt;% html_nodes(&#39;tbody&#39;) %&gt;% html_nodes(&#39;tr&#39;) %&gt;% html_text() # 필요로 하는 데이터는 모두 &#39;제&#39;로 시작한다. # &#39;제&#39;로 시작하지 않는 데이터는 불필요하므로 제거한다. requiredRows_index &lt;- str_detect(unclean_table, &#39;^제&#39;) requiredRows &lt;- unclean_table[requiredRows_index] last_order = 26 kings_info &lt;- vector(&#39;list&#39;, last_order) for (i in 1:last_order){ kings_info[[i]] = get_required_info(requiredRows, i) } kings_info = do.call(&#39;rbind&#39;, kings_info) colnames(kings_info) = c(&#39;order&#39;, &#39;name&#39;, &#39;birth&#39;, &#39;death&#39;, &#39;king_start&#39;, &#39;king_end&#39;, &#39;grave&#39;) write.table(kings_info, &#39;Joseon_king.txt&#39;, row.names=FALSE) . 필요한 패키지를 로딩중입니다: rvest Warning message: &#34;패키지 &#39;rvest&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; 필요한 패키지를 로딩중입니다: tidyverse Warning message: &#34;패키지 &#39;tidyverse&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Attaching packages - tidyverse 1.3.1 -- v ggplot2 3.3.5 v purrr 0.3.4 v tibble 3.1.6 v dplyr 1.0.8 v tidyr 1.2.0 v stringr 1.4.0 v readr 2.1.2 v forcats 0.5.1 Warning message: &#34;패키지 &#39;ggplot2&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tibble&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tidyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;readr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;purrr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;dplyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;stringr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;forcats&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Conflicts - tidyverse_conflicts() -- x dplyr::filter() masks stats::filter() x readr::guess_encoding() masks rvest::guess_encoding() x dplyr::lag() masks stats::lag() . kings_info . A data.frame: 26 × 9 ordernamebirthdeathking_startking_endgraveageclass . &lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;fct&gt; . 제1대 | 태조 | 1335 | 1408 | 1392 | 1398 | 건원릉 | 73 | Before | . 제2대 | 정종 | 1357 | 1419 | 1398 | 1400 | 후릉 | 62 | Before | . 제3대 | 태종 | 1367 | 1422 | 1400 | 1418 | 헌릉 | 55 | Before | . 제4대 | 세종 | 1397 | 1450 | 1418 | 1450 | 영릉 | 53 | Before | . 제5대 | 문종 | 1414 | 1452 | 1450 | 1452 | 현릉 | 38 | Before | . 제6대 | 단종 | 1441 | 1457 | 1452 | 1455 | 장릉 | 16 | Before | . 제7대 | 세조 | 1417 | 1468 | 1455 | 1468 | 광릉 | 51 | Before | . 제8대 | 예종 | 1450 | 1469 | 1468 | 1469 | 창릉 | 19 | Before | . 제9대 | 성종 | 1457 | 1494 | 1469 | 1494 | 선릉 | 37 | Before | . 제10대 | 연산군 | 1476 | 1506 | 1494 | 1506 | 연산군묘 | 30 | Before | . 제11대 | 중종 | 1488 | 1544 | 1506 | 1544 | 정릉 | 56 | Before | . 제12대 | 인종 | 1515 | 1545 | 1544 | 1545 | 효릉 | 30 | Before | . 제13대 | 명종 | 1534 | 1567 | 1545 | 1567 | 강릉 | 33 | Before | . 제14대 | 선조 | 1552 | 1608 | 1567 | 1608 | 목릉 | 56 | Before | . 제15대 | 광해군 | 1575 | 1641 | 1608 | 1623 | 광해군묘 | 66 | Before | . 제16대 | 인조 | 1595 | 1649 | 1623 | 1649 | 장릉 | 54 | Before | . 제17대 | 효종 | 1619 | 1659 | 1649 | 1659 | 영릉 | 40 | After | . 제18대 | 현종 | 1641 | 1674 | 1659 | 1674 | 숭릉 | 33 | After | . 제19대 | 숙종 | 1661 | 1720 | 1674 | 1720 | 명릉 | 59 | After | . 제20대 | 경종 | 1688 | 1724 | 1720 | 1724 | 의릉 | 36 | After | . 제21대 | 영조 | 1694 | 1776 | 1724 | 1776 | 원릉 | 82 | After | . 제22대 | 정조 | 1752 | 1800 | 1776 | 1800 | 건릉 | 48 | After | . 제23대 | 순조 | 1790 | 1834 | 1800 | 1834 | 인릉 | 44 | After | . 제24대 | 헌종 | 1827 | 1849 | 1834 | 1849 | 경릉 | 22 | After | . 제25대 | 철종 | 1831 | 1863 | 1849 | 1863 | 예릉 | 32 | After | . 제26대 | 고종 | 1852 | 1919 | 1863 | 1897 | 홍릉 | 67 | After | . Analysis . - 왕의 수명을 출생년도 기준으로 동의보감 편찬 이전과 이후로 나누었을 때, 유의미한 차이가 있는가? . kings_info &lt;- data.frame(kings_info) kings_info[, c(&#39;birth&#39;, &#39;death&#39;)] = kings_info[, c(&#39;birth&#39;, &#39;death&#39;)] %&gt;% unlist() %&gt;% as.numeric() kings_info = kings_info %&gt;% mutate(age = death - birth) plot(kings_info$birth, kings_info$age, xlab = &#39;birth_year&#39;, ylab = &#39;age&#39;, main = &#39;동의보감 1610년&#39;) Donguibogam = 1610 abline(v = Donguibogam, col = &#39;red&#39;) abline(lm(kings_info$age ~ kings_info$birth)) # 회귀선 # 상자그림 kings_info[&#39;class&#39;] = ifelse(kings_info[&#39;birth&#39;] &lt;= 1610, &#39;Before&#39;, &#39;After&#39;) %&gt;% factor(levels = c(&#39;Before&#39;, &#39;After&#39;)) boxplot(kings_info$age ~ kings_info$class, xlab = &#39;group&#39;, ylab = &#39;age&#39;, main = &#39;동의보감 이전과 이후&#39;) .",
            "url": "https://stahangryum.github.io/Woo/crawling/r/2022/05/30/Joseon_king.html",
            "relUrl": "/crawling/r/2022/05/30/Joseon_king.html",
            "date": " • May 30, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Chudnovsky Algorithm",
            "content": "Chudnovsky Algorithm . The Chudnovsky algorithm is a fast method for calculating the digits of π. . Reference . https://en.wikipedia.org/wiki/Chudnovsky_algorithm . Code . import math from gmpy2 import mpz from time import time import gmpy2 def pi_chudnovsky_bs(digits): &quot;&quot;&quot; Compute int(pi * 10**digits) This is done using Chudnovsky&#39;s series with binary splitting &quot;&quot;&quot; C = 640320 C3_OVER_24 = C**3 // 24 def bs(a, b): &quot;&quot;&quot; Computes the terms for binary splitting the Chudnovsky infinite series a(a) = +/- (13591409 + 545140134*a) p(a) = (6*a-5)*(2*a-1)*(6*a-1) b(a) = 1 q(a) = a*a*a*C3_OVER_24 returns P(a,b), Q(a,b) and T(a,b) &quot;&quot;&quot; if b - a == 1: # Directly compute P(a,a+1), Q(a,a+1) and T(a,a+1) if a == 0: Pab = Qab = mpz(1) else: Pab = mpz((6*a-5)*(2*a-1)*(6*a-1)) Qab = mpz(a*a*a*C3_OVER_24) Tab = Pab * (13591409 + 545140134*a) # a(a) * p(a) if a &amp; 1: Tab = -Tab else: # Recursively compute P(a,b), Q(a,b) and T(a,b) # m is the midpoint of a and b m = (a + b) // 2 # Recursively calculate P(a,m), Q(a,m) and T(a,m) Pam, Qam, Tam = bs(a, m) # Recursively calculate P(m,b), Q(m,b) and T(m,b) Pmb, Qmb, Tmb = bs(m, b) # Now combine Pab = Pam * Pmb Qab = Qam * Qmb Tab = Qmb * Tam + Pam * Tmb return Pab, Qab, Tab # how many terms to compute DIGITS_PER_TERM = math.log10(C3_OVER_24/6/2/6) N = int(digits/DIGITS_PER_TERM + 1) # Calclate P(0,N) and Q(0,N) P, Q, T = bs(0, N) one_squared = mpz(10)**(2*digits) sqrtC = gmpy2.isqrt(10005*one_squared) return (Q*426880*sqrtC) // T # The last 5 digits or pi for various numbers of digits check_digits = { 100 : 70679, 1000 : 1989, 10000 : 75678, 100000 : 24646, 1000000 : 58151, 10000000 : 55897, } if __name__ == &quot;__main__&quot;: #raise SystemExit for log10_digits in range(1,8): # 10자리 ~ 1000만자리 digits = 10**log10_digits start =time() pi = pi_chudnovsky_bs(digits) f = open(&#39;d_&#39; + str(digits), &#39;w&#39;) f.write(str(pi)) f.close() print(&quot;chudnovsky_gmpy_mpz_bs: digits&quot;,digits,&quot;time&quot;,time()-start) if digits in check_digits: last_five_digits = pi % 100000 if check_digits[digits] == last_five_digits: print(&quot;Last 5 digits %05d OK&quot; % last_five_digits) else: print(&quot;Last 5 digits %05d wrong should be %05d&quot; % (last_five_digits, check_digits[digits])) . chudnovsky_gmpy_mpz_bs: digits 10 time 0.002651214599609375 chudnovsky_gmpy_mpz_bs: digits 100 time 0.0008170604705810547 Last 5 digits 70679 OK chudnovsky_gmpy_mpz_bs: digits 1000 time 0.0013988018035888672 Last 5 digits 01989 OK chudnovsky_gmpy_mpz_bs: digits 10000 time 0.0020301342010498047 Last 5 digits 75678 OK chudnovsky_gmpy_mpz_bs: digits 100000 time 0.03248786926269531 Last 5 digits 24646 OK chudnovsky_gmpy_mpz_bs: digits 1000000 time 0.5917906761169434 Last 5 digits 58151 OK chudnovsky_gmpy_mpz_bs: digits 10000000 time 11.120594263076782 Last 5 digits 55897 OK .",
            "url": "https://stahangryum.github.io/Woo/mathematics/python/2022/05/29/chudnovsky.html",
            "relUrl": "/mathematics/python/2022/05/29/chudnovsky.html",
            "date": " • May 29, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Gaon Chart Crawling",
            "content": "Intro . - 가온 차트(Gaon Chart)는 대한민국의 대중음악 공인차트이다. 가온이라는 단어는 가운데, 중심이라는 뜻의 순우리말로, 중심이 되는 차트라는 의미에서 명명되었다. 한국음악콘텐츠협회가 운영하고 문화체육관광부가 후원하는 사업으로, 2년여 준비기간을 걸쳐 2010년 2월 23일 출범했다. . Crawling . if (!require(pacman)) install.packages(&#39;pacman&#39;); library(pacman) pacman::p_load(&quot;rvest&quot;, &quot;tidyverse&quot;) getLinks &lt;- function(termGbn){ # Input &#39;week&#39; or &#39;month&#39; base_url &lt;- &#39;http://gaonchart.co.kr/main/section/chart/online.gaon?nationGbn=T&amp;serviceGbn=ALL&#39; sample_url &lt;- paste0(base_url, &#39;&amp;termGbn=&#39;, termGbn) dates &lt;- read_html(sample_url) %&gt;% html_nodes(&#39;div[class=fr]&#39;) %&gt;% html_nodes(&#39;select&#39;) %&gt;% html_nodes(&#39;option&#39;) %&gt;% html_attr(&#39;value&#39;) %&gt;% str_subset(pattern = &#39;^[0-9]{6}$&#39;) # &#39;dates&#39;(YYYYMM) will be divided into hitYear(YYYY) and targetTime(MM). # Ex) dates &lt;- 202221. hitYear &lt;- dates %&gt;% substr(1,4) # Ex) hitYear &lt;- 2022. targetTime &lt;- dates %&gt;% substr(5,6) # Ex) hitYear &lt;- 21. complete_url &lt;- paste0(base_url, &#39;&amp;targetTime=&#39;, targetTime, &#39;&amp;hitYear=&#39;, hitYear, &#39;&amp;termGbn=&#39;, termGbn) return(complete_url) # Return all urls } getPage &lt;- function(target_url){ # Input complete URL including targetTime, hitYear, and termGbn url_splited &lt;- target_url %&gt;% strsplit(&#39;=|&amp;&#39;) %&gt;% unlist() year_temp &lt;- url_splited %&gt;% str_subset(&#39;^[0-9]{2,4}$&#39;) %&gt;% rev() %&gt;% paste0(collapse = &#39;&#39;) termGbn &lt;- url_splited %&gt;% &#39;[&#39;(length(url_splited)) html_chart &lt;- read_html(target_url) %&gt;% html_nodes(&#39;div[class=chart]&#39;) td &lt;- html_chart %&gt;% html_nodes(&#39;td&#39;) %&gt;% html_text() %&gt;% str_split(&#39; n| || r| t&#39;) %&gt;% unlist() %&gt;% str_subset(&#39;^$&#39;, negate = TRUE) change_grp &lt;- html_chart %&gt;% html_nodes(&#39;td[class=change]&#39;) %&gt;% html_nodes(&#39;span&#39;) %&gt;% html_attr(&#39;class&#39;) # sort by &#39;PLAY&#39; ## Ex) ## &quot;~~&quot;, &quot;~~&quot;, &quot;PLAY&quot;, &quot;~~&quot;, &quot;~~&quot;, &quot;PLAY&quot;, &quot;~~&quot;, &quot;~~&quot;, &quot;PLAY&quot; ## to ## |~~|~~|&#39;PLAY&#39;| ## |~~|~~|&#39;PLAY&#39;| ## |~~|~~|&#39;PLAY&#39;| # &#39;Gaon Score&#39; was newly created in Jan 2018. ## Before Jan 2018 : chart_piece has 11 columns. ## After Jan 2018 : chart_piece has 12 columns. index_PLAY &lt;- str_which(td, &#39;PLAY&#39;) PLAY_ZONE &lt;- c(11, 12) index_TRUE_PLAY &lt;- index_PLAY[index_PLAY %in% PLAY_ZONE][1] chart_piece &lt;- td %&gt;% matrix(ncol = index_TRUE_PLAY, byrow = TRUE) %&gt;% as_tibble() # Note : ifelse always returns an object of the same length as the condition. so we use if/else for this case. chart &lt;- tibble(year_temp = year_temp, ranking = chart_piece$V1, change_grp = change_grp, change_val = chart_piece$V2, title = chart_piece$V3, artist = chart_piece$V4, gaon_index = if (ncol(chart_piece) == 12) chart_piece$V6 else NA, production = if(ncol(chart_piece) == 12) chart_piece$V7 else chart_piece$V6, distribution = if(ncol(chart_piece) == 12) chart_piece$V8 else chart_piece$V7) chart$gaon_index &lt;- chart$gaon_index %&gt;% str_replace_all(&#39;[^0-9]&#39;, &#39;&#39;) %&gt;% as.numeric() colnames(chart)[1] &lt;- ifelse(termGbn == &#39;week&#39;, &#39;year_week&#39;, &#39;year_month&#39;) return(chart) # Return chart of the &#39;target_url&#39;. } # Weekly Rankings. # Time to run : 7~8min. weekLinks &lt;- getLinks(&#39;week&#39;) all_week_pages &lt;- vector(&#39;list&#39;, length(weekLinks)) for (i in 1:length(all_week_pages)) all_week_pages[[i]] &lt;- getPage(weekLinks[i]) week_final &lt;- do.call(&#39;rbind&#39;, all_week_pages) write.table(week_final, &#39;gaon_week.txt&#39;, row.names = FALSE) # Monthly Rankings. # Time to run : 1~2min. monthLinks &lt;- getLinks(&#39;month&#39;) all_month_pages &lt;- vector(&#39;list&#39;, length(monthLinks)) for (i in 1:length(all_month_pages)) all_month_pages[[i]] &lt;- getPage(monthLinks[i]) month_final &lt;- do.call(&#39;rbind&#39;, all_month_pages) write.table(month_final, &#39;gaon_month.txt&#39;, row.names = FALSE) . 필요한 패키지를 로딩중입니다: pacman Warning message: &#34;패키지 &#39;pacman&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0. Using compatibility `.name_repair`. This warning is displayed once every 8 hours. Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.&#34; . head(week_final) . A tibble: 6 × 9 year_weekrankingchange_grpchange_valtitleartistgaon_indexproductiondistribution . &lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt; . 202221 | 1 | &lt;span style=white-space:pre-wrap&gt;NA &lt;/span&gt; | - | That That (prod. &amp; feat. SUGA of BTS) | &lt;span style=white-space:pre-wrap&gt;싸이 (Psy) &lt;/span&gt; | 31776501 | &lt;span style=white-space:pre-wrap&gt;피네이션 &lt;/span&gt; | &lt;span style=white-space:pre-wrap&gt;Dreamus &lt;/span&gt; | . 202221 | 2 | up | 2 | LOVE DIVE | IVE (아이브) | 27807024 | 스타쉽엔터테인먼트 | Kakao Entertainment | . 202221 | 3 | up | 2 | TOMBOY | (여자)아이들 | 27241781 | 큐브엔터테인먼트 | Kakao Entertainment | . 202221 | 4 | down | 2 | 봄여름가을겨울 (Still Life) | BIGBANG (빅뱅) | 25590419 | YG Entertainment | YG PLUS | . 202221 | 5 | up | 1 | 사랑인가 봐 | 멜로망스(Melomance) | 22846960 | 플렉스엠 | Kakao Entertainment | . 202221 | 6 | down | 3 | 다시 만날 수 있을까 | 임영웅 | 19074593 | 물고기뮤직 | Dreamus | . head(month_final) . A tibble: 6 × 9 year_monthrankingchange_grpchange_valtitleartistgaon_indexproductiondistribution . &lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt; . 202204 | 1 | new | new | 봄여름가을겨울 (Still Life) | BIGBANG (빅뱅) | 168901052 | YG Entertainment | YG PLUS | . 202204 | 2 | up | 1 | TOMBOY | (여자)아이들 | 133304108 | 큐브엔터테인먼트 | Kakao Entertainment | . 202204 | 3 | up | 23 | Feel My Rhythm | 레드벨벳(Red Velvet) | 111957588 | SM Entertainment | Dreamus | . 202204 | 4 | new | new | LOVE DIVE | IVE (아이브) | 105286003 | 스타쉽엔터테인먼트 | Kakao Entertainment | . 202204 | 5 | up | 3 | 사랑인가 봐 | 멜로망스(Melomance) | 100850288 | 플렉스엠 | Kakao Entertainment | . 202204 | 6 | down | 4 | GANADARA (Feat. 아이유) | 박재범 | 96954973 | MORE VISION | Kakao Entertainment | . Analysis . 미완성 | .",
            "url": "https://stahangryum.github.io/Woo/crawling/r/2022/05/29/GAON.html",
            "relUrl": "/crawling/r/2022/05/29/GAON.html",
            "date": " • May 29, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Santander Customer Satisfaction",
            "content": "import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib . cust_df = pd.read_csv(&#39;dataset/santander/train_santander.csv&#39;, encoding = &#39;latin-1&#39;) cust_df.head(3) . ID var3 var15 imp_ent_var16_ult1 imp_op_var39_comer_ult1 imp_op_var39_comer_ult3 imp_op_var40_comer_ult1 imp_op_var40_comer_ult3 imp_op_var40_efect_ult1 imp_op_var40_efect_ult3 ... saldo_medio_var33_hace2 saldo_medio_var33_hace3 saldo_medio_var33_ult1 saldo_medio_var33_ult3 saldo_medio_var44_hace2 saldo_medio_var44_hace3 saldo_medio_var44_ult1 saldo_medio_var44_ult3 var38 TARGET . 0 1 | 2 | 23 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 39205.17 | 0 | . 1 3 | 2 | 34 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 49278.03 | 0 | . 2 4 | 2 | 23 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 67333.77 | 0 | . 3 rows × 371 columns . cust_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 76020 entries, 0 to 76019 Columns: 371 entries, ID to TARGET dtypes: float64(111), int64(260) memory usage: 215.2 MB . cust_df.shape . (76020, 371) . print(cust_df[&#39;TARGET&#39;].value_counts()) unsatisfied_cnt = cust_df[cust_df[&#39;TARGET&#39;] == 1].TARGET.count() total_cnt = cust_df.TARGET.count() print(&#39;unsatisfied 비율 :&#39;, np.round(unsatisfied_cnt / total_cnt, 3)) . 0 73012 1 3008 Name: TARGET, dtype: int64 unsatisfied 비율 : 0.04 . 불만족 비율은 전체의 4%에 불과하다. | . cust_df.describe() . ID var3 var15 imp_ent_var16_ult1 imp_op_var39_comer_ult1 imp_op_var39_comer_ult3 imp_op_var40_comer_ult1 imp_op_var40_comer_ult3 imp_op_var40_efect_ult1 imp_op_var40_efect_ult3 ... saldo_medio_var33_hace2 saldo_medio_var33_hace3 saldo_medio_var33_ult1 saldo_medio_var33_ult3 saldo_medio_var44_hace2 saldo_medio_var44_hace3 saldo_medio_var44_ult1 saldo_medio_var44_ult3 var38 TARGET . count 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | ... | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 76020.000000 | 7.602000e+04 | 76020.000000 | . mean 75964.050723 | -1523.199277 | 33.212865 | 86.208265 | 72.363067 | 119.529632 | 3.559130 | 6.472698 | 0.412946 | 0.567352 | ... | 7.935824 | 1.365146 | 12.215580 | 8.784074 | 31.505324 | 1.858575 | 76.026165 | 56.614351 | 1.172358e+05 | 0.039569 | . std 43781.947379 | 39033.462364 | 12.956486 | 1614.757313 | 339.315831 | 546.266294 | 93.155749 | 153.737066 | 30.604864 | 36.513513 | ... | 455.887218 | 113.959637 | 783.207399 | 538.439211 | 2013.125393 | 147.786584 | 4040.337842 | 2852.579397 | 1.826646e+05 | 0.194945 | . min 1.000000 | -999999.000000 | 5.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 5.163750e+03 | 0.000000 | . 25% 38104.750000 | 2.000000 | 23.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 6.787061e+04 | 0.000000 | . 50% 76043.000000 | 2.000000 | 28.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.064092e+05 | 0.000000 | . 75% 113748.750000 | 2.000000 | 40.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | ... | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.187563e+05 | 0.000000 | . max 151838.000000 | 238.000000 | 105.000000 | 210000.000000 | 12888.030000 | 21024.810000 | 8237.820000 | 11073.570000 | 6600.000000 | 6600.000000 | ... | 50003.880000 | 20385.720000 | 138831.630000 | 91778.730000 | 438329.220000 | 24650.010000 | 681462.900000 | 397884.300000 | 2.203474e+07 | 1.000000 | . 8 rows × 371 columns . cust_df[&#39;var3&#39;].replace(-999999, 2, inplace = True) cust_df.drop(&#39;ID&#39;, axis = 1, inplace = True) X_features = cust_df.iloc[:, :-1] y_labels = cust_df.iloc[:, -1] print(&#39;피쳐 데이터 shape :&#39;, X_features.shape) . 피쳐 데이터 shape : (76020, 369) . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size = 0.2, random_state = 0) train_cnt = y_train.count() test_cnt = y_test.count() print(&#39;학습 세트 Shape : {0}, 테스트 세트 Shape : {1}&#39;.format(X_train.shape, X_test.shape)) print(&#39; 학습 세트 레이블 값 분포 비율&#39;) print(y_train.value_counts()/train_cnt) print(&#39; n 테스트 세트 레이블 값 분포 비율&#39;) print(y_test.value_counts()/test_cnt) . 학습 세트 Shape : (60816, 369), 테스트 세트 Shape : (15204, 369) 학습 세트 레이블 값 분포 비율 0 0.960964 1 0.039036 Name: TARGET, dtype: float64 테스트 세트 레이블 값 분포 비율 0 0.9583 1 0.0417 Name: TARGET, dtype: float64 . X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state = 0) . from xgboost import XGBClassifier from sklearn.metrics import roc_auc_score xgb_clf = XGBClassifier(n_estimators = 500, random_state = 156) # 성능 평가 지표를 auc로, 조기 중단 파라미터는 100으로 설정하고 학습 수행 xgb_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric = &#39;logloss&#39;, eval_set = [(X_train, y_train), (X_test, y_test)]) xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1], average =&#39;macro&#39;) print(&#39;ROC AUC :&#39;, xgb_roc_score) . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-logloss:0.47251 validation_1-logloss:0.47431 [1] validation_0-logloss:0.35180 validation_1-logloss:0.35486 [2] validation_0-logloss:0.27740 validation_1-logloss:0.28183 [3] validation_0-logloss:0.22891 validation_1-logloss:0.23460 [4] validation_0-logloss:0.19656 validation_1-logloss:0.20328 [5] validation_0-logloss:0.17445 validation_1-logloss:0.18210 [6] validation_0-logloss:0.15934 validation_1-logloss:0.16792 [7] validation_0-logloss:0.14870 validation_1-logloss:0.15822 [8] validation_0-logloss:0.14125 validation_1-logloss:0.15182 [9] validation_0-logloss:0.13608 validation_1-logloss:0.14740 [10] validation_0-logloss:0.13231 validation_1-logloss:0.14457 [11] validation_0-logloss:0.12940 validation_1-logloss:0.14263 [12] validation_0-logloss:0.12715 validation_1-logloss:0.14133 [13] validation_0-logloss:0.12546 validation_1-logloss:0.14054 [14] validation_0-logloss:0.12434 validation_1-logloss:0.14000 [15] validation_0-logloss:0.12319 validation_1-logloss:0.13974 [16] validation_0-logloss:0.12237 validation_1-logloss:0.13947 [17] validation_0-logloss:0.12181 validation_1-logloss:0.13941 [18] validation_0-logloss:0.12139 validation_1-logloss:0.13942 [19] validation_0-logloss:0.12091 validation_1-logloss:0.13939 [20] validation_0-logloss:0.12018 validation_1-logloss:0.13936 [21] validation_0-logloss:0.11999 validation_1-logloss:0.13934 [22] validation_0-logloss:0.11947 validation_1-logloss:0.13933 [23] validation_0-logloss:0.11929 validation_1-logloss:0.13930 [24] validation_0-logloss:0.11876 validation_1-logloss:0.13931 [25] validation_0-logloss:0.11847 validation_1-logloss:0.13924 [26] validation_0-logloss:0.11811 validation_1-logloss:0.13900 [27] validation_0-logloss:0.11783 validation_1-logloss:0.13903 [28] validation_0-logloss:0.11766 validation_1-logloss:0.13908 [29] validation_0-logloss:0.11697 validation_1-logloss:0.13931 [30] validation_0-logloss:0.11663 validation_1-logloss:0.13943 [31] validation_0-logloss:0.11587 validation_1-logloss:0.13948 [32] validation_0-logloss:0.11521 validation_1-logloss:0.13967 [33] validation_0-logloss:0.11460 validation_1-logloss:0.13973 [34] validation_0-logloss:0.11446 validation_1-logloss:0.13971 [35] validation_0-logloss:0.11440 validation_1-logloss:0.13974 [36] validation_0-logloss:0.11385 validation_1-logloss:0.13981 [37] validation_0-logloss:0.11368 validation_1-logloss:0.13986 [38] validation_0-logloss:0.11361 validation_1-logloss:0.13986 [39] validation_0-logloss:0.11351 validation_1-logloss:0.13986 [40] validation_0-logloss:0.11331 validation_1-logloss:0.13998 [41] validation_0-logloss:0.11291 validation_1-logloss:0.14007 [42] validation_0-logloss:0.11281 validation_1-logloss:0.14013 [43] validation_0-logloss:0.11269 validation_1-logloss:0.14011 [44] validation_0-logloss:0.11255 validation_1-logloss:0.14015 [45] validation_0-logloss:0.11250 validation_1-logloss:0.14011 [46] validation_0-logloss:0.11246 validation_1-logloss:0.14014 [47] validation_0-logloss:0.11238 validation_1-logloss:0.14017 [48] validation_0-logloss:0.11220 validation_1-logloss:0.14014 [49] validation_0-logloss:0.11200 validation_1-logloss:0.14022 [50] validation_0-logloss:0.11190 validation_1-logloss:0.14028 [51] validation_0-logloss:0.11108 validation_1-logloss:0.14027 [52] validation_0-logloss:0.11041 validation_1-logloss:0.14031 [53] validation_0-logloss:0.10983 validation_1-logloss:0.14020 [54] validation_0-logloss:0.10961 validation_1-logloss:0.14015 [55] validation_0-logloss:0.10949 validation_1-logloss:0.14020 [56] validation_0-logloss:0.10889 validation_1-logloss:0.14026 [57] validation_0-logloss:0.10875 validation_1-logloss:0.14030 [58] validation_0-logloss:0.10831 validation_1-logloss:0.14025 [59] validation_0-logloss:0.10778 validation_1-logloss:0.14045 [60] validation_0-logloss:0.10756 validation_1-logloss:0.14051 [61] validation_0-logloss:0.10745 validation_1-logloss:0.14064 [62] validation_0-logloss:0.10702 validation_1-logloss:0.14070 [63] validation_0-logloss:0.10694 validation_1-logloss:0.14072 [64] validation_0-logloss:0.10689 validation_1-logloss:0.14072 [65] validation_0-logloss:0.10683 validation_1-logloss:0.14070 [66] validation_0-logloss:0.10654 validation_1-logloss:0.14073 [67] validation_0-logloss:0.10648 validation_1-logloss:0.14073 [68] validation_0-logloss:0.10628 validation_1-logloss:0.14087 [69] validation_0-logloss:0.10622 validation_1-logloss:0.14086 [70] validation_0-logloss:0.10616 validation_1-logloss:0.14091 [71] validation_0-logloss:0.10609 validation_1-logloss:0.14090 [72] validation_0-logloss:0.10581 validation_1-logloss:0.14109 [73] validation_0-logloss:0.10575 validation_1-logloss:0.14106 [74] validation_0-logloss:0.10562 validation_1-logloss:0.14110 [75] validation_0-logloss:0.10557 validation_1-logloss:0.14119 [76] validation_0-logloss:0.10490 validation_1-logloss:0.14114 [77] validation_0-logloss:0.10436 validation_1-logloss:0.14136 [78] validation_0-logloss:0.10396 validation_1-logloss:0.14137 [79] validation_0-logloss:0.10374 validation_1-logloss:0.14146 [80] validation_0-logloss:0.10347 validation_1-logloss:0.14155 [81] validation_0-logloss:0.10301 validation_1-logloss:0.14175 [82] validation_0-logloss:0.10283 validation_1-logloss:0.14162 [83] validation_0-logloss:0.10250 validation_1-logloss:0.14169 [84] validation_0-logloss:0.10239 validation_1-logloss:0.14176 [85] validation_0-logloss:0.10214 validation_1-logloss:0.14184 [86] validation_0-logloss:0.10211 validation_1-logloss:0.14185 [87] validation_0-logloss:0.10206 validation_1-logloss:0.14185 [88] validation_0-logloss:0.10188 validation_1-logloss:0.14194 [89] validation_0-logloss:0.10178 validation_1-logloss:0.14200 [90] validation_0-logloss:0.10174 validation_1-logloss:0.14204 [91] validation_0-logloss:0.10162 validation_1-logloss:0.14209 [92] validation_0-logloss:0.10159 validation_1-logloss:0.14209 [93] validation_0-logloss:0.10122 validation_1-logloss:0.14221 [94] validation_0-logloss:0.10118 validation_1-logloss:0.14222 [95] validation_0-logloss:0.10113 validation_1-logloss:0.14231 [96] validation_0-logloss:0.10082 validation_1-logloss:0.14250 [97] validation_0-logloss:0.10077 validation_1-logloss:0.14253 [98] validation_0-logloss:0.10035 validation_1-logloss:0.14265 [99] validation_0-logloss:0.09991 validation_1-logloss:0.14271 [100] validation_0-logloss:0.09964 validation_1-logloss:0.14277 [101] validation_0-logloss:0.09931 validation_1-logloss:0.14291 [102] validation_0-logloss:0.09928 validation_1-logloss:0.14291 [103] validation_0-logloss:0.09885 validation_1-logloss:0.14307 [104] validation_0-logloss:0.09873 validation_1-logloss:0.14323 [105] validation_0-logloss:0.09853 validation_1-logloss:0.14331 [106] validation_0-logloss:0.09799 validation_1-logloss:0.14359 [107] validation_0-logloss:0.09796 validation_1-logloss:0.14366 [108] validation_0-logloss:0.09782 validation_1-logloss:0.14385 [109] validation_0-logloss:0.09776 validation_1-logloss:0.14388 [110] validation_0-logloss:0.09756 validation_1-logloss:0.14400 [111] validation_0-logloss:0.09752 validation_1-logloss:0.14398 [112] validation_0-logloss:0.09728 validation_1-logloss:0.14405 [113] validation_0-logloss:0.09701 validation_1-logloss:0.14429 [114] validation_0-logloss:0.09689 validation_1-logloss:0.14426 [115] validation_0-logloss:0.09668 validation_1-logloss:0.14434 [116] validation_0-logloss:0.09663 validation_1-logloss:0.14439 [117] validation_0-logloss:0.09649 validation_1-logloss:0.14446 [118] validation_0-logloss:0.09641 validation_1-logloss:0.14450 [119] validation_0-logloss:0.09613 validation_1-logloss:0.14447 [120] validation_0-logloss:0.09606 validation_1-logloss:0.14455 [121] validation_0-logloss:0.09593 validation_1-logloss:0.14451 [122] validation_0-logloss:0.09566 validation_1-logloss:0.14469 [123] validation_0-logloss:0.09547 validation_1-logloss:0.14479 [124] validation_0-logloss:0.09542 validation_1-logloss:0.14476 [125] validation_0-logloss:0.09524 validation_1-logloss:0.14471 ROC AUC : 0.8410117370942843 . from sklearn.model_selection import GridSearchCV # 하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 100으로 감소 xgb_clf = XGBClassifier(n_estimators = 100) params = {&#39;max_depth&#39;:[5,7], &#39;min_child_weight&#39;:[1,3], &#39;colsample_bytree&#39;:[0.5, 0.75] } gridcv = GridSearchCV(xgb_clf, param_grid=params, cv = 3) # 2*2*2*3 gridcv.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric = &#39;auc&#39;, eval_set=[(X_tr, y_tr), (X_val, y_val)]) print(&#39;GridSearchCV 최적 파라미터:&#39;, gridcv.best_params_) xgb_rod_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:, 1], average = &#39;macro&#39;) print(&#39;ROC AUC :&#39;, xgb_roc_score) . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.79161 validation_1-auc:0.79321 [1] validation_0-auc:0.81865 validation_1-auc:0.81375 [2] validation_0-auc:0.82586 validation_1-auc:0.81846 [3] validation_0-auc:0.82789 validation_1-auc:0.82226 [4] validation_0-auc:0.83249 validation_1-auc:0.82677 [5] validation_0-auc:0.83477 validation_1-auc:0.83225 [6] validation_0-auc:0.83340 validation_1-auc:0.82654 [7] validation_0-auc:0.84223 validation_1-auc:0.83486 [8] validation_0-auc:0.84586 validation_1-auc:0.83682 [9] validation_0-auc:0.84557 validation_1-auc:0.83472 [10] validation_0-auc:0.84423 validation_1-auc:0.83181 [11] validation_0-auc:0.84428 validation_1-auc:0.82920 [12] validation_0-auc:0.85176 validation_1-auc:0.83433 [13] validation_0-auc:0.85540 validation_1-auc:0.83565 [14] validation_0-auc:0.85718 validation_1-auc:0.83696 [15] validation_0-auc:0.85851 validation_1-auc:0.83561 [16] validation_0-auc:0.85964 validation_1-auc:0.83578 [17] validation_0-auc:0.86091 validation_1-auc:0.83570 [18] validation_0-auc:0.86188 validation_1-auc:0.83595 [19] validation_0-auc:0.86249 validation_1-auc:0.83552 [20] validation_0-auc:0.86298 validation_1-auc:0.83452 [21] validation_0-auc:0.86375 validation_1-auc:0.83437 [22] validation_0-auc:0.86440 validation_1-auc:0.83516 [23] validation_0-auc:0.86554 validation_1-auc:0.83470 [24] validation_0-auc:0.86601 validation_1-auc:0.83492 [25] validation_0-auc:0.86700 validation_1-auc:0.83510 [26] validation_0-auc:0.86770 validation_1-auc:0.83412 [27] validation_0-auc:0.86852 validation_1-auc:0.83394 [28] validation_0-auc:0.86898 validation_1-auc:0.83441 [29] validation_0-auc:0.86914 validation_1-auc:0.83440 [30] validation_0-auc:0.86953 validation_1-auc:0.83380 [31] validation_0-auc:0.87051 validation_1-auc:0.83346 [32] validation_0-auc:0.87085 validation_1-auc:0.83334 [33] validation_0-auc:0.87112 validation_1-auc:0.83313 [34] validation_0-auc:0.87161 validation_1-auc:0.83383 [35] validation_0-auc:0.87173 validation_1-auc:0.83376 [36] validation_0-auc:0.87260 validation_1-auc:0.83340 [37] validation_0-auc:0.87310 validation_1-auc:0.83344 [38] validation_0-auc:0.87322 validation_1-auc:0.83343 [39] validation_0-auc:0.87339 validation_1-auc:0.83370 [40] validation_0-auc:0.87351 validation_1-auc:0.83373 [41] validation_0-auc:0.87411 validation_1-auc:0.83358 [42] validation_0-auc:0.87433 validation_1-auc:0.83325 [43] validation_0-auc:0.87432 validation_1-auc:0.83319 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.80013 validation_1-auc:0.79685 [1] validation_0-auc:0.82084 validation_1-auc:0.81574 [2] validation_0-auc:0.82744 validation_1-auc:0.82189 [3] validation_0-auc:0.83029 validation_1-auc:0.82317 [4] validation_0-auc:0.83578 validation_1-auc:0.82564 [5] validation_0-auc:0.83777 validation_1-auc:0.83385 [6] validation_0-auc:0.83742 validation_1-auc:0.83162 [7] validation_0-auc:0.84373 validation_1-auc:0.83436 [8] validation_0-auc:0.84836 validation_1-auc:0.83664 [9] validation_0-auc:0.84790 validation_1-auc:0.83583 [10] validation_0-auc:0.84717 validation_1-auc:0.83268 [11] validation_0-auc:0.84654 validation_1-auc:0.83066 [12] validation_0-auc:0.85377 validation_1-auc:0.83579 [13] validation_0-auc:0.85800 validation_1-auc:0.83859 [14] validation_0-auc:0.85962 validation_1-auc:0.83984 [15] validation_0-auc:0.86143 validation_1-auc:0.84003 [16] validation_0-auc:0.86269 validation_1-auc:0.84049 [17] validation_0-auc:0.86399 validation_1-auc:0.84009 [18] validation_0-auc:0.86474 validation_1-auc:0.84034 [19] validation_0-auc:0.86662 validation_1-auc:0.84138 [20] validation_0-auc:0.86730 validation_1-auc:0.84100 [21] validation_0-auc:0.86821 validation_1-auc:0.84058 [22] validation_0-auc:0.86942 validation_1-auc:0.84128 [23] validation_0-auc:0.86992 validation_1-auc:0.84122 [24] validation_0-auc:0.87035 validation_1-auc:0.84116 [25] validation_0-auc:0.87091 validation_1-auc:0.84045 [26] validation_0-auc:0.87139 validation_1-auc:0.83974 [27] validation_0-auc:0.87296 validation_1-auc:0.83926 [28] validation_0-auc:0.87307 validation_1-auc:0.83943 [29] validation_0-auc:0.87330 validation_1-auc:0.84017 [30] validation_0-auc:0.87443 validation_1-auc:0.83949 [31] validation_0-auc:0.87467 validation_1-auc:0.83936 [32] validation_0-auc:0.87513 validation_1-auc:0.83943 [33] validation_0-auc:0.87519 validation_1-auc:0.83951 [34] validation_0-auc:0.87542 validation_1-auc:0.83953 [35] validation_0-auc:0.87552 validation_1-auc:0.83946 [36] validation_0-auc:0.87582 validation_1-auc:0.83936 [37] validation_0-auc:0.87604 validation_1-auc:0.83919 [38] validation_0-auc:0.87622 validation_1-auc:0.83874 [39] validation_0-auc:0.87670 validation_1-auc:0.83844 [40] validation_0-auc:0.87678 validation_1-auc:0.83859 [41] validation_0-auc:0.87711 validation_1-auc:0.83830 [42] validation_0-auc:0.87738 validation_1-auc:0.83823 [43] validation_0-auc:0.87752 validation_1-auc:0.83796 [44] validation_0-auc:0.87777 validation_1-auc:0.83765 [45] validation_0-auc:0.87785 validation_1-auc:0.83786 [46] validation_0-auc:0.87802 validation_1-auc:0.83761 [47] validation_0-auc:0.87840 validation_1-auc:0.83698 [48] validation_0-auc:0.87868 validation_1-auc:0.83699 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.80039 validation_1-auc:0.80013 [1] validation_0-auc:0.82111 validation_1-auc:0.82026 [2] validation_0-auc:0.82749 validation_1-auc:0.82627 [3] validation_0-auc:0.83124 validation_1-auc:0.82830 [4] validation_0-auc:0.83475 validation_1-auc:0.82881 [5] validation_0-auc:0.83676 validation_1-auc:0.83385 [6] validation_0-auc:0.83648 validation_1-auc:0.83085 [7] validation_0-auc:0.84336 validation_1-auc:0.83472 [8] validation_0-auc:0.84624 validation_1-auc:0.83404 [9] validation_0-auc:0.84541 validation_1-auc:0.83287 [10] validation_0-auc:0.84554 validation_1-auc:0.83039 [11] validation_0-auc:0.84525 validation_1-auc:0.82995 [12] validation_0-auc:0.85144 validation_1-auc:0.83489 [13] validation_0-auc:0.85525 validation_1-auc:0.83803 [14] validation_0-auc:0.85745 validation_1-auc:0.84145 [15] validation_0-auc:0.85817 validation_1-auc:0.84082 [16] validation_0-auc:0.86006 validation_1-auc:0.84076 [17] validation_0-auc:0.86127 validation_1-auc:0.84139 [18] validation_0-auc:0.86194 validation_1-auc:0.84041 [19] validation_0-auc:0.86337 validation_1-auc:0.84100 [20] validation_0-auc:0.86386 validation_1-auc:0.84145 [21] validation_0-auc:0.86550 validation_1-auc:0.84030 [22] validation_0-auc:0.86690 validation_1-auc:0.84072 [23] validation_0-auc:0.86765 validation_1-auc:0.84077 [24] validation_0-auc:0.86827 validation_1-auc:0.84136 [25] validation_0-auc:0.86939 validation_1-auc:0.84120 [26] validation_0-auc:0.87045 validation_1-auc:0.84098 [27] validation_0-auc:0.87062 validation_1-auc:0.84148 [28] validation_0-auc:0.87072 validation_1-auc:0.84120 [29] validation_0-auc:0.87113 validation_1-auc:0.84147 [30] validation_0-auc:0.87115 validation_1-auc:0.84181 [31] validation_0-auc:0.87145 validation_1-auc:0.84172 [32] validation_0-auc:0.87226 validation_1-auc:0.84100 [33] validation_0-auc:0.87242 validation_1-auc:0.84149 [34] validation_0-auc:0.87255 validation_1-auc:0.84120 [35] validation_0-auc:0.87297 validation_1-auc:0.84095 [36] validation_0-auc:0.87348 validation_1-auc:0.84051 [37] validation_0-auc:0.87395 validation_1-auc:0.84084 [38] validation_0-auc:0.87433 validation_1-auc:0.84055 [39] validation_0-auc:0.87448 validation_1-auc:0.84048 [40] validation_0-auc:0.87465 validation_1-auc:0.84042 [41] validation_0-auc:0.87486 validation_1-auc:0.84034 [42] validation_0-auc:0.87518 validation_1-auc:0.84021 [43] validation_0-auc:0.87525 validation_1-auc:0.84022 [44] validation_0-auc:0.87595 validation_1-auc:0.83967 [45] validation_0-auc:0.87629 validation_1-auc:0.84004 [46] validation_0-auc:0.87704 validation_1-auc:0.83966 [47] validation_0-auc:0.87746 validation_1-auc:0.83963 [48] validation_0-auc:0.87774 validation_1-auc:0.83931 [49] validation_0-auc:0.87784 validation_1-auc:0.83925 [50] validation_0-auc:0.87826 validation_1-auc:0.83935 [51] validation_0-auc:0.87861 validation_1-auc:0.83920 [52] validation_0-auc:0.87950 validation_1-auc:0.83895 [53] validation_0-auc:0.88024 validation_1-auc:0.83876 [54] validation_0-auc:0.88117 validation_1-auc:0.83840 [55] validation_0-auc:0.88126 validation_1-auc:0.83834 [56] validation_0-auc:0.88145 validation_1-auc:0.83873 [57] validation_0-auc:0.88157 validation_1-auc:0.83860 [58] validation_0-auc:0.88178 validation_1-auc:0.83810 [59] validation_0-auc:0.88186 validation_1-auc:0.83774 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.79210 validation_1-auc:0.79292 [1] validation_0-auc:0.81759 validation_1-auc:0.81404 [2] validation_0-auc:0.82567 validation_1-auc:0.81864 [3] validation_0-auc:0.82819 validation_1-auc:0.82244 [4] validation_0-auc:0.83233 validation_1-auc:0.82618 [5] validation_0-auc:0.83480 validation_1-auc:0.83163 [6] validation_0-auc:0.83342 validation_1-auc:0.82840 [7] validation_0-auc:0.84265 validation_1-auc:0.83512 [8] validation_0-auc:0.84614 validation_1-auc:0.83742 [9] validation_0-auc:0.84573 validation_1-auc:0.83475 [10] validation_0-auc:0.84426 validation_1-auc:0.83066 [11] validation_0-auc:0.84358 validation_1-auc:0.82937 [12] validation_0-auc:0.85089 validation_1-auc:0.83491 [13] validation_0-auc:0.85457 validation_1-auc:0.83785 [14] validation_0-auc:0.85645 validation_1-auc:0.83894 [15] validation_0-auc:0.85744 validation_1-auc:0.83784 [16] validation_0-auc:0.85870 validation_1-auc:0.83899 [17] validation_0-auc:0.86002 validation_1-auc:0.83854 [18] validation_0-auc:0.86091 validation_1-auc:0.83860 [19] validation_0-auc:0.86154 validation_1-auc:0.83818 [20] validation_0-auc:0.86189 validation_1-auc:0.83772 [21] validation_0-auc:0.86295 validation_1-auc:0.83703 [22] validation_0-auc:0.86334 validation_1-auc:0.83721 [23] validation_0-auc:0.86402 validation_1-auc:0.83581 [24] validation_0-auc:0.86456 validation_1-auc:0.83557 [25] validation_0-auc:0.86494 validation_1-auc:0.83534 [26] validation_0-auc:0.86516 validation_1-auc:0.83481 [27] validation_0-auc:0.86660 validation_1-auc:0.83557 [28] validation_0-auc:0.86784 validation_1-auc:0.83546 [29] validation_0-auc:0.86793 validation_1-auc:0.83545 [30] validation_0-auc:0.86840 validation_1-auc:0.83496 [31] validation_0-auc:0.86867 validation_1-auc:0.83481 [32] validation_0-auc:0.86884 validation_1-auc:0.83472 [33] validation_0-auc:0.86900 validation_1-auc:0.83482 [34] validation_0-auc:0.86907 validation_1-auc:0.83423 [35] validation_0-auc:0.86981 validation_1-auc:0.83350 [36] validation_0-auc:0.86996 validation_1-auc:0.83334 [37] validation_0-auc:0.87004 validation_1-auc:0.83365 [38] validation_0-auc:0.87022 validation_1-auc:0.83384 [39] validation_0-auc:0.87078 validation_1-auc:0.83373 [40] validation_0-auc:0.87094 validation_1-auc:0.83373 [41] validation_0-auc:0.87109 validation_1-auc:0.83359 [42] validation_0-auc:0.87173 validation_1-auc:0.83365 [43] validation_0-auc:0.87264 validation_1-auc:0.83386 [44] validation_0-auc:0.87336 validation_1-auc:0.83319 [45] validation_0-auc:0.87361 validation_1-auc:0.83318 [46] validation_0-auc:0.87406 validation_1-auc:0.83227 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.79931 validation_1-auc:0.79594 [1] validation_0-auc:0.81987 validation_1-auc:0.81503 [2] validation_0-auc:0.82734 validation_1-auc:0.82126 [3] validation_0-auc:0.83110 validation_1-auc:0.82302 [4] validation_0-auc:0.83608 validation_1-auc:0.82494 [5] validation_0-auc:0.83914 validation_1-auc:0.83100 [6] validation_0-auc:0.83828 validation_1-auc:0.82999 [7] validation_0-auc:0.84425 validation_1-auc:0.83439 [8] validation_0-auc:0.84749 validation_1-auc:0.83609 [9] validation_0-auc:0.84727 validation_1-auc:0.83597 [10] validation_0-auc:0.84703 validation_1-auc:0.83250 [11] validation_0-auc:0.84664 validation_1-auc:0.83237 [12] validation_0-auc:0.85343 validation_1-auc:0.83713 [13] validation_0-auc:0.85671 validation_1-auc:0.83887 [14] validation_0-auc:0.85824 validation_1-auc:0.83919 [15] validation_0-auc:0.85962 validation_1-auc:0.83905 [16] validation_0-auc:0.86089 validation_1-auc:0.84031 [17] validation_0-auc:0.86216 validation_1-auc:0.84051 [18] validation_0-auc:0.86264 validation_1-auc:0.84051 [19] validation_0-auc:0.86341 validation_1-auc:0.84030 [20] validation_0-auc:0.86379 validation_1-auc:0.83988 [21] validation_0-auc:0.86413 validation_1-auc:0.84020 [22] validation_0-auc:0.86513 validation_1-auc:0.84033 [23] validation_0-auc:0.86584 validation_1-auc:0.84016 [24] validation_0-auc:0.86638 validation_1-auc:0.84016 [25] validation_0-auc:0.86691 validation_1-auc:0.83991 [26] validation_0-auc:0.86798 validation_1-auc:0.83979 [27] validation_0-auc:0.86869 validation_1-auc:0.83952 [28] validation_0-auc:0.86881 validation_1-auc:0.83942 [29] validation_0-auc:0.86908 validation_1-auc:0.83912 [30] validation_0-auc:0.86934 validation_1-auc:0.83907 [31] validation_0-auc:0.86942 validation_1-auc:0.83896 [32] validation_0-auc:0.87000 validation_1-auc:0.83860 [33] validation_0-auc:0.87016 validation_1-auc:0.83878 [34] validation_0-auc:0.87050 validation_1-auc:0.83830 [35] validation_0-auc:0.87069 validation_1-auc:0.83825 [36] validation_0-auc:0.87118 validation_1-auc:0.83880 [37] validation_0-auc:0.87126 validation_1-auc:0.83883 [38] validation_0-auc:0.87138 validation_1-auc:0.83882 [39] validation_0-auc:0.87243 validation_1-auc:0.83833 [40] validation_0-auc:0.87267 validation_1-auc:0.83813 [41] validation_0-auc:0.87282 validation_1-auc:0.83811 [42] validation_0-auc:0.87356 validation_1-auc:0.83806 [43] validation_0-auc:0.87372 validation_1-auc:0.83815 [44] validation_0-auc:0.87384 validation_1-auc:0.83807 [45] validation_0-auc:0.87395 validation_1-auc:0.83813 [46] validation_0-auc:0.87450 validation_1-auc:0.83757 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.80248 validation_1-auc:0.80001 [1] validation_0-auc:0.82249 validation_1-auc:0.81765 [2] validation_0-auc:0.82833 validation_1-auc:0.82524 [3] validation_0-auc:0.83371 validation_1-auc:0.82814 [4] validation_0-auc:0.83653 validation_1-auc:0.82856 [5] validation_0-auc:0.83838 validation_1-auc:0.83345 [6] validation_0-auc:0.83823 validation_1-auc:0.83165 [7] validation_0-auc:0.84386 validation_1-auc:0.83505 [8] validation_0-auc:0.84688 validation_1-auc:0.83507 [9] validation_0-auc:0.84634 validation_1-auc:0.83483 [10] validation_0-auc:0.84564 validation_1-auc:0.83324 [11] validation_0-auc:0.84501 validation_1-auc:0.83283 [12] validation_0-auc:0.85011 validation_1-auc:0.83693 [13] validation_0-auc:0.85299 validation_1-auc:0.83995 [14] validation_0-auc:0.85523 validation_1-auc:0.84250 [15] validation_0-auc:0.85608 validation_1-auc:0.84183 [16] validation_0-auc:0.85748 validation_1-auc:0.84319 [17] validation_0-auc:0.85895 validation_1-auc:0.84363 [18] validation_0-auc:0.85944 validation_1-auc:0.84311 [19] validation_0-auc:0.86102 validation_1-auc:0.84368 [20] validation_0-auc:0.86122 validation_1-auc:0.84367 [21] validation_0-auc:0.86196 validation_1-auc:0.84403 [22] validation_0-auc:0.86291 validation_1-auc:0.84498 [23] validation_0-auc:0.86385 validation_1-auc:0.84460 [24] validation_0-auc:0.86452 validation_1-auc:0.84460 [25] validation_0-auc:0.86534 validation_1-auc:0.84480 [26] validation_0-auc:0.86584 validation_1-auc:0.84441 [27] validation_0-auc:0.86653 validation_1-auc:0.84401 [28] validation_0-auc:0.86697 validation_1-auc:0.84422 [29] validation_0-auc:0.86770 validation_1-auc:0.84385 [30] validation_0-auc:0.86777 validation_1-auc:0.84407 [31] validation_0-auc:0.86803 validation_1-auc:0.84395 [32] validation_0-auc:0.86826 validation_1-auc:0.84381 [33] validation_0-auc:0.86862 validation_1-auc:0.84417 [34] validation_0-auc:0.86902 validation_1-auc:0.84385 [35] validation_0-auc:0.86959 validation_1-auc:0.84369 [36] validation_0-auc:0.87020 validation_1-auc:0.84297 [37] validation_0-auc:0.87047 validation_1-auc:0.84278 [38] validation_0-auc:0.87175 validation_1-auc:0.84286 [39] validation_0-auc:0.87269 validation_1-auc:0.84224 [40] validation_0-auc:0.87289 validation_1-auc:0.84197 [41] validation_0-auc:0.87294 validation_1-auc:0.84175 [42] validation_0-auc:0.87418 validation_1-auc:0.84148 [43] validation_0-auc:0.87431 validation_1-auc:0.84121 [44] validation_0-auc:0.87441 validation_1-auc:0.84127 [45] validation_0-auc:0.87458 validation_1-auc:0.84103 [46] validation_0-auc:0.87475 validation_1-auc:0.84119 [47] validation_0-auc:0.87529 validation_1-auc:0.84128 [48] validation_0-auc:0.87554 validation_1-auc:0.84050 [49] validation_0-auc:0.87572 validation_1-auc:0.84039 [50] validation_0-auc:0.87575 validation_1-auc:0.84062 [51] validation_0-auc:0.87605 validation_1-auc:0.84105 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.80843 validation_1-auc:0.80885 [1] validation_0-auc:0.82920 validation_1-auc:0.82211 [2] validation_0-auc:0.83320 validation_1-auc:0.82400 [3] validation_0-auc:0.83625 validation_1-auc:0.82577 [4] validation_0-auc:0.84188 validation_1-auc:0.82897 [5] validation_0-auc:0.84455 validation_1-auc:0.83377 [6] validation_0-auc:0.84503 validation_1-auc:0.82916 [7] validation_0-auc:0.85319 validation_1-auc:0.83364 [8] validation_0-auc:0.85976 validation_1-auc:0.83390 [9] validation_0-auc:0.85952 validation_1-auc:0.82834 [10] validation_0-auc:0.85919 validation_1-auc:0.82378 [11] validation_0-auc:0.85956 validation_1-auc:0.82400 [12] validation_0-auc:0.86574 validation_1-auc:0.82888 [13] validation_0-auc:0.87027 validation_1-auc:0.83251 [14] validation_0-auc:0.87240 validation_1-auc:0.83311 [15] validation_0-auc:0.87365 validation_1-auc:0.83080 [16] validation_0-auc:0.87567 validation_1-auc:0.83134 [17] validation_0-auc:0.87777 validation_1-auc:0.83255 [18] validation_0-auc:0.87904 validation_1-auc:0.83149 [19] validation_0-auc:0.88037 validation_1-auc:0.83083 [20] validation_0-auc:0.88104 validation_1-auc:0.82964 [21] validation_0-auc:0.88159 validation_1-auc:0.82802 [22] validation_0-auc:0.88227 validation_1-auc:0.82806 [23] validation_0-auc:0.88255 validation_1-auc:0.82806 [24] validation_0-auc:0.88328 validation_1-auc:0.82840 [25] validation_0-auc:0.88353 validation_1-auc:0.82851 [26] validation_0-auc:0.88384 validation_1-auc:0.82899 [27] validation_0-auc:0.88509 validation_1-auc:0.82988 [28] validation_0-auc:0.88544 validation_1-auc:0.82886 [29] validation_0-auc:0.88569 validation_1-auc:0.82922 [30] validation_0-auc:0.88588 validation_1-auc:0.82962 [31] validation_0-auc:0.88682 validation_1-auc:0.82951 [32] validation_0-auc:0.88752 validation_1-auc:0.82858 [33] validation_0-auc:0.88762 validation_1-auc:0.82843 [34] validation_0-auc:0.88792 validation_1-auc:0.82804 [35] validation_0-auc:0.88865 validation_1-auc:0.82692 [36] validation_0-auc:0.88868 validation_1-auc:0.82609 [37] validation_0-auc:0.88901 validation_1-auc:0.82607 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81304 validation_1-auc:0.81746 [1] validation_0-auc:0.82882 validation_1-auc:0.82026 [2] validation_0-auc:0.83609 validation_1-auc:0.82474 [3] validation_0-auc:0.84041 validation_1-auc:0.82824 [4] validation_0-auc:0.84760 validation_1-auc:0.83130 [5] validation_0-auc:0.84938 validation_1-auc:0.83590 [6] validation_0-auc:0.85116 validation_1-auc:0.83167 [7] validation_0-auc:0.85828 validation_1-auc:0.83471 [8] validation_0-auc:0.86371 validation_1-auc:0.83640 [9] validation_0-auc:0.86365 validation_1-auc:0.83549 [10] validation_0-auc:0.86395 validation_1-auc:0.83127 [11] validation_0-auc:0.86437 validation_1-auc:0.82983 [12] validation_0-auc:0.87068 validation_1-auc:0.83421 [13] validation_0-auc:0.87545 validation_1-auc:0.83773 [14] validation_0-auc:0.87779 validation_1-auc:0.83843 [15] validation_0-auc:0.87893 validation_1-auc:0.83628 [16] validation_0-auc:0.88035 validation_1-auc:0.83878 [17] validation_0-auc:0.88227 validation_1-auc:0.83749 [18] validation_0-auc:0.88364 validation_1-auc:0.83710 [19] validation_0-auc:0.88528 validation_1-auc:0.83727 [20] validation_0-auc:0.88606 validation_1-auc:0.83670 [21] validation_0-auc:0.88672 validation_1-auc:0.83629 [22] validation_0-auc:0.88793 validation_1-auc:0.83586 [23] validation_0-auc:0.88875 validation_1-auc:0.83562 [24] validation_0-auc:0.88913 validation_1-auc:0.83589 [25] validation_0-auc:0.88932 validation_1-auc:0.83575 [26] validation_0-auc:0.89053 validation_1-auc:0.83424 [27] validation_0-auc:0.89116 validation_1-auc:0.83427 [28] validation_0-auc:0.89172 validation_1-auc:0.83384 [29] validation_0-auc:0.89244 validation_1-auc:0.83318 [30] validation_0-auc:0.89260 validation_1-auc:0.83224 [31] validation_0-auc:0.89294 validation_1-auc:0.83214 [32] validation_0-auc:0.89361 validation_1-auc:0.83111 [33] validation_0-auc:0.89396 validation_1-auc:0.83114 [34] validation_0-auc:0.89481 validation_1-auc:0.83121 [35] validation_0-auc:0.89548 validation_1-auc:0.83133 [36] validation_0-auc:0.89589 validation_1-auc:0.83039 [37] validation_0-auc:0.89614 validation_1-auc:0.83024 [38] validation_0-auc:0.89743 validation_1-auc:0.82952 [39] validation_0-auc:0.89749 validation_1-auc:0.82950 [40] validation_0-auc:0.89754 validation_1-auc:0.82932 [41] validation_0-auc:0.89813 validation_1-auc:0.82838 [42] validation_0-auc:0.89831 validation_1-auc:0.82849 [43] validation_0-auc:0.89841 validation_1-auc:0.82827 [44] validation_0-auc:0.89908 validation_1-auc:0.82824 [45] validation_0-auc:0.89919 validation_1-auc:0.82788 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81393 validation_1-auc:0.81377 [1] validation_0-auc:0.82962 validation_1-auc:0.82668 [2] validation_0-auc:0.83724 validation_1-auc:0.83017 [3] validation_0-auc:0.84075 validation_1-auc:0.83079 [4] validation_0-auc:0.84691 validation_1-auc:0.83337 [5] validation_0-auc:0.84896 validation_1-auc:0.83502 [6] validation_0-auc:0.84980 validation_1-auc:0.82858 [7] validation_0-auc:0.85918 validation_1-auc:0.83358 [8] validation_0-auc:0.86284 validation_1-auc:0.83470 [9] validation_0-auc:0.86365 validation_1-auc:0.83427 [10] validation_0-auc:0.86243 validation_1-auc:0.83264 [11] validation_0-auc:0.86248 validation_1-auc:0.83255 [12] validation_0-auc:0.86969 validation_1-auc:0.83531 [13] validation_0-auc:0.87452 validation_1-auc:0.83774 [14] validation_0-auc:0.87630 validation_1-auc:0.83936 [15] validation_0-auc:0.87826 validation_1-auc:0.83676 [16] validation_0-auc:0.87988 validation_1-auc:0.83852 [17] validation_0-auc:0.88289 validation_1-auc:0.83811 [18] validation_0-auc:0.88333 validation_1-auc:0.83735 [19] validation_0-auc:0.88506 validation_1-auc:0.83720 [20] validation_0-auc:0.88528 validation_1-auc:0.83718 [21] validation_0-auc:0.88547 validation_1-auc:0.83646 [22] validation_0-auc:0.88632 validation_1-auc:0.83706 [23] validation_0-auc:0.88770 validation_1-auc:0.83714 [24] validation_0-auc:0.88867 validation_1-auc:0.83742 [25] validation_0-auc:0.88905 validation_1-auc:0.83753 [26] validation_0-auc:0.89065 validation_1-auc:0.83634 [27] validation_0-auc:0.89158 validation_1-auc:0.83565 [28] validation_0-auc:0.89214 validation_1-auc:0.83460 [29] validation_0-auc:0.89345 validation_1-auc:0.83413 [30] validation_0-auc:0.89377 validation_1-auc:0.83373 [31] validation_0-auc:0.89392 validation_1-auc:0.83396 [32] validation_0-auc:0.89410 validation_1-auc:0.83435 [33] validation_0-auc:0.89416 validation_1-auc:0.83412 [34] validation_0-auc:0.89437 validation_1-auc:0.83386 [35] validation_0-auc:0.89513 validation_1-auc:0.83338 [36] validation_0-auc:0.89553 validation_1-auc:0.83232 [37] validation_0-auc:0.89589 validation_1-auc:0.83223 [38] validation_0-auc:0.89609 validation_1-auc:0.83222 [39] validation_0-auc:0.89636 validation_1-auc:0.83187 [40] validation_0-auc:0.89652 validation_1-auc:0.83146 [41] validation_0-auc:0.89655 validation_1-auc:0.83131 [42] validation_0-auc:0.89789 validation_1-auc:0.83068 [43] validation_0-auc:0.89792 validation_1-auc:0.83069 [44] validation_0-auc:0.89889 validation_1-auc:0.83038 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.80901 validation_1-auc:0.80653 [1] validation_0-auc:0.82713 validation_1-auc:0.82150 [2] validation_0-auc:0.83227 validation_1-auc:0.82513 [3] validation_0-auc:0.83319 validation_1-auc:0.82525 [4] validation_0-auc:0.83786 validation_1-auc:0.82805 [5] validation_0-auc:0.84104 validation_1-auc:0.82979 [6] validation_0-auc:0.84432 validation_1-auc:0.82639 [7] validation_0-auc:0.85301 validation_1-auc:0.83411 [8] validation_0-auc:0.85882 validation_1-auc:0.83754 [9] validation_0-auc:0.85838 validation_1-auc:0.83437 [10] validation_0-auc:0.85606 validation_1-auc:0.83252 [11] validation_0-auc:0.85677 validation_1-auc:0.83031 [12] validation_0-auc:0.86256 validation_1-auc:0.83311 [13] validation_0-auc:0.86712 validation_1-auc:0.83500 [14] validation_0-auc:0.86926 validation_1-auc:0.83593 [15] validation_0-auc:0.87031 validation_1-auc:0.83404 [16] validation_0-auc:0.87119 validation_1-auc:0.83472 [17] validation_0-auc:0.87276 validation_1-auc:0.83454 [18] validation_0-auc:0.87365 validation_1-auc:0.83418 [19] validation_0-auc:0.87495 validation_1-auc:0.83324 [20] validation_0-auc:0.87498 validation_1-auc:0.83267 [21] validation_0-auc:0.87527 validation_1-auc:0.83259 [22] validation_0-auc:0.87572 validation_1-auc:0.83274 [23] validation_0-auc:0.87659 validation_1-auc:0.83362 [24] validation_0-auc:0.87704 validation_1-auc:0.83315 [25] validation_0-auc:0.87743 validation_1-auc:0.83338 [26] validation_0-auc:0.87762 validation_1-auc:0.83358 [27] validation_0-auc:0.87818 validation_1-auc:0.83337 [28] validation_0-auc:0.87822 validation_1-auc:0.83346 [29] validation_0-auc:0.87890 validation_1-auc:0.83331 [30] validation_0-auc:0.87903 validation_1-auc:0.83315 [31] validation_0-auc:0.87993 validation_1-auc:0.83277 [32] validation_0-auc:0.88063 validation_1-auc:0.83284 [33] validation_0-auc:0.88096 validation_1-auc:0.83339 [34] validation_0-auc:0.88210 validation_1-auc:0.83309 [35] validation_0-auc:0.88207 validation_1-auc:0.83317 [36] validation_0-auc:0.88224 validation_1-auc:0.83314 [37] validation_0-auc:0.88240 validation_1-auc:0.83292 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81176 validation_1-auc:0.80947 [1] validation_0-auc:0.82651 validation_1-auc:0.82286 [2] validation_0-auc:0.83551 validation_1-auc:0.82712 [3] validation_0-auc:0.83820 validation_1-auc:0.82810 [4] validation_0-auc:0.84733 validation_1-auc:0.82952 [5] validation_0-auc:0.84903 validation_1-auc:0.83409 [6] validation_0-auc:0.84836 validation_1-auc:0.83191 [7] validation_0-auc:0.85387 validation_1-auc:0.83486 [8] validation_0-auc:0.85876 validation_1-auc:0.83709 [9] validation_0-auc:0.85840 validation_1-auc:0.83730 [10] validation_0-auc:0.85787 validation_1-auc:0.83417 [11] validation_0-auc:0.85814 validation_1-auc:0.83328 [12] validation_0-auc:0.86431 validation_1-auc:0.83684 [13] validation_0-auc:0.86878 validation_1-auc:0.83901 [14] validation_0-auc:0.87119 validation_1-auc:0.83987 [15] validation_0-auc:0.87268 validation_1-auc:0.83789 [16] validation_0-auc:0.87455 validation_1-auc:0.83903 [17] validation_0-auc:0.87645 validation_1-auc:0.83873 [18] validation_0-auc:0.87724 validation_1-auc:0.83908 [19] validation_0-auc:0.87799 validation_1-auc:0.83966 [20] validation_0-auc:0.87882 validation_1-auc:0.83958 [21] validation_0-auc:0.87902 validation_1-auc:0.83960 [22] validation_0-auc:0.87951 validation_1-auc:0.83985 [23] validation_0-auc:0.88042 validation_1-auc:0.83903 [24] validation_0-auc:0.88118 validation_1-auc:0.83938 [25] validation_0-auc:0.88183 validation_1-auc:0.83941 [26] validation_0-auc:0.88279 validation_1-auc:0.83943 [27] validation_0-auc:0.88430 validation_1-auc:0.83947 [28] validation_0-auc:0.88447 validation_1-auc:0.83972 [29] validation_0-auc:0.88487 validation_1-auc:0.83903 [30] validation_0-auc:0.88567 validation_1-auc:0.83956 [31] validation_0-auc:0.88560 validation_1-auc:0.83942 [32] validation_0-auc:0.88572 validation_1-auc:0.83903 [33] validation_0-auc:0.88598 validation_1-auc:0.83902 [34] validation_0-auc:0.88633 validation_1-auc:0.83882 [35] validation_0-auc:0.88642 validation_1-auc:0.83890 [36] validation_0-auc:0.88707 validation_1-auc:0.83877 [37] validation_0-auc:0.88742 validation_1-auc:0.83862 [38] validation_0-auc:0.88755 validation_1-auc:0.83835 [39] validation_0-auc:0.88788 validation_1-auc:0.83760 [40] validation_0-auc:0.88777 validation_1-auc:0.83781 [41] validation_0-auc:0.88796 validation_1-auc:0.83789 [42] validation_0-auc:0.88804 validation_1-auc:0.83796 [43] validation_0-auc:0.88868 validation_1-auc:0.83769 [44] validation_0-auc:0.88942 validation_1-auc:0.83764 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81519 validation_1-auc:0.81115 [1] validation_0-auc:0.83201 validation_1-auc:0.82366 [2] validation_0-auc:0.83718 validation_1-auc:0.83029 [3] validation_0-auc:0.84145 validation_1-auc:0.83163 [4] validation_0-auc:0.84628 validation_1-auc:0.83410 [5] validation_0-auc:0.84792 validation_1-auc:0.83694 [6] validation_0-auc:0.84780 validation_1-auc:0.83116 [7] validation_0-auc:0.85599 validation_1-auc:0.83759 [8] validation_0-auc:0.85905 validation_1-auc:0.83700 [9] validation_0-auc:0.85860 validation_1-auc:0.83638 [10] validation_0-auc:0.85875 validation_1-auc:0.83594 [11] validation_0-auc:0.85921 validation_1-auc:0.83691 [12] validation_0-auc:0.86560 validation_1-auc:0.84075 [13] validation_0-auc:0.86941 validation_1-auc:0.84350 [14] validation_0-auc:0.87102 validation_1-auc:0.84520 [15] validation_0-auc:0.87174 validation_1-auc:0.84423 [16] validation_0-auc:0.87350 validation_1-auc:0.84460 [17] validation_0-auc:0.87528 validation_1-auc:0.84395 [18] validation_0-auc:0.87593 validation_1-auc:0.84331 [19] validation_0-auc:0.87733 validation_1-auc:0.84275 [20] validation_0-auc:0.87769 validation_1-auc:0.84252 [21] validation_0-auc:0.87822 validation_1-auc:0.84160 [22] validation_0-auc:0.87989 validation_1-auc:0.84207 [23] validation_0-auc:0.88086 validation_1-auc:0.84223 [24] validation_0-auc:0.88139 validation_1-auc:0.84238 [25] validation_0-auc:0.88186 validation_1-auc:0.84258 [26] validation_0-auc:0.88258 validation_1-auc:0.84240 [27] validation_0-auc:0.88359 validation_1-auc:0.84183 [28] validation_0-auc:0.88402 validation_1-auc:0.84147 [29] validation_0-auc:0.88415 validation_1-auc:0.84140 [30] validation_0-auc:0.88455 validation_1-auc:0.84080 [31] validation_0-auc:0.88538 validation_1-auc:0.84070 [32] validation_0-auc:0.88563 validation_1-auc:0.84055 [33] validation_0-auc:0.88610 validation_1-auc:0.84024 [34] validation_0-auc:0.88631 validation_1-auc:0.83977 [35] validation_0-auc:0.88637 validation_1-auc:0.83959 [36] validation_0-auc:0.88644 validation_1-auc:0.83935 [37] validation_0-auc:0.88728 validation_1-auc:0.83898 [38] validation_0-auc:0.88802 validation_1-auc:0.83814 [39] validation_0-auc:0.88815 validation_1-auc:0.83806 [40] validation_0-auc:0.88815 validation_1-auc:0.83811 [41] validation_0-auc:0.88838 validation_1-auc:0.83807 [42] validation_0-auc:0.88883 validation_1-auc:0.83753 [43] validation_0-auc:0.88902 validation_1-auc:0.83781 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81007 validation_1-auc:0.80693 [1] validation_0-auc:0.82137 validation_1-auc:0.81877 [2] validation_0-auc:0.82976 validation_1-auc:0.82498 [3] validation_0-auc:0.83120 validation_1-auc:0.82212 [4] validation_0-auc:0.83382 validation_1-auc:0.82481 [5] validation_0-auc:0.83696 validation_1-auc:0.82672 [6] validation_0-auc:0.83976 validation_1-auc:0.83016 [7] validation_0-auc:0.84177 validation_1-auc:0.83330 [8] validation_0-auc:0.84585 validation_1-auc:0.83282 [9] validation_0-auc:0.84984 validation_1-auc:0.83519 [10] validation_0-auc:0.85146 validation_1-auc:0.83530 [11] validation_0-auc:0.85113 validation_1-auc:0.83380 [12] validation_0-auc:0.85502 validation_1-auc:0.83622 [13] validation_0-auc:0.85797 validation_1-auc:0.83644 [14] validation_0-auc:0.85990 validation_1-auc:0.83686 [15] validation_0-auc:0.86114 validation_1-auc:0.83639 [16] validation_0-auc:0.86158 validation_1-auc:0.83602 [17] validation_0-auc:0.86285 validation_1-auc:0.83501 [18] validation_0-auc:0.86405 validation_1-auc:0.83454 [19] validation_0-auc:0.86498 validation_1-auc:0.83497 [20] validation_0-auc:0.86595 validation_1-auc:0.83417 [21] validation_0-auc:0.86757 validation_1-auc:0.83454 [22] validation_0-auc:0.86810 validation_1-auc:0.83466 [23] validation_0-auc:0.86830 validation_1-auc:0.83461 [24] validation_0-auc:0.86859 validation_1-auc:0.83422 [25] validation_0-auc:0.86941 validation_1-auc:0.83371 [26] validation_0-auc:0.86986 validation_1-auc:0.83392 [27] validation_0-auc:0.87053 validation_1-auc:0.83330 [28] validation_0-auc:0.87105 validation_1-auc:0.83367 [29] validation_0-auc:0.87111 validation_1-auc:0.83371 [30] validation_0-auc:0.87152 validation_1-auc:0.83435 [31] validation_0-auc:0.87181 validation_1-auc:0.83437 [32] validation_0-auc:0.87286 validation_1-auc:0.83459 [33] validation_0-auc:0.87304 validation_1-auc:0.83470 [34] validation_0-auc:0.87347 validation_1-auc:0.83407 [35] validation_0-auc:0.87393 validation_1-auc:0.83319 [36] validation_0-auc:0.87464 validation_1-auc:0.83300 [37] validation_0-auc:0.87469 validation_1-auc:0.83311 [38] validation_0-auc:0.87502 validation_1-auc:0.83281 [39] validation_0-auc:0.87594 validation_1-auc:0.83273 [40] validation_0-auc:0.87620 validation_1-auc:0.83299 [41] validation_0-auc:0.87747 validation_1-auc:0.83274 [42] validation_0-auc:0.87754 validation_1-auc:0.83254 [43] validation_0-auc:0.87846 validation_1-auc:0.83286 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.80863 validation_1-auc:0.80010 [1] validation_0-auc:0.82349 validation_1-auc:0.81717 [2] validation_0-auc:0.82654 validation_1-auc:0.81737 [3] validation_0-auc:0.82988 validation_1-auc:0.82281 [4] validation_0-auc:0.83570 validation_1-auc:0.82554 [5] validation_0-auc:0.83917 validation_1-auc:0.82930 [6] validation_0-auc:0.84492 validation_1-auc:0.83396 [7] validation_0-auc:0.84657 validation_1-auc:0.83569 [8] validation_0-auc:0.84837 validation_1-auc:0.83476 [9] validation_0-auc:0.85010 validation_1-auc:0.83841 [10] validation_0-auc:0.85017 validation_1-auc:0.83887 [11] validation_0-auc:0.85091 validation_1-auc:0.83723 [12] validation_0-auc:0.85584 validation_1-auc:0.83976 [13] validation_0-auc:0.85900 validation_1-auc:0.84063 [14] validation_0-auc:0.86059 validation_1-auc:0.84054 [15] validation_0-auc:0.86167 validation_1-auc:0.84086 [16] validation_0-auc:0.86303 validation_1-auc:0.84085 [17] validation_0-auc:0.86383 validation_1-auc:0.83947 [18] validation_0-auc:0.86462 validation_1-auc:0.83971 [19] validation_0-auc:0.86559 validation_1-auc:0.84059 [20] validation_0-auc:0.86650 validation_1-auc:0.83981 [21] validation_0-auc:0.86762 validation_1-auc:0.84030 [22] validation_0-auc:0.86865 validation_1-auc:0.84050 [23] validation_0-auc:0.86916 validation_1-auc:0.83978 [24] validation_0-auc:0.86953 validation_1-auc:0.84033 [25] validation_0-auc:0.86992 validation_1-auc:0.84000 [26] validation_0-auc:0.87005 validation_1-auc:0.83998 [27] validation_0-auc:0.87115 validation_1-auc:0.83964 [28] validation_0-auc:0.87205 validation_1-auc:0.83972 [29] validation_0-auc:0.87328 validation_1-auc:0.83984 [30] validation_0-auc:0.87360 validation_1-auc:0.83929 [31] validation_0-auc:0.87367 validation_1-auc:0.83938 [32] validation_0-auc:0.87441 validation_1-auc:0.83918 [33] validation_0-auc:0.87490 validation_1-auc:0.83990 [34] validation_0-auc:0.87594 validation_1-auc:0.84011 [35] validation_0-auc:0.87618 validation_1-auc:0.83988 [36] validation_0-auc:0.87648 validation_1-auc:0.83991 [37] validation_0-auc:0.87657 validation_1-auc:0.83991 [38] validation_0-auc:0.87676 validation_1-auc:0.83987 [39] validation_0-auc:0.87696 validation_1-auc:0.83973 [40] validation_0-auc:0.87705 validation_1-auc:0.83990 [41] validation_0-auc:0.87724 validation_1-auc:0.83941 [42] validation_0-auc:0.87781 validation_1-auc:0.83934 [43] validation_0-auc:0.87810 validation_1-auc:0.83924 [44] validation_0-auc:0.87848 validation_1-auc:0.83882 [45] validation_0-auc:0.87863 validation_1-auc:0.83888 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.82005 validation_1-auc:0.81815 [1] validation_0-auc:0.82547 validation_1-auc:0.82159 [2] validation_0-auc:0.83019 validation_1-auc:0.82631 [3] validation_0-auc:0.83230 validation_1-auc:0.82660 [4] validation_0-auc:0.83488 validation_1-auc:0.82988 [5] validation_0-auc:0.83888 validation_1-auc:0.83262 [6] validation_0-auc:0.84242 validation_1-auc:0.83408 [7] validation_0-auc:0.84581 validation_1-auc:0.83560 [8] validation_0-auc:0.84775 validation_1-auc:0.83617 [9] validation_0-auc:0.84989 validation_1-auc:0.83746 [10] validation_0-auc:0.85052 validation_1-auc:0.83816 [11] validation_0-auc:0.84982 validation_1-auc:0.83603 [12] validation_0-auc:0.85408 validation_1-auc:0.83825 [13] validation_0-auc:0.85547 validation_1-auc:0.83955 [14] validation_0-auc:0.85818 validation_1-auc:0.84292 [15] validation_0-auc:0.85990 validation_1-auc:0.84361 [16] validation_0-auc:0.86142 validation_1-auc:0.84287 [17] validation_0-auc:0.86247 validation_1-auc:0.84280 [18] validation_0-auc:0.86276 validation_1-auc:0.84297 [19] validation_0-auc:0.86368 validation_1-auc:0.84290 [20] validation_0-auc:0.86488 validation_1-auc:0.84279 [21] validation_0-auc:0.86540 validation_1-auc:0.84307 [22] validation_0-auc:0.86631 validation_1-auc:0.84285 [23] validation_0-auc:0.86687 validation_1-auc:0.84289 [24] validation_0-auc:0.86777 validation_1-auc:0.84289 [25] validation_0-auc:0.86830 validation_1-auc:0.84279 [26] validation_0-auc:0.86862 validation_1-auc:0.84237 [27] validation_0-auc:0.87011 validation_1-auc:0.84232 [28] validation_0-auc:0.87063 validation_1-auc:0.84224 [29] validation_0-auc:0.87063 validation_1-auc:0.84199 [30] validation_0-auc:0.87108 validation_1-auc:0.84246 [31] validation_0-auc:0.87190 validation_1-auc:0.84252 [32] validation_0-auc:0.87275 validation_1-auc:0.84147 [33] validation_0-auc:0.87302 validation_1-auc:0.84149 [34] validation_0-auc:0.87350 validation_1-auc:0.84118 [35] validation_0-auc:0.87371 validation_1-auc:0.84115 [36] validation_0-auc:0.87407 validation_1-auc:0.84113 [37] validation_0-auc:0.87475 validation_1-auc:0.84038 [38] validation_0-auc:0.87529 validation_1-auc:0.84009 [39] validation_0-auc:0.87540 validation_1-auc:0.83988 [40] validation_0-auc:0.87555 validation_1-auc:0.83984 [41] validation_0-auc:0.87579 validation_1-auc:0.83991 [42] validation_0-auc:0.87630 validation_1-auc:0.83942 [43] validation_0-auc:0.87664 validation_1-auc:0.83926 [44] validation_0-auc:0.87713 validation_1-auc:0.83916 [45] validation_0-auc:0.87763 validation_1-auc:0.83868 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81105 validation_1-auc:0.80637 [1] validation_0-auc:0.82008 validation_1-auc:0.81881 [2] validation_0-auc:0.82922 validation_1-auc:0.82532 [3] validation_0-auc:0.83159 validation_1-auc:0.82594 [4] validation_0-auc:0.83378 validation_1-auc:0.82618 [5] validation_0-auc:0.83671 validation_1-auc:0.82887 [6] validation_0-auc:0.84111 validation_1-auc:0.83302 [7] validation_0-auc:0.84227 validation_1-auc:0.83380 [8] validation_0-auc:0.84422 validation_1-auc:0.83346 [9] validation_0-auc:0.84742 validation_1-auc:0.83581 [10] validation_0-auc:0.84984 validation_1-auc:0.83563 [11] validation_0-auc:0.84933 validation_1-auc:0.83344 [12] validation_0-auc:0.85285 validation_1-auc:0.83653 [13] validation_0-auc:0.85494 validation_1-auc:0.83796 [14] validation_0-auc:0.85653 validation_1-auc:0.83880 [15] validation_0-auc:0.85803 validation_1-auc:0.83841 [16] validation_0-auc:0.85922 validation_1-auc:0.83773 [17] validation_0-auc:0.85983 validation_1-auc:0.83709 [18] validation_0-auc:0.86162 validation_1-auc:0.83622 [19] validation_0-auc:0.86232 validation_1-auc:0.83513 [20] validation_0-auc:0.86287 validation_1-auc:0.83518 [21] validation_0-auc:0.86374 validation_1-auc:0.83543 [22] validation_0-auc:0.86416 validation_1-auc:0.83540 [23] validation_0-auc:0.86459 validation_1-auc:0.83510 [24] validation_0-auc:0.86482 validation_1-auc:0.83477 [25] validation_0-auc:0.86526 validation_1-auc:0.83484 [26] validation_0-auc:0.86545 validation_1-auc:0.83473 [27] validation_0-auc:0.86568 validation_1-auc:0.83481 [28] validation_0-auc:0.86578 validation_1-auc:0.83485 [29] validation_0-auc:0.86654 validation_1-auc:0.83501 [30] validation_0-auc:0.86666 validation_1-auc:0.83465 [31] validation_0-auc:0.86790 validation_1-auc:0.83486 [32] validation_0-auc:0.86802 validation_1-auc:0.83488 [33] validation_0-auc:0.86809 validation_1-auc:0.83473 [34] validation_0-auc:0.86821 validation_1-auc:0.83483 [35] validation_0-auc:0.86828 validation_1-auc:0.83508 [36] validation_0-auc:0.86861 validation_1-auc:0.83435 [37] validation_0-auc:0.86866 validation_1-auc:0.83425 [38] validation_0-auc:0.86892 validation_1-auc:0.83451 [39] validation_0-auc:0.86913 validation_1-auc:0.83425 [40] validation_0-auc:0.86939 validation_1-auc:0.83430 [41] validation_0-auc:0.86940 validation_1-auc:0.83443 [42] validation_0-auc:0.86949 validation_1-auc:0.83436 [43] validation_0-auc:0.87013 validation_1-auc:0.83441 [44] validation_0-auc:0.87059 validation_1-auc:0.83365 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81067 validation_1-auc:0.81109 [1] validation_0-auc:0.82045 validation_1-auc:0.81627 [2] validation_0-auc:0.82760 validation_1-auc:0.82116 [3] validation_0-auc:0.82925 validation_1-auc:0.81730 [4] validation_0-auc:0.83628 validation_1-auc:0.82554 [5] validation_0-auc:0.83889 validation_1-auc:0.82992 [6] validation_0-auc:0.84258 validation_1-auc:0.83304 [7] validation_0-auc:0.84515 validation_1-auc:0.83327 [8] validation_0-auc:0.84797 validation_1-auc:0.83479 [9] validation_0-auc:0.84982 validation_1-auc:0.83737 [10] validation_0-auc:0.84996 validation_1-auc:0.83746 [11] validation_0-auc:0.84929 validation_1-auc:0.83715 [12] validation_0-auc:0.85506 validation_1-auc:0.83957 [13] validation_0-auc:0.85817 validation_1-auc:0.84131 [14] validation_0-auc:0.85945 validation_1-auc:0.84041 [15] validation_0-auc:0.86040 validation_1-auc:0.83984 [16] validation_0-auc:0.86127 validation_1-auc:0.83954 [17] validation_0-auc:0.86170 validation_1-auc:0.83947 [18] validation_0-auc:0.86276 validation_1-auc:0.83945 [19] validation_0-auc:0.86327 validation_1-auc:0.84019 [20] validation_0-auc:0.86381 validation_1-auc:0.84075 [21] validation_0-auc:0.86454 validation_1-auc:0.84078 [22] validation_0-auc:0.86530 validation_1-auc:0.84164 [23] validation_0-auc:0.86598 validation_1-auc:0.84128 [24] validation_0-auc:0.86656 validation_1-auc:0.84078 [25] validation_0-auc:0.86721 validation_1-auc:0.84069 [26] validation_0-auc:0.86745 validation_1-auc:0.84066 [27] validation_0-auc:0.86808 validation_1-auc:0.84017 [28] validation_0-auc:0.86914 validation_1-auc:0.84027 [29] validation_0-auc:0.86951 validation_1-auc:0.84014 [30] validation_0-auc:0.86972 validation_1-auc:0.84016 [31] validation_0-auc:0.86996 validation_1-auc:0.83992 [32] validation_0-auc:0.87072 validation_1-auc:0.84001 [33] validation_0-auc:0.87090 validation_1-auc:0.83997 [34] validation_0-auc:0.87111 validation_1-auc:0.83969 [35] validation_0-auc:0.87145 validation_1-auc:0.83964 [36] validation_0-auc:0.87215 validation_1-auc:0.84006 [37] validation_0-auc:0.87242 validation_1-auc:0.83987 [38] validation_0-auc:0.87262 validation_1-auc:0.83995 [39] validation_0-auc:0.87270 validation_1-auc:0.84021 [40] validation_0-auc:0.87275 validation_1-auc:0.84066 [41] validation_0-auc:0.87323 validation_1-auc:0.84095 [42] validation_0-auc:0.87372 validation_1-auc:0.84074 [43] validation_0-auc:0.87433 validation_1-auc:0.84057 [44] validation_0-auc:0.87440 validation_1-auc:0.84028 [45] validation_0-auc:0.87511 validation_1-auc:0.84011 [46] validation_0-auc:0.87553 validation_1-auc:0.83972 [47] validation_0-auc:0.87606 validation_1-auc:0.83880 [48] validation_0-auc:0.87630 validation_1-auc:0.83876 [49] validation_0-auc:0.87629 validation_1-auc:0.83900 [50] validation_0-auc:0.87637 validation_1-auc:0.83902 [51] validation_0-auc:0.87649 validation_1-auc:0.83930 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81835 validation_1-auc:0.81691 [1] validation_0-auc:0.82862 validation_1-auc:0.82346 [2] validation_0-auc:0.83280 validation_1-auc:0.82893 [3] validation_0-auc:0.83563 validation_1-auc:0.82931 [4] validation_0-auc:0.83780 validation_1-auc:0.83200 [5] validation_0-auc:0.83975 validation_1-auc:0.83280 [6] validation_0-auc:0.84205 validation_1-auc:0.83374 [7] validation_0-auc:0.84453 validation_1-auc:0.83256 [8] validation_0-auc:0.84638 validation_1-auc:0.83384 [9] validation_0-auc:0.84986 validation_1-auc:0.83670 [10] validation_0-auc:0.85058 validation_1-auc:0.83825 [11] validation_0-auc:0.84986 validation_1-auc:0.83646 [12] validation_0-auc:0.85321 validation_1-auc:0.83744 [13] validation_0-auc:0.85478 validation_1-auc:0.83942 [14] validation_0-auc:0.85613 validation_1-auc:0.84091 [15] validation_0-auc:0.85709 validation_1-auc:0.84170 [16] validation_0-auc:0.85891 validation_1-auc:0.84239 [17] validation_0-auc:0.86023 validation_1-auc:0.84215 [18] validation_0-auc:0.86146 validation_1-auc:0.84247 [19] validation_0-auc:0.86202 validation_1-auc:0.84237 [20] validation_0-auc:0.86268 validation_1-auc:0.84152 [21] validation_0-auc:0.86342 validation_1-auc:0.84132 [22] validation_0-auc:0.86492 validation_1-auc:0.84044 [23] validation_0-auc:0.86602 validation_1-auc:0.84073 [24] validation_0-auc:0.86688 validation_1-auc:0.84082 [25] validation_0-auc:0.86779 validation_1-auc:0.84074 [26] validation_0-auc:0.86849 validation_1-auc:0.84076 [27] validation_0-auc:0.86910 validation_1-auc:0.84096 [28] validation_0-auc:0.86931 validation_1-auc:0.84113 [29] validation_0-auc:0.86974 validation_1-auc:0.84187 [30] validation_0-auc:0.87070 validation_1-auc:0.84167 [31] validation_0-auc:0.87108 validation_1-auc:0.84174 [32] validation_0-auc:0.87123 validation_1-auc:0.84166 [33] validation_0-auc:0.87153 validation_1-auc:0.84142 [34] validation_0-auc:0.87214 validation_1-auc:0.84153 [35] validation_0-auc:0.87289 validation_1-auc:0.84147 [36] validation_0-auc:0.87329 validation_1-auc:0.84136 [37] validation_0-auc:0.87345 validation_1-auc:0.84116 [38] validation_0-auc:0.87355 validation_1-auc:0.84114 [39] validation_0-auc:0.87411 validation_1-auc:0.84087 [40] validation_0-auc:0.87419 validation_1-auc:0.84088 [41] validation_0-auc:0.87540 validation_1-auc:0.84065 [42] validation_0-auc:0.87576 validation_1-auc:0.84078 [43] validation_0-auc:0.87598 validation_1-auc:0.84097 [44] validation_0-auc:0.87646 validation_1-auc:0.84047 [45] validation_0-auc:0.87666 validation_1-auc:0.84048 [46] validation_0-auc:0.87670 validation_1-auc:0.84016 [47] validation_0-auc:0.87719 validation_1-auc:0.84000 [48] validation_0-auc:0.87796 validation_1-auc:0.83922 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): . [0] validation_0-auc:0.81685 validation_1-auc:0.81075 [1] validation_0-auc:0.82791 validation_1-auc:0.82283 [2] validation_0-auc:0.83537 validation_1-auc:0.82615 [3] validation_0-auc:0.83996 validation_1-auc:0.82712 [4] validation_0-auc:0.84558 validation_1-auc:0.82791 [5] validation_0-auc:0.84781 validation_1-auc:0.82977 [6] validation_0-auc:0.85151 validation_1-auc:0.83373 [7] validation_0-auc:0.85510 validation_1-auc:0.83444 [8] validation_0-auc:0.85998 validation_1-auc:0.83601 [9] validation_0-auc:0.86238 validation_1-auc:0.83804 [10] validation_0-auc:0.86435 validation_1-auc:0.83584 [11] validation_0-auc:0.86583 validation_1-auc:0.83093 [12] validation_0-auc:0.87079 validation_1-auc:0.83235 [13] validation_0-auc:0.87454 validation_1-auc:0.83253 [14] validation_0-auc:0.87642 validation_1-auc:0.83254 [15] validation_0-auc:0.87856 validation_1-auc:0.83218 [16] validation_0-auc:0.87973 validation_1-auc:0.83171 [17] validation_0-auc:0.88122 validation_1-auc:0.83115 [18] validation_0-auc:0.88256 validation_1-auc:0.83119 [19] validation_0-auc:0.88330 validation_1-auc:0.83139 [20] validation_0-auc:0.88408 validation_1-auc:0.83082 [21] validation_0-auc:0.88505 validation_1-auc:0.83044 [22] validation_0-auc:0.88631 validation_1-auc:0.83025 [23] validation_0-auc:0.88670 validation_1-auc:0.83047 [24] validation_0-auc:0.88740 validation_1-auc:0.82903 [25] validation_0-auc:0.88770 validation_1-auc:0.82895 [26] validation_0-auc:0.88793 validation_1-auc:0.82913 [27] validation_0-auc:0.88808 validation_1-auc:0.82881 [28] validation_0-auc:0.88830 validation_1-auc:0.82901 [29] validation_0-auc:0.88834 validation_1-auc:0.82910 [30] validation_0-auc:0.88894 validation_1-auc:0.82854 [31] validation_0-auc:0.88898 validation_1-auc:0.82859 [32] validation_0-auc:0.88914 validation_1-auc:0.82837 [33] validation_0-auc:0.88935 validation_1-auc:0.82847 [34] validation_0-auc:0.89037 validation_1-auc:0.82891 [35] validation_0-auc:0.89097 validation_1-auc:0.82869 [36] validation_0-auc:0.89158 validation_1-auc:0.82814 [37] validation_0-auc:0.89167 validation_1-auc:0.82822 [38] validation_0-auc:0.89184 validation_1-auc:0.82764 [39] validation_0-auc:0.89187 validation_1-auc:0.82734 . C: Users woo anaconda3 envs py39r41 lib site-packages xgboost sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1]. warnings.warn(label_encoder_deprecation_msg, UserWarning) C: Users woo anaconda3 envs py39r41 lib site-packages xgboost data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead. elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)): .",
            "url": "https://stahangryum.github.io/Woo/kaggle/2022/05/10/santander.html",
            "relUrl": "/kaggle/2022/05/10/santander.html",
            "date": " • May 10, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "EDA HIGHLIGHT",
            "content": "library(tidyverse) . Warning message: &#34;패키지 &#39;tidyverse&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Attaching packages - tidyverse 1.3.1 -- v ggplot2 3.3.5 v purrr 0.3.4 v tibble 3.1.6 v dplyr 1.0.8 v tidyr 1.2.0 v stringr 1.4.0 v readr 2.1.2 v forcats 0.5.1 Warning message: &#34;패키지 &#39;ggplot2&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tibble&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;tidyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;readr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;purrr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;dplyr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;stringr&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; Warning message: &#34;패키지 &#39;forcats&#39;는 R 버전 4.1.3에서 작성되었습니다&#34; -- Conflicts - tidyverse_conflicts() -- x dplyr::filter() masks stats::filter() x dplyr::lag() masks stats::lag() . Ch.1 R Language . 생략 | . Ch.2 Introduction to EDA . 자료분석은 대체로 두 가지 단계로 나뉜다. . 탐색적 자료분석(데이터의 구조와 특징 파악) . | 확증적 자료분석(모형, 재현성 평가) . | . EDA(Exploratory Data Analysis) . EDA는 데이터 특징과 내재하는 구조적 관계를 알아내기 위한 기법들을 통칭한다. . | 데이터를 특정한 모형에 적합시키기 보다는 데이터를 있는 그대로 보려는 데에 중점을 둔다. . | . 4 Themes . EDA에서는 네 가지 주제가 때로는 홀로, 때로는 얽혀서 나타난다. . 저항성(resistance)의 강조(예를 들어 평균보다는 일부자료의 파손에 저항적인 중위수가 바람직한 대표값 측도로서 선호된다.) . | 잔차(residual) 계산 . | 자료변수의 재표현(re-expression)을 통한 다각적 시도 . | 그래프를 통한 현시성(revelation) . | . Summary (2) . 자료분석은 탐색적 자료분석과 확증적 자료분석의 두 단계로 나눌 수 있다. . | EDA는 자료의 구조 및 특징의 파악을 목적으로 한다. 이를 위하여 효과적이고 신뢰성 있는 데이터의 요약과 그래프적 기법이 사용된다. . | EDA의 네 개 주제는 저항성, 잔차, 재표현, 현시성이다. . | 통계적 모형은 &#39;진실&#39;로서가 아니라 &#39;주요 사례&#39;로서 의미가 있다. 또한 모형과 데이터는 일방통행이 아닌 쌍방통행으로 이해되어야 한다. 데이터와 분석도 사이클을 이룬다. . | . Ch.3 Stem and Leaf . Stem and Leaf . 데이터의 값을 십 단위인 줄기(stem)와 일 단위인 잎(leaf)으로 분리한다. . - 장점 . 사분위수나 중앙값을 찾기 쉽다. . | 분포의 전체적인 모양(봉우리 개수, 대칭분포, 치우친 방향)을 쉽게 알 수 있다. . | 이상값 유무를 파악할 수 있다. . | . - 단점 . 자료가 많은 경우에는 부적합하고 자료의 수가 50개 이하일 때 적합하다. | . exam1 = read.table(&#39;dataset/EDA/exam1.txt&#39;, header = TRUE) head(exam1) . A data.frame: 6 × 2 hwscore . &lt;int&gt;&lt;int&gt; . 10 | 54 | . 20 | 51 | . 31 | 52 | . 40 | 82 | . 51 | 37 | . 61 | 41 | . stem(exam1$score) . The decimal point is 1 digit(s) to the right of the | 0 | 00 1 | 058 2 | 1333458889 3 | 0355789 4 | 11133456678 5 | 11122233344456688 6 | 147779 7 | 33478 8 | 29 9 | 09 . 이 줄기그림의 주요 특징은 이봉분포의 모습을 보인다는 점이다. 이것은 자료가 2개의 군집으로 되어 있음을 말한다. | . exam1[exam1$hw == 0, ]$score %&gt;% stem # 과제 미제출자 exam1[exam1$hw == 1, ]$score %&gt;% stem # 과제 제출자 . The decimal point is 1 digit(s) to the right of the | 0 | 00 1 | 05 2 | 13334589 3 | 0355 4 | 13378 5 | 122333446 6 | 4 7 | 3 8 | 29 The decimal point is 1 digit(s) to the right of the | 1 | 8 2 | 88 3 | 789 4 | 114566 5 | 11245688 6 | 17779 7 | 3478 8 | 9 | 09 . 과제 제출 여부에 따라서 줄기-잎 그림을 두 개 그려본 결과 흥미로운 점을 확인했다. . 과제 미제출자에 경우 여전히 이봉분포를 띄고 있으나 과제 제출자의 경우 단봉분포를 띄고 있다. . 이것은 과제물 미제출 그룹이 서로 이질적인 어떤 두 집단(50점대를 중심으로 하는 집단과 20점대를 중심으로 하는 집단)의 혼합임을 말하여 준다. . 아마 전자는 학업습관이 불성실하나 학업능력은 우수한 집단이고 후자는 학업습관과 학업능력 모두 좋지 않은 학생들의 집단이 아닐까 생각해본다. . Tip :R에서 줄기 수를 줄이거나 늘이려면 stem() 함수 내 scale 파라미터를 조정하면 된다. . stem(exam1$score, scale = 0.5) # 줄기 수를 절반으로 줄인다. . The decimal point is 1 digit(s) to the right of the | 0 | 00058 2 | 13334588890355789 4 | 1113345667811122233344456688 6 | 14777933478 8 | 2909 . 이 줄기 그림은 단봉분포의 형태를 취한다. 이것은 너무 단순하여 이 자료의 주요 특성을 잃은 것으로 볼 수 있다. . 즉 2개의 봉우리를 구분하지 못하고 1개만 본 것이다. . stem(exam1$score, scale = 2) # 줄기 수를 두 배로 늘인다. . The decimal point is 1 digit(s) to the right of the | 0 | 00 0 | 1 | 0 1 | 58 2 | 13334 2 | 58889 3 | 03 3 | 55789 4 | 111334 4 | 56678 5 | 111222333444 5 | 56688 6 | 14 6 | 7779 7 | 334 7 | 78 8 | 2 8 | 9 9 | 0 9 | 9 . 줄기 수를 늘였더니 더 많은 봉우리를 볼 수 있다. . 일반적으로 줄기 수를 늘이면 늘일수록 많은 수의 봉우리를 보게 되고 그 반대로 줄기 수를 줄이면 줄일수록 적은 수의 봉우리를 보게 된다. . Compared with Histogram . hist(exam1$score) . 줄기 - 잎 히스토그램 . 정보 손실 | 손실되지 않음 | 손실됨 | . 줄기 수 변환 | 쉬움 | 어려움 | . 구간의 폭 | 조정 불가능 | 조정 가능 | . Summary (3) . 줄기 그림은 히스토그램과 마찬가지로 자료 분포의 특성을 그래프화한 것이다. 줄기 그림은 히스토그램에 비하여 정보의 보전 면에서 우수하며 쉽게 구간(줄기) 수를 늘이거나 줄일 수 있다. 그러나 구간(줄기)의 선정시 제약이 따른다. . | 적절한 줄기 그림을 그리기 위하여 여러 개의 그림을 그려보고 비교해 보아야 한다. 계획된 시행착오가 필요하다. . | 줄기 그림에서는 다음과 같은 자료의 특성을 관찰할 수 있다. . 군집의 수 | 집중도가 높은 구간 | 대칭성 여부 | 자료의 범위 및 산포 | 특이점의 존재여부 | . | . Ch.4 Numerical Summary and Box Plot . Mean and Median . . 한 쪽 꼬리가 긴 분포에서 평균값은 쉽게 휘둘리지만 중앙값은 쉽게 휘둘리지 않다. 따라서 중앙값이 대표값으로서 적합하다. | . $ begin{cases} X_{ frac{N+1}{2}} qquad if N = odd dfrac{X_{ frac{N}{2}} + X_{ frac{N}{2} + 1}}{2} qquad if N = even end{cases}$ . 중간값의 깊이 $d(M)$은 . $d(M) = dfrac{(N+1)}{2}$ . Five Number Summary . 아래 4분위수 : $H_L$ 중간값 : $M$ 위 4분위수 : $H_U$ . 다섯 숫자 요약 = (min, $H_L, M, H_U$, max) = (최솟값, 제 1사분위수, 중앙값, 제 3사분위수, 최댓값) . summary(exam1$score) . Min. 1st Qu. Median Mean 3rd Qu. Max. 0.00 33.00 48.00 47.23 58.00 99.00 . Skewness . 왜도 = $SKEW = dfrac{(H_U - M) - (M - H_L)}{(H_U - M) + (M - H_L)}$ . 왜도 &lt; 0 이면 왼쪽으로 기울어진 분포 . 왜도 &gt; 0 이면 오른쪽으로 기울어진 분포 . Quantiles . low = quantile(exam1$score, c(1/2, 1/4, 1/8, 1/16), type = 8) %&gt;% as.numeric %&gt;% round(2)# 중간값, 아래 4분위수, 아래 8분위수, 아래 16분위수 high = quantile(exam1$score, c(1/2, 3/4, 7/8, 15/16), type = 8) %&gt;% as.numeric %&gt;% round(2) # 중간값, 위 4분위수, 위 8분위수, 위 16분위수 values = cbind(low, high, (low+high)/2, high-low) colnames(values) = c(&#39;low&#39;, &#39;high&#39;, &#39;mid&#39;, &#39;spr&#39;) rownames(values) = c(&#39;M&#39;, &#39;H&#39;, &#39;E&#39;, &#39;D&#39;) values . A matrix: 4 × 4 of type dbl lowhighmidspr . M48.00 | 48.00 | 48.00 | 0.00 | . H32.00 | 58.00 | 45.00 | 26.00 | . E23.00 | 73.00 | 48.00 | 50.00 | . D16.25 | 80.33 | 48.29 | 64.08 | . KURTO . Ch.5 Data Re-Expression . &#47729;&#49849;, &#47196;&#44536;, &#51648;&#49688; &#48320;&#54872;&#50640; &#51032;&#54620; &#51116;&#54364;&#54788; . Standardization . 표준화 변환이란 통상적으로 한 자료묶음의 평균이 0, 표준편차가 1이 되도록 하는 선형변환을 말한다. | . $x_1, x_2, dots, x_n$을 자료 값이라고 할 때 이것의 표준화변환 $z_1, z_2, dots, z_n$은 다음과 같이 정한다. . $z_i = dfrac{x_i - bar{x}}{s_x}, , i = 1,2, dots,n. qquad(1)$ . 그런데 (1)은 로버스트하지 않은 $ bar{x}$와 $s_x$에 의존하므로 EDA의 관점에서는 믿고 사용하기 어렵다. [^1] . 왜냐하면 표본평균과 표본표준편차는 극단적인 이상점에 의해 크게 변동될 수 있기 때문이다. | 그러나 중앙값 또는 사분위수범위(IQR)은 비교적 로버스트하다. | . 즉, 평균 $ bar{x}$ 대신에 중앙값 $med_x$를, 표준편차 $s_x$ 대신에 사분위수범위 $IQR$을 보정한 $ tilde{ sigma_x} = dfrac{IQR}{1.35}$을 쓰는 것이 좋을 것이다. . 따라서 로버스트 표준화 변환은 다음과 같다. . $ bar{z_i} = dfrac{x_i - med_x}{ tilde{ sigma_x}} , i = 1,2, dots,n. qquad(1)$ . 표준화 변환을 사용하는 예시 상황은 다음과 같다. . [1] &#34;A 그룹 학생 100명의 시험 X 점수는 N(40,10)으로부터 생성되었다.&#34; [1] &#34;B 그룹 학생 90명의 시험 Y 점수는 N(40,10)으로부터, 나머지 10명의 시험 Y 점수 N(80,5)으로부터 생성되었다.&#34; . par(mfrow = c(1,2)) X_group &lt;- rnorm(100, 40, 10) Y_group &lt;- c(rnorm(90,40,10), rnorm(10,80,5)) z_X &lt;- (X_group-mean(X_group))/sd(X_group) z_Y &lt;- (Y_group-mean(Y_group))/sd(Y_group) hist(z_X, breaks = seq(-6, 6, 0.5), freq = F, ylim = c(0, 0.7), main = &#39;Standardized X&#39;) hist(z_Y, breaks = seq(-6, 6, 0.5), freq = F, ylim = c(0, 0.7), main = &#39;Standardized Y&#39;) . par(mfrow = c(1,2)) robust_z_X &lt;- (X_group-median(X_group))/(IQR(X_group)/1.35) robust_z_Y &lt;- (Y_group-median(Y_group))/(IQR(Y_group)/1.35) hist(robust_z_X, breaks = seq(-6, 6, 0.5), freq = F, ylim = c(0, 0.7), main = &#39;Robust Standardized X&#39;) hist(robust_z_Y, breaks = seq(-6, 6, 0.5), freq = F, ylim = c(0, 0.7), main = &#39;Robust Standardized Y&#39;) . Summary (5) . 선형변환 $ax+b , (a &gt; 0)$은 분포의 형태를 바꾸지 않는다. 그러나 비선형변환은 분포의 형태를 바꾼다. | . 변환의 사다리는 $x^p$ 꼴의 파워(power, 멱승)형 변환을 일컫는데 변환의 사다리를 내려가면 $(p &lt; 1)$ 오른쪽 꼬리가 짧아진다. $p=0$에 해당하는 변환은 로그변환이다. | . 자료의 재표현은 분포의 대칭화를 위하여, 또는 자료묶음들의 산포를 균일화하기 위한 목적으로 실행된다. | . 자료의 재표현은 자료 해석을 풍부하게 한다. | . Ch.6 QQ-Plot . Various Patterns . Normal Distribution . 정규분포로부터의 모의생성 자료에 대한 정규확률 플롯 대체로 직선적인 경향선을 확인할 수 있다. | 직선의 절편과 기울기가 각각 100과 15 근처임을 확인할 수 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- rnorm(40, 100, 15) qqnorm(x1) qqline(x1) x2 &lt;- rnorm(4000, 100, 15) qqnorm(x2) qqline(x2) . Mixture Normal Distribution . 혼합 정규분포로부터의 모의생성 자료에 대한 정규확률 플롯 중앙에서 밀도가 낮다. | 우상과 좌하 부분에서 강한 곡선성을 볼 수 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- c(rnorm(20, 70, 15), rnorm(20, 130, 15)) qqnorm(x1) x2 &lt;- c(rnorm(2000, 70, 15), rnorm(2000, 130, 15)) qqnorm(x2) . Data with outliers . 특이값이 내재하는 모의생성 자료에 대한 정규확률 플롯 25, 175가 이상점으로 존재한다. | 25는 주경향선보다 아래에 있다. | 175는 주경향선보다 위에 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- rnorm(38, 100, 15) outliers &lt;- c(25, 175) qqnorm(c(x1, outliers)) x2 &lt;- rnorm(3800, 100, 15) qqnorm(c(x2, outliers)) . Short Tail . 꼬리가 짧은 분포로부터의 모의생성 자료에 대한 정규확률 플롯 플롯의 전체적 모양이 비스듬한 S자 성장곡선의 형태를 취하고 있음을 볼 수 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- runif(40, 80, 120) qqnorm(x1) x2 &lt;- runif(4000, 80, 120) qqnorm(x2) . Long Tail . 꼬리가 긴 분포로부터의 모의생성 자료에 대한 정규확률 플롯 플롯의 전체적인 모양이 비스듬한 역 S자 성장곡선의 형태를 취하고 있음을 볼 수 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- c(rexp(20,1), -rexp(20,1)) qqnorm(x1) x2 &lt;- c(rexp(2000,1), -rexp(2000,1)) qqnorm(x2) . Right Skewed . 큰 값 쪽으로 긴 꼬리를 뻗은 기울어진 분포의 경우 비스듬히 기울어진 J자 곡선의 형태임을 볼 수 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- exp(rnorm(40, 5, 1)) qqnorm(x1) x2 &lt;- exp(rnorm(4000, 5, 1)) qqnorm(x2) . Left Skewed . 작은 값 쪽으로 긴 꼬리를 뻗은 기울어진 분포의 경우 비스듬히 기울어진 역 J자 곡선의 형태임을 볼 수 있다. | . | . par(mfrow = c(1,2)) x1 &lt;- 1500 - exp(rnorm(40,5,1)) qqnorm(x1) x2 &lt;- 1500 - exp(rnorm(40,5,1)) qqnorm(x2) . Example . 백혈병 환자 21명의 생존시간에 관한 다음의 자료를 지수분포에 적합하여 보자. | . leukemia &lt;- c(1,1,2,2,3,4,4,5,5,8,8,8,8,11,11,12,12,15,17,22,23) leukemia_quant = ((1:length(leukemia)) - 1/3) / (length(leukemia) + 1/3) x &lt;- -log(1-leukemia_quant) y &lt;- sort(leukemia) plot(y ~ x) . library(lattice) qqmath(leukemia) . T . x &lt;- rbeta(800,2,3) * 100 y &lt;- rbeta(1200,3,2) * 100 . round(quantile(x), 1) . &lt;dl class=dl-inline&gt;0%225%23.250%37.475%52.7100%95.6&lt;/dl&gt; round(quantile(y), 1) . &lt;dl class=dl-inline&gt;0%4.825%44.250%62.175%75.9100%99.2&lt;/dl&gt; par(mfrow=c(1,2)) qqplot(x, y, xlim = c(0,100)) qqplot(x, y, xlim = c(0,100), type = &#39;l&#39;) . Ch.7 2&#50896; &#51088;&#47308;, &#48712;&#46020; &#54364;&#51032; &#53456;&#49353; . [^1] 로버스트(robust) 한 통계량은 이상치/에러값으로 부터 영향을 크게 받지 않는 (건장한) 통계량 .",
            "url": "https://stahangryum.github.io/Woo/eda/r/highlight/2022/04/12/eda_highlight.html",
            "relUrl": "/eda/r/highlight/2022/04/12/eda_highlight.html",
            "date": " • Apr 12, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "numpy Highlight",
            "content": "Reference . ref. https://numpy.org/doc/stable/user/index.html# . ref. https://github.com/guebin/IP2022 . NumPy . Numerical Python | . Import . import numpy as np . Array Creation(ndarray) . N Dimensional Array | . A = np.array([1,2,3]) A . array([1, 2, 3]) . mylist = [3, 4, 5] array_from_list = np.array(mylist) array_from_list . array([3, 4, 5]) . mytuple = (4,5,6) array_from_tuple = np.array(mytuple) array_from_tuple . array([4, 5, 6]) . np.array(range(10)) . array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) . np.linspace(0,1,12) # 0 ~ 1을 12등분하여 만듬 (끝점을 포함) . array([0. , 0.09090909, 0.18181818, 0.27272727, 0.36363636, 0.45454545, 0.54545455, 0.63636364, 0.72727273, 0.81818182, 0.90909091, 1. ]) . len(np.linspace(0,1,12)) . 12 . np.arange(5) . array([0, 1, 2, 3, 4]) . np.arange(1,6) . array([1, 2, 3, 4, 5]) . np.zeros(3) # 0을 3개 . array([0., 0., 0.]) . np.zeros((3,3)) . array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) . np.ones(3) # 1을 3개 . array([1., 1., 1.]) . np.ones((3,3)) . array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . np.eye(3) # 단위 행렬 . array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]) . np.diag([1,2,3]) # 대각선이 1,2,3인 행렬 . array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]) . Broadcasting . A+1 # 덧셈 . array([2, 3, 4]) . A-4 # 뺄셈 . array([-3, -2, -1]) . A*2 # 곱셈 . array([2, 4, 6]) . A/2 # 나눗셈 . array([0.5, 1. , 1.5]) . A**2 # 제곱 . array([1, 4, 9]) . A%2 # 나머지 . array([1, 0, 1], dtype=int32) . np.sqrt(A) . array([1. , 1.41421356, 1.73205081]) . np.log(A) . array([0. , 0.69314718, 1.09861229]) . np.exp(A) . array([ 2.71828183, 7.3890561 , 20.08553692]) . np.sin(A) . array([0.84147098, 0.90929743, 0.14112001]) . A = np.array([11,22,33,44,55,66]) . Indexing . A[2] . 33 . A[5] . 66 . A[1:4] . array([22, 33, 44]) . A[[0,2,4]] . array([11, 33, 55]) . A[[True, False, True, False, False, True]] . array([11, 33, 66]) . A &lt; 33 . array([ True, True, False, False, False, False]) . A[A&lt;33] . array([11, 22]) . Matrix Indexing . A2 = np.array([[1,2,3,4],[-1,-2,-3,-4],[5,6,7,8],[-5,-6,-7,-8]]) A2 . array([[ 1, 2, 3, 4], [-1, -2, -3, -4], [ 5, 6, 7, 8], [-5, -6, -7, -8]]) . A2[1][3] . -4 . A2[1,3] . -4 . A2[0, 0:2] . array([1, 2]) . A2[0] . array([1, 2, 3, 4]) . A2[0, 2:] . array([3, 4]) . A2[:, :] . array([[ 1, 2, 3, 4], [-1, -2, -3, -4], [ 5, 6, 7, 8], [-5, -6, -7, -8]]) . A2[[0,2], :] . array([[1, 2, 3, 4], [5, 6, 7, 8]]) . A2[[0,2]] . array([[1, 2, 3, 4], [5, 6, 7, 8]]) . Useful Functions . np.random . {python} np.random. . np.random.rand . {python} np.random.rand(N) . np.random.rand(10) # 0~1 사이에서 10개의 난수 생성 . array([0.74265347, 0.12865142, 0.9512475 , 0.24358922, 0.03553823, 0.2295192 , 0.12775839, 0.0919773 , 0.50947895, 0.74584544]) . np.random.rand(10)*2 # (0~1)*2 = 0~2 사이에서 10개의 난수 생성 . array([0.70426213, 1.54703597, 0.73553232, 1.35319966, 1.7224698 , 1.43787541, 1.62631319, 1.54416732, 0.3511027 , 1.63909984]) . np.random.rand(10)+1 # 1~2 사이에서 10개의 난수 생성 . array([1.8882947 , 1.21487037, 1.87248472, 1.8506064 , 1.42443757, 1.795348 , 1.37847909, 1.24870616, 1.66128972, 1.7608405 ]) . np.random.rand(10)*2+1 # 1~3 사이에서 10개의 난수 생성 . array([2.16303879, 1.27818637, 1.32514334, 1.6161346 , 2.03926784, 1.50032755, 1.16183896, 1.51923212, 2.67152899, 1.2616228 ]) . np.random.randn . {python} np.random.randn(N) . np.random.randn(10) # 표준정규분포에서 10개 추출 . array([ 0.16284596, -1.41505923, -0.87931282, -1.96742692, -0.17715718, -0.18035526, 1.31177136, -1.02100905, -0.3559429 , 0.40319735]) . np.random.randn(10)*2 # 평균이 0이고 표준편차가 2인 정규분포 . array([ 0.29806358, 2.00020956, -0.5111455 , -3.0789904 , 2.98176489, 3.77815177, -1.25610359, -1.54689973, -2.11675118, 0.5415075 ]) . np.random.randn(10)*2 + 3 # 평균이 0이고 표준편차가 3인 정규분포 . array([ 0.19911518, 2.68233421, 3.80413328, 2.60169535, 2.48309103, 5.28444139, 5.77762188, 5.52430879, -0.17405269, 3.34573411]) . np.random.randint . 중복을 허용하지 않고 정수를 생성한다. | . np.random.randint(7) # [0,7)의 범위에서 정수 한 개 생성 . 1 . np.random.randint(7, size = (20,)) . array([1, 0, 2, 1, 4, 4, 0, 2, 3, 1, 3, 5, 2, 5, 6, 5, 6, 1, 1, 2]) . np.random.randint(7, size = (2,2)) # [0,7)의 범위 무작위 정수가 원소인 2x2 행렬을 생성한다. . array([[2, 1], [4, 6]]) . np.random.randint(low=10, high=20, size=(2,5)) # [10, 20)의 범위에서 정수 한 개 생성 . array([[16, 14, 13, 13, 11], [12, 11, 18, 14, 15]]) . Warning :np.random.randint(high = N)은 사용할 수 없다. . np.random.choice . 복원추출이 default | . np.random.choice(5,20) . array([3, 2, 4, 2, 0, 1, 1, 2, 1, 4, 3, 3, 3, 1, 0, 0, 0, 0, 2, 2]) . np.random.choice([&#39;apple&#39;, &#39;orange&#39;, &#39;banana&#39;], 20) . array([&#39;banana&#39;, &#39;apple&#39;, &#39;apple&#39;, &#39;apple&#39;, &#39;apple&#39;, &#39;banana&#39;, &#39;apple&#39;, &#39;banana&#39;, &#39;banana&#39;, &#39;banana&#39;, &#39;orange&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;apple&#39;, &#39;orange&#39;, &#39;orange&#39;, &#39;orange&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;banana&#39;], dtype=&#39;&lt;U6&#39;) . np.random.choice(5, 2, replace = False) # Replace = False로 하면 비복원추출을 시행한다. . array([2, 3]) . np.random.binomial . np.random.binomial(n=10, p=0.2, size = (5,)) . array([2, 3, 3, 2, 2]) . np.random.normal . {python} np.random.normal(loc = mean, scale = stdev, size) default : np.random.normal(loc = 0, scale = 1, size = None) . np.random.normal(2, 3, 10) # 평균이 2이고 표준편차가 3인 정규분포 . array([-2.2383093 , 4.8091005 , 0.15352256, 4.9793976 , 0.33729707, 6.12970338, 5.18818041, -1.62767898, -1.60791145, 0.97458435]) . np.random.uniform . np.random.uniform(low=2, high=4, size = (5,)) # 균등분포 . array([2.51568342, 2.3858703 , 2.42784566, 3.65082018, 2.5756164 ]) . np.random.poisson(lam=5, size=(5,)) . array([2, 5, 4, 3, 3]) . np.random.poisson . np.random.poisson(lam=5, size=(5,)) . array([3, 7, 3, 4, 4]) . .corrcoef . np.random.seed(43052) x= np.random.randn(10000) y= np.random.randn(10000)*2 z= np.random.randn(10000)*0.5 np.corrcoef([x,y,z]).round(2) . array([[ 1. , -0.01, 0.01], [-0.01, 1. , 0. ], [ 0.01, 0. , 1. ]]) . .cov . np.cov([x,y,z]).round(2) . array([[ 0.99, -0.02, 0. ], [-0.02, 4.06, 0. ], [ 0. , 0. , 0.25]]) . .reshape . . Tip: R의 dim 함수와 유사하다. . A = np.array([11,22,33,44,55,66]) A . array([11, 22, 33, 44, 55, 66]) . A.reshape(2,3) . array([[11, 22, 33], [44, 55, 66]]) . A . array([11, 22, 33, 44, 55, 66]) . A = A.reshape(2,3) A . array([[11, 22, 33], [44, 55, 66]]) . note :reshape with -1 . A = np.arange(24) A . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) . A.reshape(2,-1) # 행의 수가 2인 행렬, 열은 알아서 맞춰 . array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]]) . A.reshape(4, -1) # 행의 수가 4인 행렬, 열은 알아서 맞춰 . array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) . A.reshape(-1, 4) # 열의 수가 4인 행렬, 행은 알아서 맞춰 . array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]) . A.reshape(-1) # 다시 길이가 24인 벡터로 . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]) . .shape . A = np.array(3.14) # Scalar, 0d array A.shape . () . A = np.array([3.14]) # Vector, 1d array A.shape . (1,) . A = np.array([[3.14]]) # Matrix, 2d array A.shape . (1, 1) . A = np.array([[[3.14]]]) # Tensor, 3d array A.shape . (1, 1, 1) . A = np.array([[1,2,3],[2,5,6],[4,4,2]]) A.shape . (3, 3) . .T . A = np.arange(4).reshape(2,2) A . array([[0, 1], [2, 3]]) . A.T # 전치행렬 . array([[0, 2], [1, 3]]) . np.linalg.inv . np.linalg.inv(A) # 역행렬 . array([[-1.5, 0.5], [ 1. , 0. ]]) . @ . A @ np.linalg.inv(A) . array([[1., 0.], [0., 1.]]) . np.concatenate . A = np.array([1,2]) B = np.array([4,5]) np.concatenate([A, B]) . array([1, 2, 4, 5]) . A = np.arange(4).reshape(2,2) B = np.arange(10,14).reshape(2,2) np.concatenate([A, B]) # axis = 0이 생략되어 있다. . array([[ 0, 1], [ 2, 3], [10, 11], [12, 13]]) . A=np.array(range(4)).reshape(2,2) B=np.array(range(2)).reshape(2,1) np.concatenate([a,b],axis=1) # 꼭 같은 차원일 필요는 없고, 붙여지는 부분의 길이만 같으면 됨 . NameError Traceback (most recent call last) Input In [82], in &lt;cell line: 3&gt;() 1 A=np.array(range(4)).reshape(2,2) 2 B=np.array(range(2)).reshape(2,1) -&gt; 3 np.concatenate([a,b],axis=1) NameError: name &#39;a&#39; is not defined . A = np.arange(4).reshape(2,2) B = np.arange(10,14).reshape(2,2) np.concatenate([A, B], axis=1) . A = np.array(range(2*3*4)).reshape(2,3,4) B = - A A, B . np.concatenate([A,B], axis=0) . np.concatenate([A,B], axis=1) . np.concatenate([A,B], axis=2) . np.stack . Warning : . A = np.array([1,2,3]) B = np.array([2,3,4]) np.concatenate([A,B], axis = 1) . AxisError Traceback (most recent call last) Input In [83], in &lt;cell line: 3&gt;() 1 A = np.array([1,2,3]) 2 B = np.array([2,3,4]) -&gt; 3 np.concatenate([A,B], axis = 1) File &lt;__array_function__ internals&gt;:180, in concatenate(*args, **kwargs) AxisError: axis 1 is out of bounds for array of dimension 1 . A = np.array([1,2,3]) B = np.array([2,3,4]) np.stack([A,B], axis=0) . array([[1, 2, 3], [2, 3, 4]]) . np.stack([A,B], axis=1) . array([[1, 2], [2, 3], [3, 4]]) . A = np.arange(3*4*5).reshape(3,4,5) B = - A A.shape, B.shape . ((3, 4, 5), (3, 4, 5)) . np.stack([A,B], axis = 0) . array([[[[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [ 10, 11, 12, 13, 14], [ 15, 16, 17, 18, 19]], [[ 20, 21, 22, 23, 24], [ 25, 26, 27, 28, 29], [ 30, 31, 32, 33, 34], [ 35, 36, 37, 38, 39]], [[ 40, 41, 42, 43, 44], [ 45, 46, 47, 48, 49], [ 50, 51, 52, 53, 54], [ 55, 56, 57, 58, 59]]], [[[ 0, -1, -2, -3, -4], [ -5, -6, -7, -8, -9], [-10, -11, -12, -13, -14], [-15, -16, -17, -18, -19]], [[-20, -21, -22, -23, -24], [-25, -26, -27, -28, -29], [-30, -31, -32, -33, -34], [-35, -36, -37, -38, -39]], [[-40, -41, -42, -43, -44], [-45, -46, -47, -48, -49], [-50, -51, -52, -53, -54], [-55, -56, -57, -58, -59]]]]) . . np.stack([A,B], axis = 0).shape # axis = 0 &lt;==&gt; axis = -4 . (2, 3, 4, 5) . np.stack([A,B], axis = 1).shape # axis = 1 &lt;==&gt; axis = -3 . (3, 2, 4, 5) . np.stack([A,B], axis = 2).shape # axis = 2 &lt;==&gt; axis = -2 . (3, 4, 2, 5) . np.stack([A,B], axis = 3).shape # axis = 3 &lt;==&gt; axis = -1 . (3, 4, 5, 2) . Difference between np.concatenate and np.stack . np.concatenate는 축의 총 개수를 유지하면서 결합한다. . np.stack은 축의 개수를 하나 증가시키면서 결합한다. . np.vstack . A = np.arange(6) B = - A . np.vstack([A, B]) . array([[ 0, 1, 2, 3, 4, 5], [ 0, -1, -2, -3, -4, -5]]) . np.hstack . A = np.arange(6) B = - A . np.hstack([A, B]) . array([ 0, 1, 2, 3, 4, 5, 0, -1, -2, -3, -4, -5]) . np.append . A = np.arange(30).reshape(5,6) B = - np.arange(8).reshape(2,2,2) A.shape, B.shape . ((5, 6), (2, 2, 2)) . np.append(A, B) # 다 풀어서 더한다. . array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 0, -1, -2, -3, -4, -5, -6, -7]) . A = np.arange(2*3*4).reshape(2,3,4) B = - A A, B . (array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]), array([[[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]]])) . A.shape, B.shape, np.append(A, B, axis = 0).shape . ((2, 3, 4), (2, 3, 4), (4, 3, 4)) . np.append(A, B, axis = 0) . array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[ 12, 13, 14, 15], [ 16, 17, 18, 19], [ 20, 21, 22, 23]], [[ 0, -1, -2, -3], [ -4, -5, -6, -7], [ -8, -9, -10, -11]], [[-12, -13, -14, -15], [-16, -17, -18, -19], [-20, -21, -22, -23]]]) . np.diff . A = np.array([1,2,4,6,7]) np.diff(A) . array([1, 2, 2, 1]) . np.diff(np.diff(A)) . array([ 1, 0, -1]) . np.diff(A, prepend=100) # np.diff(np.array([100] + A.tolist()) ), 즉 맨 앞에 100을 추가하여 차분 . array([-99, 1, 2, 2, 1]) . np.diff(A, append=100) # np.diff(np.array(A.tolist() + [100]) ), 즉 맨 뒤에 100을 추가하여 차분 . array([ 1, 2, 2, 1, 93]) . A = np.arange(24).reshape(4,6) A . array([[ 0, 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]) . np.diff(A, axis = 0) . array([[6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6], [6, 6, 6, 6, 6, 6]]) . np.diff(A, axis = 1) . array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]) . np.where . A = np.array([0,0,0,1,0]) np.where(A==1) # 조건을 만족하는 인덱스를 반환 . (array([3], dtype=int64),) . np.random.seed(43052) A = np.random.randn(12).reshape(3,4) np.where(A&lt;0) # 조건을 만족하는 인덱스가 (1,2), (1,3), (2,0), (2,1), (2,3) 이라는 의미 . (array([1, 1, 2, 2, 2], dtype=int64), array([2, 3, 0, 1, 3], dtype=int64)) . A[np.where(A&lt;0)] . array([-1.66307542, -1.38277318, -1.92684484, -1.4862163 , -0.03488725]) . np.where(A&lt;0, 0, A) # 조건이 True이면 0, False이면 A . array([[0.38342049, 1.0841745 , 1.14277825, 0.30789368], [0.23778744, 0.35595116, 0. , 0. ], [0. , 0. , 0.00692519, 0. ]]) . np.where(A&lt;0, 5, 1) # 조건이 True이면 0, False이면 1 . array([[1, 1, 1, 1], [1, 1, 5, 5], [5, 5, 1, 5]]) . np.argwhere . A = np.array([0,0,0,1,0]) np.argwhere(A==1) . array([[3]], dtype=int64) . np.random.seed(43052) A = np.random.randn(12).reshape(3,4) np.argwhere(A&lt;0) # 조건을 만족하는 인덱스가 (1,2), (1,3), (2,0), (2,1), (2,3) 이라는 의미 . array([[1, 2], [1, 3], [2, 0], [2, 1], [2, 3]], dtype=int64) . A[np.argwhere(A&lt;0)] # 불가능 . IndexError Traceback (most recent call last) Input In [106], in &lt;cell line: 1&gt;() -&gt; 1 A[np.argwhere(A&lt;0)] IndexError: index 3 is out of bounds for axis 0 with size 3 . Difference between np.where and np.argwhere . np.where는 인덱스의 좌표를 읽는 가독성이 떨어지지만 조건에 맞는 원소를 출력하거나 처리하기에 좋다. . np.argwhere는 인덱스의 좌표를 읽는 가독성은 좋지만 조건에 맞는 원소를 출력하거나 처리하기에 좋지 못하다. . np.ix_ . A = np.arange(12).reshape(3,4) A . array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) . A[[0,1], [0,1]]이 A[0:2, 0:2]를 의미하게 하려면 아레와 같이 np.ix_를 사용한다. | . A[np.ix_([0,1],[0,1])] . array([[0, 1], [4, 5]]) . Operations . .sum . A = np.array([1,2,3]) A.sum() . 6 . .mean . A = np.array([1,2,3]) A.mean() . 2.0 . .min . A = np.array([1,2,3]) A.min() . 1 . .max . A = np.array([1,2,3]) A.max() . 3 . .prod . A = np.array([1,2,3]) A.prod() . 6 . .std . A = np.arange(1,20) A.std() # 분포를 n으로 나누는 것이 default이다. . 5.477225575051661 . A = A = np.array([1,2,3]) A.std(ddof=1) # ddof 옵션을 사용하여 분포를 n-1로 나눈다. . 1.0 . A = A = np.array([1,2,3]) A.std(ddof=2) # ddof 옵션을 사용하여 분포를 n-1로 나눈다. . 1.4142135623730951 . .argmin . A = np.array([1,2,3]) # 가장 작은 값의 인덱스를 리턴 A.argmin() . 0 . np.random.seed(43052) A = np.random.randn(4*5).reshape(4,5) A . array([[ 0.38342049, 1.0841745 , 1.14277825, 0.30789368, 0.23778744], [ 0.35595116, -1.66307542, -1.38277318, -1.92684484, -1.4862163 ], [ 0.00692519, -0.03488725, -0.34357323, 0.70895648, -1.55100608], [ 1.34565583, -0.05654272, -0.83017342, -1.46395159, -0.35459593]]) . A.argmin(axis = 0) . array([2, 1, 1, 1, 2], dtype=int64) . A.argmin(axis = 1) . array([4, 3, 4, 3], dtype=int64) . .argmax . A = np.array([1,2,3]) # 가장 큰 값의 인덱스를 리턴 A.argmax() . 2 . np.random.seed(43052) A = np.random.randn(4*5).reshape(4,5) A . array([[ 0.38342049, 1.0841745 , 1.14277825, 0.30789368, 0.23778744], [ 0.35595116, -1.66307542, -1.38277318, -1.92684484, -1.4862163 ], [ 0.00692519, -0.03488725, -0.34357323, 0.70895648, -1.55100608], [ 1.34565583, -0.05654272, -0.83017342, -1.46395159, -0.35459593]]) . A.argmax(axis = 0) . array([3, 0, 0, 2, 0], dtype=int64) . A.argmax(axis = 1) . array([2, 0, 3, 0], dtype=int64) . .cumsum . A = np.array([1,2,3,4]) A.cumsum() # 누적합 . array([ 1, 3, 6, 10]) . .cumprod . A = np.array([1,2,3,4]) A.cumprod() # 누적곱 . array([ 1, 2, 6, 24]) . A = np.array([2**i for i in np.arange(10)]) A . array([ 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]) . A.cumprod() . array([ 1, 2, 8, 64, 1024, 32768, 2097152, 268435456, 0, 0]) . Applications . Solving System of Equations . $ begin{cases} y+z+w = 3 x+z+w = 3 x+y+w = 3 x+y+z = 3 end{cases}$ . $ begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 &amp; 1 1 &amp; 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 &amp; 0 end{bmatrix} begin{bmatrix} x y z w end{bmatrix} = begin{bmatrix} 3 3 3 3 end{bmatrix}$ . $ begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 &amp; 1 1 &amp; 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 &amp; 0 end{bmatrix}^{ ,-1} begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 &amp; 1 1 &amp; 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 &amp; 0 end{bmatrix} begin{bmatrix} x y z w end{bmatrix} = begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 &amp; 1 1 &amp; 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 &amp; 0 end{bmatrix}^{ ,-1} begin{bmatrix} 3 3 3 3 end{bmatrix}$ . $ begin{bmatrix} x y z w end{bmatrix} = begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 1 &amp; 0 &amp; 1 &amp; 1 1 &amp; 1 &amp; 0 &amp; 1 1 &amp; 1 &amp; 1 &amp; 0 end{bmatrix}^{ ,-1} begin{bmatrix} 3 3 3 3 end{bmatrix}$ . v = &#39;x&#39;, &#39;y&#39;, &#39;z&#39; A = np.linalg.inv(np.array([[0,1,1,1],[1,0,1,1],[1,1,0,1],[1,1,1,0]])) B = np.array([3,3,3,3]).reshape(4,1) answer = A@B.reshape(-1) for v, i in zip(v, answer): print(v, &#39;:&#39;, i) . x : 1.0 y : 1.0 z : 1.0 .",
            "url": "https://stahangryum.github.io/Woo/python/highlight/2022/04/11/numpy_highlight.html",
            "relUrl": "/python/highlight/2022/04/11/numpy_highlight.html",
            "date": " • Apr 11, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Pima Indians Diabetes Prediction",
            "content": "Reference . ref. https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database . Pima Indians Diabetes Prediction . Variable Definition . Pregnancies | 임신 횟수 | . Glucose | 포도당 부하 검사 수치 | . BloodPressure | 혈압 | . SkinThickness | 팔 삼두근 뒤쪽의 피하지방 측정값(mm) | . Inlulin | 혈청 인슐린(mu U/ml) | . BMI | 체질량지수$( frac{kg}{m^2})$ | . DiabetesPredigreeFunction | 당뇨 내력 가중치 값 | . Age | 나이 | . Outcome | 클래스 결정 값(0 또는 1) | . Packages . import numpy as np import pandas as pd import matplotlib.pyplot as plt %matplotlib inline from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve from sklearn.preprocessing import StandardScaler from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import Binarizer import warnings warnings.filterwarnings(action=&#39;ignore&#39;) . Preprocessing . diabetes_data = pd.read_csv(&#39;diabetes.csv&#39;) diabetes_data.head() . Pregnancies Glucose BloodPressure SkinThickness Insulin BMI DiabetesPedigreeFunction Age Outcome . 0 6 | 148 | 72 | 35 | 0 | 33.6 | 0.627 | 50 | 1 | . 1 1 | 85 | 66 | 29 | 0 | 26.6 | 0.351 | 31 | 0 | . 2 8 | 183 | 64 | 0 | 0 | 23.3 | 0.672 | 32 | 1 | . 3 1 | 89 | 66 | 23 | 94 | 28.1 | 0.167 | 21 | 0 | . 4 0 | 137 | 40 | 35 | 168 | 43.1 | 2.288 | 33 | 1 | . diabetes_data.Outcome.value_counts() . 0 500 1 268 Name: Outcome, dtype: int64 . diabetes_data.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 768 entries, 0 to 767 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 Pregnancies 768 non-null int64 1 Glucose 768 non-null int64 2 BloodPressure 768 non-null int64 3 SkinThickness 768 non-null int64 4 Insulin 768 non-null int64 5 BMI 768 non-null float64 6 DiabetesPedigreeFunction 768 non-null float64 7 Age 768 non-null int64 8 Outcome 768 non-null int64 dtypes: float64(2), int64(7) memory usage: 54.1 KB . Glucose, BloodPressure, SkinThickness, Insulin, Bmi은 0이면 안된다. | . zero_features = [&#39;Glucose&#39;, &#39;BloodPressure&#39;, &#39;SkinThickness&#39;, &#39;Insulin&#39;, &#39;BMI&#39;] for i, feature in enumerate(zero_features): plt.subplot(3,2,i+1) plt.hist(diabetes_data[feature]) . diabetes_data[diabetes_data[&#39;Glucose&#39;] == 0][&#39;Glucose&#39;].count() . 5 . for feature in zero_features: zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count() print(&#39;{0} 0 건수는 {1}, 퍼센트는 {2:.2f}%&#39;.format(feature, zero_count, 100*zero_count / diabetes_data[feature].count())) . Glucose 0 건수는 5, 퍼센트는 0.65% BloodPressure 0 건수는 35, 퍼센트는 4.56% SkinThickness 0 건수는 227, 퍼센트는 29.56% Insulin 0 건수는 374, 퍼센트는 48.70% BMI 0 건수는 11, 퍼센트는 1.43% . SkinThickness, Insulin feature가 0인 행을 지우면 데이터 손실이 너무 크므로 평균값으로 대체한다. . mean_zero_features = diabetes_data[zero_features].mean() diabetes_data[zero_features] = diabetes_data[zero_features].replace(0, mean_zero_features) . Prediction . def precision_recall_curve_plot(y_test, pred_proba_c1): precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1) plt.figure(figsize=(8,6)) threshold_boundary = thresholds.shape[0] plt.plot(thresholds, precisions[0:threshold_boundary], linestyle = &#39;-&#39;, label = &#39;precision&#39;) plt.plot(thresholds, recalls[0:threshold_boundary], label = &#39;recall&#39;) start, end = plt.xlim() plt.xticks(np.round(np.arange(start, end, 0.1), 2)) plt.xlabel(&#39;Threshold value&#39;); plt.ylabel(&#39;Precision and Recall value&#39;) plt.legend(); plt.grid() plt.show() def get_clf_eval(y_test, pred=None, pred_proba=None): # 모델 평가 함수 confusion = confusion_matrix(y_test, pred) accuracy = accuracy_score(y_test, pred) precision = precision_score(y_test, pred) recall = recall_score(y_test, pred) f1 = f1_score(y_test, pred) roc_auc = roc_auc_score(y_test, pred_proba) print(&#39;오차 행렬&#39;) print(confusion) print(&#39;정확도 : {0:.3f}, 정밀도 : {1:.3f}, 재현율 : {2:.3f}, F1 : {3:.3f}, AUC : {4:.3f}&#39;.format( accuracy, precision, recall, f1, roc_auc)) def get_eval_by_threshold(y_test, pred_proba_c1, thresholds): for custom_threshold in thresholds: binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) custom_predict = binarizer.transform(pred_proba_c1) print(&#39;-&#39;) print(&#39;임계값:&#39;, round(custom_threshold,2)) get_clf_eval(y_test, custom_predict, pred_proba_c1) . . feature_name = diabetes_data.columns[:-1] target_name = diabetes_data.columns[-1] X = diabetes_data.loc[:, feature_name] y = diabetes_data.loc[:, target_name] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y) . lr_clf = LogisticRegression() lr_clf.fit(X_train, y_train) pred = lr_clf.predict(X_test) pred_proba = lr_clf.predict_proba(X_test)[:, 1] get_clf_eval(y_test, pred, pred_proba) . 오차 행렬 [[90 10] [21 33]] 정확도 : 0.799, 정밀도 : 0.767, 재현율 : 0.611, F1 : 0.680, AUC : 0.845 . pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1] precision_recall_curve_plot(y_test, pred_proba_c1) . thresholds = np.arange(0.3, 0.5, 0.03) pred_proba = lr_clf.predict_proba(X_test) get_eval_by_threshold(y_test, pred_proba[:, 1].reshape(-1,1), thresholds) . - 임계값: 0.3 오차 행렬 [[67 33] [11 43]] 정확도 : 0.714, 정밀도 : 0.566, 재현율 : 0.796, F1 : 0.662, AUC : 0.845 - 임계값: 0.33 오차 행렬 [[73 27] [12 42]] 정확도 : 0.747, 정밀도 : 0.609, 재현율 : 0.778, F1 : 0.683, AUC : 0.845 - 임계값: 0.36 오차 행렬 [[76 24] [15 39]] 정확도 : 0.747, 정밀도 : 0.619, 재현율 : 0.722, F1 : 0.667, AUC : 0.845 - 임계값: 0.39 오차 행렬 [[79 21] [17 37]] 정확도 : 0.753, 정밀도 : 0.638, 재현율 : 0.685, F1 : 0.661, AUC : 0.845 - 임계값: 0.42 오차 행렬 [[84 16] [18 36]] 정확도 : 0.779, 정밀도 : 0.692, 재현율 : 0.667, F1 : 0.679, AUC : 0.845 - 임계값: 0.45 오차 행렬 [[85 15] [18 36]] 정확도 : 0.786, 정밀도 : 0.706, 재현율 : 0.667, F1 : 0.686, AUC : 0.845 - 임계값: 0.48 오차 행렬 [[89 11] [19 35]] 정확도 : 0.805, 정밀도 : 0.761, 재현율 : 0.648, F1 : 0.700, AUC : 0.845 . . binarizer = Binarizer(threshold=0.48) pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1)) get_clf_eval(y_test, pred_th_048, pred_proba[:, 1]) . 오차 행렬 [[89 11] [19 35]] 정확도 : 0.805, 정밀도 : 0.761, 재현율 : 0.648, F1 : 0.700, AUC : 0.845 .",
            "url": "https://stahangryum.github.io/Woo/kaggle/2022/04/07/pima.html",
            "relUrl": "/kaggle/2022/04/07/pima.html",
            "date": " • Apr 7, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Titanic Survivor Prediction",
            "content": "Reference . ref. https://www.kaggle.com/c/titanic/ . Titanic Survivor Prediction . 타이타닉호 침몰 사고 당시 탑승자들의 정보를 활용하여 생존자를 예측하라. . Data Dictionary . Variable Definition Key . Survived | Survival | 0 = No, 1 = Yes | . Pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd | . Sex | Sex | . Age | Age in years | . SibSp | # of siblings / spouses aboard the Titanic | . Parch | # of parents / children aboard the Titanic | . Ticket | Ticket number | . Fare | Passenger fare | . Cabin | Cabin number | . Embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton | . Variable Notes . pclass: A proxy for socio-economic status (SES) 1st = Upper 2nd = Middle 3rd = Lower . age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5 . sibsp: The dataset defines family relations in this way... Sibling = brother, sister, stepbrother, stepsister Spouse = husband, wife (mistresses and fiancés were ignored) . parch: The dataset defines family relations in this way... Parent = mother, father Child = daughter, son, stepdaughter, stepson Some children travelled only with a nanny, therefore parch=0 for them. . Stage I . import . import numpy as np import pandas as pd . code . import os print(os.getcwd()) . C: Users godgk Desktop Project kaggle Titanic . train = pd.read_csv(&#39;data/train.csv&#39;) test = pd.read_csv(&#39;data/test.csv&#39;) . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . print(&#39;train data shape&#39;, train.shape) print(&#39;test data shape&#39;, test.shape) print(&#39;--[train infomation]--&#39;) print(train.info()) print(&#39;--[test infomation]--&#39;) print(test.info()) . train data shape (891, 12) test data shape (418, 11) --[train infomation]-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB None --[test infomation]-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 418 entries, 0 to 417 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 418 non-null int64 1 Pclass 418 non-null int64 2 Name 418 non-null object 3 Sex 418 non-null object 4 Age 332 non-null float64 5 SibSp 418 non-null int64 6 Parch 418 non-null int64 7 Ticket 418 non-null object 8 Fare 417 non-null float64 9 Cabin 91 non-null object 10 Embarked 418 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 36.0+ KB None . train.isnull().sum() . PassengerId 0 Survived 0 Pclass 0 Name 0 Sex 0 Age 177 SibSp 0 Parch 0 Ticket 0 Fare 0 Cabin 687 Embarked 2 dtype: int64 . test.isnull().sum() . PassengerId 0 Pclass 0 Name 0 Sex 0 Age 86 SibSp 0 Parch 0 Ticket 0 Fare 1 Cabin 327 Embarked 0 dtype: int64 . Stage II . import . import matplotlib.pyplot as plt %matplotlib inline import seaborn as sns sns.set() . def pie_chart(feature): feature_ratio = train[feature].value_counts(sort=False) feature_size = feature_ratio.size feature_index = feature_ratio.index survived = train[train[&#39;Survived&#39;] == 1][feature].value_counts() dead = train[train[&#39;Survived&#39;] == 0][feature].value_counts() plt.plot(aspect=&#39;auto&#39;) plt.pie(feature_ratio, labels=feature_index, autopct=&#39;%1.1f%%&#39;) plt.title(feature + &#39; &#39;s ratio in total&#39;) plt.show() for i, index in enumerate(feature_index): plt.subplot(1, feature_size + 1, i + 1, aspect=&#39;equal&#39;) plt.pie([survived[index], dead[index]], labels=[&#39;Survivied&#39;, &#39;Dead&#39;], autopct=&#39;%1.1f%%&#39;) plt.title(str(index) + &#39; &#39;s ratio&#39;) plt.show() . pie_chart(&quot;Sex&quot;) . 남성 탑승객이 여성 탑승객보다 많다. . | 여성 탑승객의 생존 비율이 남성 탑승객보다 높다. . | . pie_chart(&quot;Pclass&quot;) . 1등실 2등실 3등실 순으로 생존 비율이 높다. | . pie_chart(&quot;Embarked&quot;) . train[&#39;Ticket&#39;][0:50] . 0 A/5 21171 1 PC 17599 2 STON/O2. 3101282 3 113803 4 373450 5 330877 6 17463 7 349909 8 347742 9 237736 10 PP 9549 11 113783 12 A/5. 2151 13 347082 14 350406 15 248706 16 382652 17 244373 18 345763 19 2649 20 239865 21 248698 22 330923 23 113788 24 349909 25 347077 26 2631 27 19950 28 330959 29 349216 30 PC 17601 31 PC 17569 32 335677 33 C.A. 24579 34 PC 17604 35 113789 36 2677 37 A./5. 2152 38 345764 39 2651 40 7546 41 11668 42 349253 43 SC/Paris 2123 44 330958 45 S.C./A.4. 23567 46 370371 47 14311 48 2662 49 349237 Name: Ticket, dtype: object . train.Ticket . 0 A/5 21171 1 PC 17599 2 STON/O2. 3101282 3 113803 4 373450 ... 886 211536 887 112053 888 W./C. 6607 889 111369 890 370376 Name: Ticket, Length: 891, dtype: object . Stage 3 . def bar_chart(feature): survived = train[train[&#39;Survived&#39;] == 1][feature].value_counts() dead = train[train[&#39;Survived&#39;] == 0][feature].value_counts() df = pd.DataFrame([survived, dead]) df.index = [&#39;Survived&#39;, &#39;Dead&#39;] df.plot(kind=&#39;bar&#39;, stacked=True, figsize=(10,5)) . bar_chart(&quot;SibSp&quot;) . bar_chart(&quot;Parch&quot;) . Data Preprocessing . train_and_test = [train, test] . Name Feature . for dataset in train_and_test: dataset[&#39;Title&#39;] = dataset.Name.str.extract(&#39; ([A-Za-z]+) .&#39;) . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked Title . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | Mr | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | Mrs | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | Miss | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | Mrs | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | Mr | . pd.crosstab(train[&#39;Title&#39;], train[&#39;Sex&#39;]) . Sex female male . Title . Capt 0 | 1 | . Col 0 | 2 | . Countess 1 | 0 | . Don 0 | 1 | . Dr 1 | 6 | . Jonkheer 0 | 1 | . Lady 1 | 0 | . Major 0 | 2 | . Master 0 | 40 | . Miss 182 | 0 | . Mlle 2 | 0 | . Mme 1 | 0 | . Mr 0 | 517 | . Mrs 125 | 0 | . Ms 1 | 0 | . Rev 0 | 6 | . Sir 0 | 1 | . for dataset in train_and_test: dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace([&#39;Capt&#39;, &#39;Col&#39;, &#39;Countess&#39;, &#39;Don&#39;,&#39;Dona&#39;, &#39;Dr&#39;, &#39;Jonkheer&#39;,&#39;Lady&#39;,&#39;Major&#39;, &#39;Rev&#39;, &#39;Sir&#39;], &#39;Other&#39;) dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace([&#39;Mlle&#39;, &#39;Ms&#39;], &#39;Miss&#39;) dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].replace(&#39;Mme&#39;, &#39;Mrs&#39;) . pd.crosstab(train[&#39;Title&#39;], train[&#39;Sex&#39;]) . Sex female male . Title . Master 0 | 40 | . Miss 185 | 0 | . Mr 0 | 517 | . Mrs 126 | 0 | . Other 3 | 20 | . train[[&#39;Title&#39;, &#39;Survived&#39;]].groupby(&#39;Title&#39;).mean() . Survived . Title . Master 0.575000 | . Miss 0.702703 | . Mr 0.156673 | . Mrs 0.793651 | . Other 0.347826 | . train[[&#39;Title&#39;, &#39;Survived&#39;]].groupby(&#39;Title&#39;, as_index = False).mean() # as_index = True이면 Title이 index로 작용한다. . Title Survived . 0 Master | 0.575000 | . 1 Miss | 0.702703 | . 2 Mr | 0.156673 | . 3 Mrs | 0.793651 | . 4 Other | 0.347826 | . for dataset in train_and_test: dataset[&#39;Title&#39;] = dataset[&#39;Title&#39;].astype(str) . Sex Feature . for dataset in train_and_test: dataset[&#39;Sex&#39;] = dataset[&#39;Sex&#39;].astype(str) . Embarked Feature . train.Embarked.value_counts(dropna=False) . S 644 C 168 Q 77 NaN 2 Name: Embarked, dtype: int64 . for dataset in train_and_test: dataset[&#39;Embarked&#39;] = dataset[&#39;Embarked&#39;].fillna(&#39;S&#39;) dataset[&#39;Embarked&#39;] = dataset[&#39;Embarked&#39;].astype(str) . Age Feature . Binning . train.Age.isna().sum() . 177 . for dataset in train_and_test: dataset[&#39;Age&#39;].fillna(dataset[&#39;Age&#39;].mean(), inplace=True) dataset[&#39;Age&#39;] = dataset[&#39;Age&#39;].astype(int) train[&#39;AgeBand&#39;] = pd.cut(train[&#39;Age&#39;], 5) train[[&#39;AgeBand&#39;, &#39;Survived&#39;]].groupby([&#39;AgeBand&#39;], as_index=False).mean() . AgeBand Survived . 0 (-0.08, 16.0] | 0.550000 | . 1 (16.0, 32.0] | 0.344762 | . 2 (32.0, 48.0] | 0.403226 | . 3 (48.0, 64.0] | 0.434783 | . 4 (64.0, 80.0] | 0.090909 | . for dataset in train_and_test: dataset.loc[ dataset[&#39;Age&#39;] &lt;= 16, &#39;Age&#39;] = 0 dataset.loc[(dataset[&#39;Age&#39;] &gt; 16) &amp; (dataset[&#39;Age&#39;] &lt;= 32), &#39;Age&#39;] = 1 dataset.loc[(dataset[&#39;Age&#39;] &gt; 32) &amp; (dataset[&#39;Age&#39;] &lt;= 48), &#39;Age&#39;] = 2 dataset.loc[(dataset[&#39;Age&#39;] &gt; 48) &amp; (dataset[&#39;Age&#39;] &lt;= 64), &#39;Age&#39;] = 3 dataset.loc[ dataset[&#39;Age&#39;] &gt; 64, &#39;Age&#39;] = 4 dataset[&#39;Age&#39;] = dataset[&#39;Age&#39;].map( { 0:&#39;Child&#39;, 1:&#39;Young&#39;, 2:&#39;Middle&#39;, 3:&#39;Prime&#39;, 4:&#39;Old&#39; } ).astype(str) . Fare Feature . for dataset in train_and_test: print(dataset[&#39;Fare&#39;].isna().sum()) . 0 1 . train[[&#39;Pclass&#39;, &#39;Fare&#39;]].groupby([&#39;Pclass&#39;], as_index=False).mean() . Pclass Fare . 0 1 | 84.154687 | . 1 2 | 20.662183 | . 2 3 | 13.675550 | . test[test[&#39;Fare&#39;].isna()][&#39;Pclass&#39;] . 152 3 Name: Pclass, dtype: int64 . for dataset in train_and_test: dataset[&#39;Fare&#39;] = dataset[&#39;Fare&#39;].fillna(13.675) # Pclass가 3인 승객의 평균 Fare . train[&#39;FareBand&#39;] = pd.qcut(train[&#39;Fare&#39;], 5) for dataset in train_and_test: dataset.loc[ dataset[&#39;Fare&#39;] &lt;= 7.854, &#39;Fare&#39;] = 0 dataset.loc[(dataset[&#39;Fare&#39;] &gt; 7.854) &amp; (dataset[&#39;Fare&#39;] &lt;= 10.5), &#39;Fare&#39;] = 1 dataset.loc[(dataset[&#39;Fare&#39;] &gt; 10.5) &amp; (dataset[&#39;Fare&#39;] &lt;= 21.679), &#39;Fare&#39;] = 2 dataset.loc[(dataset[&#39;Fare&#39;] &gt; 21.679) &amp; (dataset[&#39;Fare&#39;] &lt;= 39.688), &#39;Fare&#39;] = 3 dataset.loc[ dataset[&#39;Fare&#39;] &gt; 39.688, &#39;Fare&#39;] = 4 dataset[&#39;Fare&#39;] = dataset[&#39;Fare&#39;].map( { 0:&#39;XS&#39;, 1:&#39;S&#39;, 2:&#39;M&#39;, 3:&#39;L&#39;, 4:&#39;XL&#39; } ).astype(str) . SibSp &amp; Parch Feature (Family) . for dataset in train_and_test: dataset[&#39;Family&#39;] = dataset[&#39;Parch&#39;] + dataset[&#39;SibSp&#39;] dataset[&#39;Family&#39;] = dataset[&#39;Family&#39;].astype(int) . Other Feature . features_drop = [&#39;Name&#39;, &#39;Ticket&#39;, &#39;Cabin&#39;, &#39;SibSp&#39;, &#39;Parch&#39;] train = train.drop(features_drop, axis = 1) test = test.drop(features_drop, axis = 1) train = train.drop([&#39;PassengerId&#39;, &#39;AgeBand&#39;, &#39;FareBand&#39;], axis = 1) . train.head() . Survived Pclass Sex Age Fare Embarked Title Family . 0 0 | 3 | male | Young | XS | S | Mr | 1 | . 1 1 | 1 | female | Middle | XL | C | Mrs | 1 | . 2 1 | 3 | female | Young | S | S | Miss | 0 | . 3 1 | 1 | female | Middle | XL | S | Mrs | 1 | . 4 0 | 3 | male | Middle | S | S | Mr | 0 | . test.head() . PassengerId Pclass Sex Age Fare Embarked Title Family . 0 892 | 3 | male | Middle | XS | Q | Mr | 0 | . 1 893 | 3 | female | Middle | XS | S | Mrs | 1 | . 2 894 | 2 | male | Prime | S | Q | Mr | 0 | . 3 895 | 3 | male | Young | S | S | Mr | 0 | . 4 896 | 3 | female | Young | M | S | Mrs | 2 | . train = pd.get_dummies(train) test = pd.get_dummies(test) train_label = train[&#39;Survived&#39;] train_data = train.drop(&#39;Survived&#39;, axis = 1) test_data = test.drop(&#39;PassengerId&#39;, axis = 1).copy() . print(train_data.shape, train_label.shape, test_data.shape) . (891, 22) (891,) (418, 22) . train . Survived Pclass Family Sex_female Sex_male Age_Child Age_Middle Age_Old Age_Prime Age_Young ... Fare_XL Fare_XS Embarked_C Embarked_Q Embarked_S Title_Master Title_Miss Title_Mr Title_Mrs Title_Other . 0 0 | 3 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | . 1 1 | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | ... | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | . 2 1 | 3 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 3 1 | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | ... | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | . 4 0 | 3 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 0 | 2 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | . 887 1 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 888 0 | 3 | 3 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | . 889 1 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | . 890 0 | 3 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | . 891 rows × 23 columns . test . PassengerId Pclass Family Sex_female Sex_male Age_Child Age_Middle Age_Old Age_Prime Age_Young ... Fare_XL Fare_XS Embarked_C Embarked_Q Embarked_S Title_Master Title_Miss Title_Mr Title_Mrs Title_Other . 0 892 | 3 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | ... | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | . 1 893 | 3 | 1 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | . 2 894 | 2 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | ... | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | . 3 895 | 3 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | . 4 896 | 3 | 2 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 413 1305 | 3 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | . 414 1306 | 1 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | ... | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | . 415 1307 | 3 | 0 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | ... | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | . 416 1308 | 3 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | . 417 1309 | 3 | 2 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 418 rows × 23 columns . Learning . import . !pip install scikit-learn . Requirement already satisfied: scikit-learn in c: users godgk anaconda3 envs py39r40 lib site-packages (1.0.2) Requirement already satisfied: numpy&gt;=1.14.6 in c: users godgk anaconda3 envs py39r40 lib site-packages (from scikit-learn) (1.20.3) Requirement already satisfied: scipy&gt;=1.1.0 in c: users godgk anaconda3 envs py39r40 lib site-packages (from scikit-learn) (1.7.1) Requirement already satisfied: joblib&gt;=0.11 in c: users godgk anaconda3 envs py39r40 lib site-packages (from scikit-learn) (1.1.0) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in c: users godgk anaconda3 envs py39r40 lib site-packages (from scikit-learn) (3.1.0) . from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC from sklearn.neighbors import KNeighborsClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.naive_bayes import GaussianNB from sklearn.utils import shuffle . train_data, train_label = shuffle(train_data, train_label, random_state = 5) . def train_and_test(model): model.fit(train_data, train_label) prediction = model.predict(test_data) accuracy = round(model.score(train_data, train_label) * 100, 2) print(&quot;Accuracy : &quot;, accuracy, &quot;%&quot;) return prediction . log_pred = train_and_test(LogisticRegression()) # SVM svm_pred = train_and_test(SVC()) #kNN knn_pred_4 = train_and_test(KNeighborsClassifier(n_neighbors = 4)) # Random Forest rf_pred = train_and_test(RandomForestClassifier(n_estimators=100)) # Navie Bayes nb_pred = train_and_test(GaussianNB()) . Accuracy : 82.27 % Accuracy : 83.61 % Accuracy : 84.74 % Accuracy : 88.55 % Accuracy : 79.35 % . submission = pd.DataFrame({ &quot;PassengerId&quot;: test[&quot;PassengerId&quot;], &quot;Survived&quot;: rf_pred }) submission.to_csv(&#39;submission_rf.csv&#39;, index=False) .",
            "url": "https://stahangryum.github.io/Woo/kaggle/2022/04/06/Titanic.html",
            "relUrl": "/kaggle/2022/04/06/Titanic.html",
            "date": " • Apr 6, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "Initial Settings",
            "content": "작성중 | . Window Setting . https://www.youtube.com/watch?v=SgqgBPx8zEE . Anaconda Setting . https://www.anaconda.com/products/individual . conda create -n py39r41 python=3.9 . | conda activate py39r41 . | conda install -c conda-forge r-essentials=4.1 . | conda install -c conda-forge jupyterlab . | R . | install.packages(&quot;IRkernel&quot;) . | library(IRkernel) . | installspec() . | q() . | pip install numpy . | pip install pandas . | pip install SciPy . | pip install matplotlib . | conda install -c conda-forge rise . | etc . | . . Git Setting . Git . | Git Bash . | GitHub Desktop . | . !git add . !git commit -m . !git push .",
            "url": "https://stahangryum.github.io/Woo/2022/03/15/settings.html",
            "relUrl": "/2022/03/15/settings.html",
            "date": " • Mar 15, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Monte Carlo Integration with Python",
            "content": "Monte Carlo Integration . Problem . Find $ int_0^1 (x + sin( pi x)) ,dx$. . Solution I - Analytic Sol . $ int_0^1 (x + sin( pi x)) ,dx = left[ cfrac{1}{2} x^2- cfrac{1}{ pi}cos( pi x) right]_0^1 = cfrac{1}{2} + cfrac{1}{ pi} + cfrac{1}{ pi} = cfrac{1}{2}+ cfrac{2}{ pi}$ . Solution II - Monte Carlo Integration in Python . import numpy as np import matplotlib.pyplot as plt %matplotlib inline . def function(x): return x + np.sin(np.pi*x) x = np.linspace(0, 1, 10000) y = [function(x) for x in x] plt.plot(x, y) plt.show() . def function(x): #함수 정의 return x + np.sin(np.pi*x) N = 5000 # Random Sampling 시행 횟수 width = 1 # 사각형의 가로 길이 height = 1.6 #사각형의 세로 길이 X = np.random.random(N) # 0~1까지의 x 좌표 Random Sampling을 N번 시행 rand_Y = height * np.random.random(N) # 그래프상 최솟값 ~ 최댓값까지의 y 좌표 Randon Sampling을 N번 시행 in_or_out = rand_Y &lt; function(X) # rand_Y &lt; FX (IN)이면 True, Y &gt; F (OUT)이면 False A = height * width * np.sum(in_or_out) / N # 영역 S의 넓이 print(&#39;이론적으로 구한 값 : {0} n샘플링으로 구한 값 : {1}&#39;.format(1/2 + 2/np.pi, A)) . 이론적으로 구한 값 : 1.1366197723675815 샘플링으로 구한 값 : 1.12864 . Visualization . from matplotlib.animation import FuncAnimation . color = list(map(lambda x: &#39;blue&#39; if x == True else &#39;red&#39;, in_or_out)) #색 정하기 x = np.linspace(0, 1, 10000) #함수 그리기 y = [function(x) for x in x] plt.plot(x, y, color = &#39;black&#39;) plt.scatter(X, rand_Y, color = color, s=1, label=&#39;A = {0}&#39;.format(np.round(A, 4))) plt.legend(loc = &#39;lower right&#39;) #범례(legend) 위치 plt.plot([0, width], [0, 0], color=&#39;black&#39;) # 사각형 영역 plt.plot([width, width], [0, height], color=&#39;black&#39;) plt.plot([0, width], [height, height], color=&#39;black&#39;) plt.plot([0, 0], [0, height], color=&#39;black&#39;) plt.xlabel(&#39;x&#39;) plt.ylabel(&#39;y&#39;) plt.show() .",
            "url": "https://stahangryum.github.io/Woo/python/2021/10/03/monte_carlo.html",
            "relUrl": "/python/2021/10/03/monte_carlo.html",
            "date": " • Oct 3, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Taylor and Maclaurin Series",
            "content": "Taylor Series . $ f(x) = sum_{n=0}^ infty cfrac{f^{(n)}(a)}{n!}(x-a)^n qquad quad= f(a) + cfrac{f&#39;(a)}{1!}(x-a) + cfrac{f&#39;&#39;(a)}{2!}(x-a) + cfrac{f&#39;&#39;&#39;(a)}{3!}(x-a)+ cdots $ . Maclaurin Series . $ f(x) = sum_{n=0}^ infty cfrac{f^{(n)}(0)}{n!}(x-0)^n qquad quad = f(a) + cfrac{f^{ prime}(0)}{1!}(x-0) + cfrac{f^{ prime prime}(0)}{2!}(x-0) + cfrac{f^{ prime prime prime}(0)}{3!}(x-0)+ cdots $ . Examples . $ cfrac{1}{1-x} = sum_{n=0}^ infty{x^n} = 1+x+x^2+x^3+ cdots qquad R = 1 , e^x = sum_{n=0}^ infty cfrac{x^n}{n!} = 1 + cfrac{x}{1!} + cfrac{x^2}{2!} + cfrac{x^3}{3!}+ cdots qquad R = infty , sin ,x = sum_{n=0}^ infty(-1)^n cfrac{x^{2n+1}}{(2n+1)!} = x - cfrac{x^3}{3!} + cfrac{x^5}{5!} - cfrac{x^7}{7!}+ cdots qquad R = infty , cos ,x = sum_{n=0}^ infty(-1)^n cfrac{x^{2n}}{(2n)!} = 1 - cfrac{x^2}{2!} + cfrac{x^4}{4!} - cfrac{x^6}{6!}+ cdots qquad R = infty , tan^{-1} ,x = sum_{n=0}^ infty(-1)^n cfrac{x^{2n+1}}{(2n+1)} = x - cfrac{x^3}{3} + cfrac{x^5}{5} - cfrac{x^7}{7}+ cdots qquad R = 1 , ln(1+x) = sum_{n=1}^ infty(-1)^{n-1} cfrac{x^{n}}{n} = x - cfrac{x^2}{2} + cfrac{x^3}{3} - cfrac{x^4}{4}+ cdots qquad R = 1 $ .",
            "url": "https://stahangryum.github.io/Woo/mathematics/2021/10/02/taylor.html",
            "relUrl": "/mathematics/2021/10/02/taylor.html",
            "date": " • Oct 2, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Kim Jeewoo . Jeonbuk Nation University. Statistics . GitHub . | LinkedIn . | Blog . | . . Contact . stahangryum@gmail.com .",
          "url": "https://stahangryum.github.io/Woo/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://stahangryum.github.io/Woo/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}